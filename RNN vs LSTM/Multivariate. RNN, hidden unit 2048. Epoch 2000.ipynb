{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d01b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjintae\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jintae/RNN%20seq%202048./runs/2lka09qu\" target=\"_blank\">epoch 2000</a></strong> to <a href=\"https://wandb.ai/jintae/RNN%20seq%202048.\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jintae/RNN%20seq%202048./runs/2lka09qu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1f0b555f520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"RNN seq 2048.\", name=\"epoch 2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650bae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE  Sales\n",
      "0     0   3459\n",
      "1     1   3458\n",
      "2     2   4002\n",
      "3     3   4564\n",
      "4     4   4221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/PARK/Desktop/Alcohol_Sales.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e18e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4f8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6063052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01930485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 3459],\n",
       "       [   1, 3458],\n",
       "       [   2, 4002],\n",
       "       [   3, 4564],\n",
       "       [   4, 4221]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad83b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17aef2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data.mean()\n",
    "data_std = data.std()\n",
    "\n",
    "data = (data - data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fe0032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9194862 , -0.12914209],\n",
       "       [-0.91925771, -0.12937058],\n",
       "       [-0.91902922, -0.00507246],\n",
       "       [-0.91880073,  0.12333846],\n",
       "       [-0.91857224,  0.04496667]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ac24ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_label = []\n",
    "\n",
    "data_len = 325\n",
    "time_step = 100\n",
    "out_dim = 25\n",
    "\n",
    "for i in range(176):\n",
    "    _input = data[i:i+time_step]\n",
    "    _label = data[i+time_step:i+time_step+out_dim]\n",
    "    \n",
    "    train_input.append(_input)\n",
    "    train_label.append(_label)\n",
    "    \n",
    "\n",
    "train_input = np.array(train_input)\n",
    "train_label = np.array(train_label)\n",
    "train_label = np.delete(train_label, 0, axis=2)\n",
    "\n",
    "\n",
    "test_input = np.array(data[data_len-out_dim-time_step:data_len-out_dim])\n",
    "test_label =np.array(data[300:325])\n",
    "test_label = np.delete(test_label, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41975dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b762c3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 25, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127c63a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6647472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d83c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "shuffled_indices = np.random.permutation(np.arange(train_input.shape[0]))\n",
    "train_input = train_input[shuffled_indices, :, :]\n",
    "train_label = train_label[shuffled_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a183926e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 2048)              4200448   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                51225     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,251,673\n",
      "Trainable params: 4,251,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.5996 - mae: 1.3653INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 735ms/step - loss: 2.5996 - mae: 1.3653 - val_loss: 9.3753 - val_mae: 2.8874\n",
      "Epoch 2/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.5937 - mae: 1.7955INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 672ms/step - loss: 4.5937 - mae: 1.7955 - val_loss: 0.8127 - val_mae: 0.7461\n",
      "Epoch 3/2000\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 2.7370 - mae: 1.3826 - val_loss: 3.8378 - val_mae: 1.5387\n",
      "Epoch 4/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 5.1664 - mae: 1.9445 - val_loss: 1.0335 - val_mae: 0.8735\n",
      "Epoch 5/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3440 - mae: 0.9784INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 576ms/step - loss: 1.3440 - mae: 0.9784 - val_loss: 0.2800 - val_mae: 0.4292\n",
      "Epoch 6/2000\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.3064 - mae: 0.4461 - val_loss: 0.3919 - val_mae: 0.5029\n",
      "Epoch 7/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.3526 - mae: 0.4864 - val_loss: 0.2913 - val_mae: 0.4431\n",
      "Epoch 8/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2806 - mae: 0.4291INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 609ms/step - loss: 0.2806 - mae: 0.4291 - val_loss: 0.2098 - val_mae: 0.3786\n",
      "Epoch 9/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2282 - mae: 0.3925INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 599ms/step - loss: 0.2282 - mae: 0.3925 - val_loss: 0.2093 - val_mae: 0.3808\n",
      "Epoch 10/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2159 - mae: 0.3821INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 570ms/step - loss: 0.2159 - mae: 0.3821 - val_loss: 0.1989 - val_mae: 0.3702\n",
      "Epoch 11/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2027 - mae: 0.3703INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 615ms/step - loss: 0.2027 - mae: 0.3703 - val_loss: 0.1933 - val_mae: 0.3645\n",
      "Epoch 12/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1964 - mae: 0.3668INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 619ms/step - loss: 0.1964 - mae: 0.3668 - val_loss: 0.1871 - val_mae: 0.3624\n",
      "Epoch 13/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1988 - mae: 0.3684INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 639ms/step - loss: 0.1988 - mae: 0.3684 - val_loss: 0.1841 - val_mae: 0.3578\n",
      "Epoch 14/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1979 - mae: 0.3667INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 628ms/step - loss: 0.1979 - mae: 0.3667 - val_loss: 0.1840 - val_mae: 0.3586\n",
      "Epoch 15/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1976 - mae: 0.3679INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 606ms/step - loss: 0.1976 - mae: 0.3679 - val_loss: 0.1796 - val_mae: 0.3560\n",
      "Epoch 16/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1824 - mae: 0.3555INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 696ms/step - loss: 0.1824 - mae: 0.3555 - val_loss: 0.1781 - val_mae: 0.3514\n",
      "Epoch 17/2000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.1821 - mae: 0.3530 - val_loss: 0.1789 - val_mae: 0.3558\n",
      "Epoch 18/2000\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.1861 - mae: 0.3560 - val_loss: 0.1783 - val_mae: 0.3519\n",
      "Epoch 19/2000\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.1946 - mae: 0.3651 - val_loss: 0.1793 - val_mae: 0.3534\n",
      "Epoch 20/2000\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.1952 - mae: 0.3644 - val_loss: 0.1873 - val_mae: 0.3586\n",
      "Epoch 21/2000\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.2088 - mae: 0.3772 - val_loss: 0.1879 - val_mae: 0.3614\n",
      "Epoch 22/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.1974 - mae: 0.3656 - val_loss: 0.1811 - val_mae: 0.3543\n",
      "Epoch 23/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1828 - mae: 0.3546 - val_loss: 0.1799 - val_mae: 0.3537\n",
      "Epoch 24/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1834 - mae: 0.3554 - val_loss: 0.1786 - val_mae: 0.3552\n",
      "Epoch 25/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1876 - mae: 0.3578INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 591ms/step - loss: 0.1876 - mae: 0.3578 - val_loss: 0.1773 - val_mae: 0.3508\n",
      "Epoch 26/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1830 - mae: 0.3554INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 674ms/step - loss: 0.1830 - mae: 0.3554 - val_loss: 0.1762 - val_mae: 0.3500\n",
      "Epoch 27/2000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.1783 - mae: 0.3501 - val_loss: 0.1772 - val_mae: 0.3516\n",
      "Epoch 28/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1800 - mae: 0.3522INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 609ms/step - loss: 0.1800 - mae: 0.3522 - val_loss: 0.1746 - val_mae: 0.3486\n",
      "Epoch 29/2000\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.1813 - mae: 0.3526 - val_loss: 0.1764 - val_mae: 0.3511\n",
      "Epoch 30/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1820 - mae: 0.3540 - val_loss: 0.1803 - val_mae: 0.3564\n",
      "Epoch 31/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.1908 - mae: 0.3590 - val_loss: 0.1892 - val_mae: 0.3599\n",
      "Epoch 32/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1922 - mae: 0.3640 - val_loss: 0.1921 - val_mae: 0.3668\n",
      "Epoch 33/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1877 - mae: 0.3593 - val_loss: 0.1777 - val_mae: 0.3495\n",
      "Epoch 34/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1821 - mae: 0.3528 - val_loss: 0.1766 - val_mae: 0.3504\n",
      "Epoch 35/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1848 - mae: 0.3561 - val_loss: 0.1767 - val_mae: 0.3525\n",
      "Epoch 36/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1815 - mae: 0.3519 - val_loss: 0.1945 - val_mae: 0.3638\n",
      "Epoch 37/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2010 - mae: 0.3702 - val_loss: 0.1764 - val_mae: 0.3498\n",
      "Epoch 38/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1929 - mae: 0.3642 - val_loss: 0.1826 - val_mae: 0.3578\n",
      "Epoch 39/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1923 - mae: 0.3622 - val_loss: 0.1983 - val_mae: 0.3647\n",
      "Epoch 40/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1869 - mae: 0.3577 - val_loss: 0.1803 - val_mae: 0.3556\n",
      "Epoch 41/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.1761 - mae: 0.3474 - val_loss: 0.1921 - val_mae: 0.3599\n",
      "Epoch 42/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1864 - mae: 0.3590 - val_loss: 0.1781 - val_mae: 0.3530\n",
      "Epoch 43/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2048 - mae: 0.3749 - val_loss: 0.1953 - val_mae: 0.3664\n",
      "Epoch 44/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2067 - mae: 0.3742 - val_loss: 0.2131 - val_mae: 0.3771\n",
      "Epoch 45/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1985 - mae: 0.3670 - val_loss: 0.1792 - val_mae: 0.3517\n",
      "Epoch 46/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.1892 - mae: 0.3612 - val_loss: 0.1802 - val_mae: 0.3542\n",
      "Epoch 47/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1877 - mae: 0.3577 - val_loss: 0.1865 - val_mae: 0.3554\n",
      "Epoch 48/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1834 - mae: 0.3547 - val_loss: 0.1782 - val_mae: 0.3517\n",
      "Epoch 49/2000\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.1778 - mae: 0.3484 - val_loss: 0.1853 - val_mae: 0.3563\n",
      "Epoch 50/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1796 - mae: 0.3517 - val_loss: 0.1765 - val_mae: 0.3508\n",
      "Epoch 51/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1783 - mae: 0.3499 - val_loss: 0.1851 - val_mae: 0.3572\n",
      "Epoch 52/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1780 - mae: 0.3484 - val_loss: 0.1802 - val_mae: 0.3536\n",
      "Epoch 53/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1851 - mae: 0.3566 - val_loss: 0.1769 - val_mae: 0.3527\n",
      "Epoch 54/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1795 - mae: 0.3509 - val_loss: 0.1846 - val_mae: 0.3581\n",
      "Epoch 55/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2007 - mae: 0.3673 - val_loss: 0.2174 - val_mae: 0.3822\n",
      "Epoch 56/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1983 - mae: 0.3676INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 584ms/step - loss: 0.1983 - mae: 0.3676 - val_loss: 0.1736 - val_mae: 0.3475\n",
      "Epoch 57/2000\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.1857 - mae: 0.3564 - val_loss: 0.1763 - val_mae: 0.3500\n",
      "Epoch 58/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1759 - mae: 0.3464INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 710ms/step - loss: 0.1759 - mae: 0.3464 - val_loss: 0.1712 - val_mae: 0.3446\n",
      "Epoch 59/2000\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.1748 - mae: 0.3463 - val_loss: 0.1783 - val_mae: 0.3498\n",
      "Epoch 60/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1753 - mae: 0.3474 - val_loss: 0.1736 - val_mae: 0.3461\n",
      "Epoch 61/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1727 - mae: 0.3435INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 651ms/step - loss: 0.1727 - mae: 0.3435 - val_loss: 0.1685 - val_mae: 0.3400\n",
      "Epoch 62/2000\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.1727 - mae: 0.3458 - val_loss: 0.1724 - val_mae: 0.3479\n",
      "Epoch 63/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1712 - mae: 0.3425 - val_loss: 0.1710 - val_mae: 0.3408\n",
      "Epoch 64/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1780 - mae: 0.3489 - val_loss: 0.1762 - val_mae: 0.3517\n",
      "Epoch 65/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1768 - mae: 0.3463 - val_loss: 0.1823 - val_mae: 0.3519\n",
      "Epoch 66/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1768 - mae: 0.3482 - val_loss: 0.1823 - val_mae: 0.3516\n",
      "Epoch 67/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1814 - mae: 0.3520 - val_loss: 0.1851 - val_mae: 0.3548\n",
      "Epoch 68/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1787 - mae: 0.3482 - val_loss: 0.1757 - val_mae: 0.3479\n",
      "Epoch 69/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1722 - mae: 0.3428 - val_loss: 0.1817 - val_mae: 0.3516\n",
      "Epoch 70/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1807 - mae: 0.3482 - val_loss: 0.1737 - val_mae: 0.3447\n",
      "Epoch 71/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1729 - mae: 0.3438INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 567ms/step - loss: 0.1729 - mae: 0.3438 - val_loss: 0.1649 - val_mae: 0.3389\n",
      "Epoch 72/2000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.1738 - mae: 0.3441 - val_loss: 0.1927 - val_mae: 0.3666\n",
      "Epoch 73/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1853 - mae: 0.3521 - val_loss: 0.1708 - val_mae: 0.3410\n",
      "Epoch 74/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1852 - mae: 0.3514 - val_loss: 0.2577 - val_mae: 0.4168\n",
      "Epoch 75/2000\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.2310 - mae: 0.3975 - val_loss: 0.1845 - val_mae: 0.3533\n",
      "Epoch 76/2000\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.1931 - mae: 0.3649 - val_loss: 0.1728 - val_mae: 0.3478\n",
      "Epoch 77/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1869 - mae: 0.3553 - val_loss: 0.2155 - val_mae: 0.3797\n",
      "Epoch 78/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.1854 - mae: 0.3512 - val_loss: 0.2116 - val_mae: 0.3774\n",
      "Epoch 79/2000\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.1939 - mae: 0.3623 - val_loss: 0.1739 - val_mae: 0.3435\n",
      "Epoch 80/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1769 - mae: 0.3473INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 631ms/step - loss: 0.1769 - mae: 0.3473 - val_loss: 0.1649 - val_mae: 0.3377\n",
      "Epoch 81/2000\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.1678 - mae: 0.3405 - val_loss: 0.1866 - val_mae: 0.3601\n",
      "Epoch 82/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.1965 - mae: 0.3655 - val_loss: 0.1914 - val_mae: 0.3609\n",
      "Epoch 83/2000\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.1868 - mae: 0.3490 - val_loss: 0.1875 - val_mae: 0.3539\n",
      "Epoch 84/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1967 - mae: 0.3657 - val_loss: 0.1905 - val_mae: 0.3584\n",
      "Epoch 85/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.2010 - mae: 0.3687 - val_loss: 0.1926 - val_mae: 0.3604\n",
      "Epoch 86/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1796 - mae: 0.3482 - val_loss: 0.1735 - val_mae: 0.3443\n",
      "Epoch 87/2000\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.1808 - mae: 0.3502 - val_loss: 0.1670 - val_mae: 0.3385\n",
      "Epoch 88/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1712 - mae: 0.3372 - val_loss: 0.2460 - val_mae: 0.4066\n",
      "Epoch 89/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2092 - mae: 0.3730 - val_loss: 0.1854 - val_mae: 0.3542\n",
      "Epoch 90/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.1838 - mae: 0.3510 - val_loss: 0.1677 - val_mae: 0.3374\n",
      "Epoch 91/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1926 - mae: 0.3600 - val_loss: 0.1682 - val_mae: 0.3405\n",
      "Epoch 92/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1736 - mae: 0.3426 - val_loss: 0.2111 - val_mae: 0.3762\n",
      "Epoch 93/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1957 - mae: 0.3589 - val_loss: 0.2164 - val_mae: 0.3799\n",
      "Epoch 94/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2131 - mae: 0.3786 - val_loss: 0.2499 - val_mae: 0.4124\n",
      "Epoch 95/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2161 - mae: 0.3787 - val_loss: 0.1675 - val_mae: 0.3374\n",
      "Epoch 96/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1932 - mae: 0.3611 - val_loss: 0.1893 - val_mae: 0.3582\n",
      "Epoch 97/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1893 - mae: 0.3569 - val_loss: 0.1795 - val_mae: 0.3510\n",
      "Epoch 98/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1735 - mae: 0.3395 - val_loss: 0.1908 - val_mae: 0.3575\n",
      "Epoch 99/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1721 - mae: 0.3386INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 579ms/step - loss: 0.1721 - mae: 0.3386 - val_loss: 0.1648 - val_mae: 0.3362\n",
      "Epoch 100/2000\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.1802 - mae: 0.3495 - val_loss: 0.1848 - val_mae: 0.3534\n",
      "Epoch 101/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1730 - mae: 0.3426 - val_loss: 0.1668 - val_mae: 0.3402\n",
      "Epoch 102/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1741 - mae: 0.3445 - val_loss: 0.2164 - val_mae: 0.3818\n",
      "Epoch 103/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1941 - mae: 0.3610 - val_loss: 0.1983 - val_mae: 0.3648\n",
      "Epoch 104/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1844 - mae: 0.3506 - val_loss: 0.1655 - val_mae: 0.3322\n",
      "Epoch 105/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1841 - mae: 0.3522 - val_loss: 0.1922 - val_mae: 0.3604\n",
      "Epoch 106/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1896 - mae: 0.3575 - val_loss: 0.1758 - val_mae: 0.3448\n",
      "Epoch 107/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1836 - mae: 0.3468INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 597ms/step - loss: 0.1836 - mae: 0.3468 - val_loss: 0.1603 - val_mae: 0.3295\n",
      "Epoch 108/2000\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.1797 - mae: 0.3475 - val_loss: 0.2059 - val_mae: 0.3712\n",
      "Epoch 109/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2052 - mae: 0.3686 - val_loss: 0.2844 - val_mae: 0.4395\n",
      "Epoch 110/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2247 - mae: 0.3876 - val_loss: 0.1706 - val_mae: 0.3384\n",
      "Epoch 111/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1818 - mae: 0.3496 - val_loss: 0.2438 - val_mae: 0.3997\n",
      "Epoch 112/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2343 - mae: 0.3980 - val_loss: 0.1956 - val_mae: 0.3620\n",
      "Epoch 113/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1823 - mae: 0.3504 - val_loss: 0.1903 - val_mae: 0.3536\n",
      "Epoch 114/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1811 - mae: 0.3455 - val_loss: 0.2052 - val_mae: 0.3740\n",
      "Epoch 115/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1888 - mae: 0.3561 - val_loss: 0.1618 - val_mae: 0.3316\n",
      "Epoch 116/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1589 - mae: 0.3264INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 573ms/step - loss: 0.1589 - mae: 0.3264 - val_loss: 0.1526 - val_mae: 0.3211\n",
      "Epoch 117/2000\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.1693 - mae: 0.3397 - val_loss: 0.1706 - val_mae: 0.3379\n",
      "Epoch 118/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1630 - mae: 0.3297 - val_loss: 0.1589 - val_mae: 0.3300\n",
      "Epoch 119/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1557 - mae: 0.3243 - val_loss: 0.1581 - val_mae: 0.3289\n",
      "Epoch 120/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1592 - mae: 0.3299 - val_loss: 0.1764 - val_mae: 0.3446\n",
      "Epoch 121/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1569 - mae: 0.3257INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 567ms/step - loss: 0.1569 - mae: 0.3257 - val_loss: 0.1448 - val_mae: 0.3175\n",
      "Epoch 122/2000\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.1524 - mae: 0.3210 - val_loss: 0.1749 - val_mae: 0.3409\n",
      "Epoch 123/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2040 - mae: 0.3665 - val_loss: 0.2629 - val_mae: 0.4131\n",
      "Epoch 124/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2116 - mae: 0.3710 - val_loss: 0.1656 - val_mae: 0.3352\n",
      "Epoch 125/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2474 - mae: 0.3990 - val_loss: 0.1741 - val_mae: 0.3441\n",
      "Epoch 126/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2431 - mae: 0.3978 - val_loss: 0.2123 - val_mae: 0.3769\n",
      "Epoch 127/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1903 - mae: 0.3539 - val_loss: 0.1665 - val_mae: 0.3351\n",
      "Epoch 128/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1586 - mae: 0.3282 - val_loss: 0.1553 - val_mae: 0.3215\n",
      "Epoch 129/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1784 - mae: 0.3479 - val_loss: 0.2149 - val_mae: 0.3763\n",
      "Epoch 130/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1996 - mae: 0.3608 - val_loss: 0.1723 - val_mae: 0.3433\n",
      "Epoch 131/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1934 - mae: 0.3602 - val_loss: 0.1684 - val_mae: 0.3346\n",
      "Epoch 132/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1649 - mae: 0.3304 - val_loss: 0.1463 - val_mae: 0.3140\n",
      "Epoch 133/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1564 - mae: 0.3212 - val_loss: 0.2621 - val_mae: 0.4228\n",
      "Epoch 134/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1905 - mae: 0.3527 - val_loss: 0.1586 - val_mae: 0.3273\n",
      "Epoch 135/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1571 - mae: 0.3262 - val_loss: 0.1554 - val_mae: 0.3220\n",
      "Epoch 136/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1466 - mae: 0.3171INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 590ms/step - loss: 0.1466 - mae: 0.3171 - val_loss: 0.1418 - val_mae: 0.3118\n",
      "Epoch 137/2000\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.1485 - mae: 0.3171 - val_loss: 0.1657 - val_mae: 0.3354\n",
      "Epoch 138/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1700 - mae: 0.3366INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 573ms/step - loss: 0.1700 - mae: 0.3366 - val_loss: 0.1405 - val_mae: 0.3066\n",
      "Epoch 139/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1479 - mae: 0.3139INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 586ms/step - loss: 0.1479 - mae: 0.3139 - val_loss: 0.1383 - val_mae: 0.3038\n",
      "Epoch 140/2000\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.1452 - mae: 0.3114 - val_loss: 0.1460 - val_mae: 0.3093\n",
      "Epoch 141/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1448 - mae: 0.3095 - val_loss: 0.1823 - val_mae: 0.3409\n",
      "Epoch 142/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1598 - mae: 0.3239INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 588ms/step - loss: 0.1598 - mae: 0.3239 - val_loss: 0.1334 - val_mae: 0.2957\n",
      "Epoch 143/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1263 - mae: 0.2890INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 639ms/step - loss: 0.1263 - mae: 0.2890 - val_loss: 0.1270 - val_mae: 0.2906\n",
      "Epoch 144/2000\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.1265 - mae: 0.2892 - val_loss: 0.1389 - val_mae: 0.3027\n",
      "Epoch 145/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1236 - mae: 0.2864 - val_loss: 0.1277 - val_mae: 0.2939\n",
      "Epoch 146/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1416 - mae: 0.3043 - val_loss: 0.1468 - val_mae: 0.3131\n",
      "Epoch 147/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1366 - mae: 0.3014 - val_loss: 0.1551 - val_mae: 0.3232\n",
      "Epoch 148/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1344 - mae: 0.2957INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 646ms/step - loss: 0.1344 - mae: 0.2957 - val_loss: 0.1199 - val_mae: 0.2837\n",
      "Epoch 149/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1098 - mae: 0.2673INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 610ms/step - loss: 0.1098 - mae: 0.2673 - val_loss: 0.1062 - val_mae: 0.2654\n",
      "Epoch 150/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1153 - mae: 0.2749INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 630ms/step - loss: 0.1153 - mae: 0.2749 - val_loss: 0.1038 - val_mae: 0.2602\n",
      "Epoch 151/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1197 - mae: 0.2784INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 630ms/step - loss: 0.1197 - mae: 0.2784 - val_loss: 0.0963 - val_mae: 0.2483\n",
      "Epoch 152/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0985 - mae: 0.2548INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 668ms/step - loss: 0.0985 - mae: 0.2548 - val_loss: 0.0901 - val_mae: 0.2433\n",
      "Epoch 153/2000\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0990 - mae: 0.2540 - val_loss: 0.0970 - val_mae: 0.2513\n",
      "Epoch 154/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1050 - mae: 0.2590 - val_loss: 0.0915 - val_mae: 0.2417\n",
      "Epoch 155/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0947 - mae: 0.2450 - val_loss: 0.0972 - val_mae: 0.2474\n",
      "Epoch 156/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0985 - mae: 0.2515 - val_loss: 0.1049 - val_mae: 0.2631\n",
      "Epoch 157/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1100 - mae: 0.2676INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 623ms/step - loss: 0.1100 - mae: 0.2676 - val_loss: 0.0900 - val_mae: 0.2420\n",
      "Epoch 158/2000\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.1008 - mae: 0.2541 - val_loss: 0.1215 - val_mae: 0.2805\n",
      "Epoch 159/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1127 - mae: 0.2707 - val_loss: 0.0946 - val_mae: 0.2481\n",
      "Epoch 160/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0943 - mae: 0.2467 - val_loss: 0.0998 - val_mae: 0.2531\n",
      "Epoch 161/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1018 - mae: 0.2525 - val_loss: 0.0930 - val_mae: 0.2395\n",
      "Epoch 162/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0900 - mae: 0.2366INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 569ms/step - loss: 0.0900 - mae: 0.2366 - val_loss: 0.0859 - val_mae: 0.2284\n",
      "Epoch 163/2000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0850 - mae: 0.2290 - val_loss: 0.0915 - val_mae: 0.2418\n",
      "Epoch 164/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0950 - mae: 0.2443 - val_loss: 0.1123 - val_mae: 0.2638\n",
      "Epoch 165/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0972 - mae: 0.2469 - val_loss: 0.1176 - val_mae: 0.2697\n",
      "Epoch 166/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1008 - mae: 0.2502INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 588ms/step - loss: 0.1008 - mae: 0.2502 - val_loss: 0.0733 - val_mae: 0.2110\n",
      "Epoch 167/2000\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0962 - mae: 0.2447 - val_loss: 0.1280 - val_mae: 0.2900\n",
      "Epoch 168/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1195 - mae: 0.2780 - val_loss: 0.0857 - val_mae: 0.2278\n",
      "Epoch 169/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1054 - mae: 0.2567 - val_loss: 0.1203 - val_mae: 0.2712\n",
      "Epoch 170/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0944 - mae: 0.2436 - val_loss: 0.1197 - val_mae: 0.2729\n",
      "Epoch 171/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0947 - mae: 0.2441 - val_loss: 0.0849 - val_mae: 0.2285\n",
      "Epoch 172/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0830 - mae: 0.2263INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 589ms/step - loss: 0.0830 - mae: 0.2263 - val_loss: 0.0708 - val_mae: 0.2100\n",
      "Epoch 173/2000\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0794 - mae: 0.2227 - val_loss: 0.0773 - val_mae: 0.2179\n",
      "Epoch 174/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0813 - mae: 0.2238 - val_loss: 0.0787 - val_mae: 0.2202\n",
      "Epoch 175/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0846 - mae: 0.2290 - val_loss: 0.0756 - val_mae: 0.2201\n",
      "Epoch 176/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0806 - mae: 0.2215 - val_loss: 0.0742 - val_mae: 0.2190\n",
      "Epoch 177/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0751 - mae: 0.2156 - val_loss: 0.0876 - val_mae: 0.2341\n",
      "Epoch 178/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0803 - mae: 0.2241 - val_loss: 0.0739 - val_mae: 0.2114\n",
      "Epoch 179/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0748 - mae: 0.2134 - val_loss: 0.0715 - val_mae: 0.2110\n",
      "Epoch 180/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0732 - mae: 0.2127 - val_loss: 0.0780 - val_mae: 0.2216\n",
      "Epoch 181/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0783 - mae: 0.2215 - val_loss: 0.0923 - val_mae: 0.2365\n",
      "Epoch 182/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0828 - mae: 0.2253 - val_loss: 0.0754 - val_mae: 0.2157\n",
      "Epoch 183/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0813 - mae: 0.2210 - val_loss: 0.0967 - val_mae: 0.2497\n",
      "Epoch 184/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0938 - mae: 0.2413 - val_loss: 0.0808 - val_mae: 0.2283\n",
      "Epoch 185/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0844 - mae: 0.2285 - val_loss: 0.0872 - val_mae: 0.2280\n",
      "Epoch 186/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0819 - mae: 0.2252 - val_loss: 0.0811 - val_mae: 0.2214\n",
      "Epoch 187/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0836 - mae: 0.2264 - val_loss: 0.0714 - val_mae: 0.2085\n",
      "Epoch 188/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0738 - mae: 0.2112 - val_loss: 0.0783 - val_mae: 0.2132\n",
      "Epoch 189/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0716 - mae: 0.2081 - val_loss: 0.0735 - val_mae: 0.2133\n",
      "Epoch 190/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0775 - mae: 0.2193 - val_loss: 0.0771 - val_mae: 0.2187\n",
      "Epoch 191/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0808 - mae: 0.2231 - val_loss: 0.0730 - val_mae: 0.2166\n",
      "Epoch 192/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0771 - mae: 0.2181 - val_loss: 0.0751 - val_mae: 0.2186\n",
      "Epoch 193/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0777 - mae: 0.2176 - val_loss: 0.0811 - val_mae: 0.2223\n",
      "Epoch 194/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0777 - mae: 0.2182 - val_loss: 0.0791 - val_mae: 0.2170\n",
      "Epoch 195/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0759 - mae: 0.2174INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 577ms/step - loss: 0.0759 - mae: 0.2174 - val_loss: 0.0671 - val_mae: 0.2001\n",
      "Epoch 196/2000\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0767 - mae: 0.2193 - val_loss: 0.0805 - val_mae: 0.2316\n",
      "Epoch 197/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0871 - mae: 0.2325 - val_loss: 0.0738 - val_mae: 0.2194\n",
      "Epoch 198/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0790 - mae: 0.2209INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_203603-2lka09qu\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 564ms/step - loss: 0.0790 - mae: 0.2209 - val_loss: 0.0649 - val_mae: 0.1977\n",
      "Epoch 199/2000\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0740 - mae: 0.2120 - val_loss: 0.0837 - val_mae: 0.2247\n",
      "Epoch 200/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0766 - mae: 0.2165 - val_loss: 0.0807 - val_mae: 0.2192\n",
      "Epoch 201/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0770 - mae: 0.2187 - val_loss: 0.0723 - val_mae: 0.2114\n",
      "Epoch 202/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0791 - mae: 0.2213 - val_loss: 0.0717 - val_mae: 0.2116\n",
      "Epoch 203/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0767 - mae: 0.2190 - val_loss: 0.0681 - val_mae: 0.2015\n",
      "Epoch 204/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0713 - mae: 0.2080 - val_loss: 0.0807 - val_mae: 0.2189\n",
      "Epoch 205/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0752 - mae: 0.2150 - val_loss: 0.0840 - val_mae: 0.2329\n",
      "Epoch 206/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0840 - mae: 0.2287 - val_loss: 0.0720 - val_mae: 0.2096\n",
      "Epoch 207/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0812 - mae: 0.2234 - val_loss: 0.0790 - val_mae: 0.2173\n",
      "Epoch 208/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0789 - mae: 0.2211 - val_loss: 0.0942 - val_mae: 0.2401\n",
      "Epoch 209/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0841 - mae: 0.2294 - val_loss: 0.0769 - val_mae: 0.2223\n",
      "Epoch 210/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0809 - mae: 0.2235 - val_loss: 0.0722 - val_mae: 0.2129\n",
      "Epoch 211/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0788 - mae: 0.2205 - val_loss: 0.0788 - val_mae: 0.2250\n",
      "Epoch 212/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0788 - mae: 0.2226 - val_loss: 0.0821 - val_mae: 0.2291\n",
      "Epoch 213/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0776 - mae: 0.2182 - val_loss: 0.0757 - val_mae: 0.2138\n",
      "Epoch 214/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0781 - mae: 0.2190 - val_loss: 0.0712 - val_mae: 0.2126\n",
      "Epoch 215/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0812 - mae: 0.2234 - val_loss: 0.1042 - val_mae: 0.2584\n",
      "Epoch 216/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1031 - mae: 0.2519 - val_loss: 0.0998 - val_mae: 0.2500\n",
      "Epoch 217/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0969 - mae: 0.2455 - val_loss: 0.0781 - val_mae: 0.2190\n",
      "Epoch 218/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0813 - mae: 0.2229 - val_loss: 0.0877 - val_mae: 0.2347\n",
      "Epoch 219/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0814 - mae: 0.2237 - val_loss: 0.0813 - val_mae: 0.2290\n",
      "Epoch 220/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0860 - mae: 0.2281 - val_loss: 0.0695 - val_mae: 0.2059\n",
      "Epoch 221/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0799 - mae: 0.2216 - val_loss: 0.0769 - val_mae: 0.2164\n",
      "Epoch 222/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0747 - mae: 0.2141 - val_loss: 0.0797 - val_mae: 0.2187\n",
      "Epoch 223/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0752 - mae: 0.2161 - val_loss: 0.0782 - val_mae: 0.2200\n",
      "Epoch 224/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0748 - mae: 0.2143 - val_loss: 0.0809 - val_mae: 0.2289\n",
      "Epoch 225/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0757 - mae: 0.2153 - val_loss: 0.0792 - val_mae: 0.2195\n",
      "Epoch 226/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0746 - mae: 0.2163 - val_loss: 0.0833 - val_mae: 0.2235\n",
      "Epoch 227/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0785 - mae: 0.2203 - val_loss: 0.0713 - val_mae: 0.2126\n",
      "Epoch 228/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0762 - mae: 0.2159 - val_loss: 0.0739 - val_mae: 0.2140\n",
      "Epoch 229/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0740 - mae: 0.2135 - val_loss: 0.0721 - val_mae: 0.2082\n",
      "Epoch 230/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0746 - mae: 0.2139 - val_loss: 0.0716 - val_mae: 0.2100\n",
      "Epoch 231/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0730 - mae: 0.2115 - val_loss: 0.0739 - val_mae: 0.2172\n",
      "Epoch 232/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0755 - mae: 0.2167 - val_loss: 0.0730 - val_mae: 0.2162\n",
      "Epoch 233/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0742 - mae: 0.2142 - val_loss: 0.0983 - val_mae: 0.2420\n",
      "Epoch 234/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0812 - mae: 0.2257 - val_loss: 0.0806 - val_mae: 0.2194\n",
      "Epoch 235/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0765 - mae: 0.2159 - val_loss: 0.0769 - val_mae: 0.2201\n",
      "Epoch 236/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0730 - mae: 0.2127 - val_loss: 0.0730 - val_mae: 0.2091\n",
      "Epoch 237/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0774 - mae: 0.2180 - val_loss: 0.0754 - val_mae: 0.2154\n",
      "Epoch 238/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0761 - mae: 0.2170 - val_loss: 0.0687 - val_mae: 0.2048\n",
      "Epoch 239/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0696 - mae: 0.2065 - val_loss: 0.0763 - val_mae: 0.2175\n",
      "Epoch 240/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0726 - mae: 0.2117 - val_loss: 0.0795 - val_mae: 0.2241\n",
      "Epoch 241/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0769 - mae: 0.2168 - val_loss: 0.0840 - val_mae: 0.2359\n",
      "Epoch 242/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0828 - mae: 0.2271 - val_loss: 0.0802 - val_mae: 0.2235\n",
      "Epoch 243/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0851 - mae: 0.2290 - val_loss: 0.0826 - val_mae: 0.2226\n",
      "Epoch 244/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0742 - mae: 0.2153 - val_loss: 0.0760 - val_mae: 0.2123\n",
      "Epoch 245/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0757 - mae: 0.2140 - val_loss: 0.0733 - val_mae: 0.2114\n",
      "Epoch 246/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0737 - mae: 0.2126 - val_loss: 0.0887 - val_mae: 0.2283\n",
      "Epoch 247/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0767 - mae: 0.2198 - val_loss: 0.0720 - val_mae: 0.2130\n",
      "Epoch 248/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0788 - mae: 0.2210 - val_loss: 0.0780 - val_mae: 0.2207\n",
      "Epoch 249/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0785 - mae: 0.2205 - val_loss: 0.0825 - val_mae: 0.2215\n",
      "Epoch 250/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0770 - mae: 0.2173 - val_loss: 0.0777 - val_mae: 0.2172\n",
      "Epoch 251/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0745 - mae: 0.2138 - val_loss: 0.0862 - val_mae: 0.2374\n",
      "Epoch 252/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0793 - mae: 0.2222 - val_loss: 0.0797 - val_mae: 0.2282\n",
      "Epoch 253/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0788 - mae: 0.2215 - val_loss: 0.0738 - val_mae: 0.2166\n",
      "Epoch 254/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0812 - mae: 0.2243 - val_loss: 0.0738 - val_mae: 0.2114\n",
      "Epoch 255/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0821 - mae: 0.2241 - val_loss: 0.0814 - val_mae: 0.2249\n",
      "Epoch 256/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0771 - mae: 0.2178 - val_loss: 0.0767 - val_mae: 0.2221\n",
      "Epoch 257/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0750 - mae: 0.2163 - val_loss: 0.0760 - val_mae: 0.2216\n",
      "Epoch 258/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0771 - mae: 0.2197 - val_loss: 0.0799 - val_mae: 0.2199\n",
      "Epoch 259/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0773 - mae: 0.2180 - val_loss: 0.0660 - val_mae: 0.1995\n",
      "Epoch 260/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0727 - mae: 0.2106 - val_loss: 0.0791 - val_mae: 0.2205\n",
      "Epoch 261/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0766 - mae: 0.2177 - val_loss: 0.0723 - val_mae: 0.2079\n",
      "Epoch 262/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0751 - mae: 0.2143 - val_loss: 0.0762 - val_mae: 0.2207\n",
      "Epoch 263/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0804 - mae: 0.2256 - val_loss: 0.0763 - val_mae: 0.2202\n",
      "Epoch 264/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0755 - mae: 0.2162 - val_loss: 0.1010 - val_mae: 0.2504\n",
      "Epoch 265/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0836 - mae: 0.2285 - val_loss: 0.0828 - val_mae: 0.2229\n",
      "Epoch 266/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0893 - mae: 0.2364 - val_loss: 0.0794 - val_mae: 0.2207\n",
      "Epoch 267/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0866 - mae: 0.2312 - val_loss: 0.0883 - val_mae: 0.2381\n",
      "Epoch 268/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0796 - mae: 0.2226 - val_loss: 0.0753 - val_mae: 0.2123\n",
      "Epoch 269/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0761 - mae: 0.2174 - val_loss: 0.0889 - val_mae: 0.2361\n",
      "Epoch 270/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0852 - mae: 0.2284 - val_loss: 0.0848 - val_mae: 0.2289\n",
      "Epoch 271/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0795 - mae: 0.2201 - val_loss: 0.0737 - val_mae: 0.2125\n",
      "Epoch 272/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0733 - mae: 0.2096 - val_loss: 0.0734 - val_mae: 0.2189\n",
      "Epoch 273/2000\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0748 - mae: 0.2143 - val_loss: 0.0753 - val_mae: 0.2154\n",
      "Epoch 274/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0753 - mae: 0.2148 - val_loss: 0.0712 - val_mae: 0.2107\n",
      "Epoch 275/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0749 - mae: 0.2172 - val_loss: 0.0954 - val_mae: 0.2426\n",
      "Epoch 276/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0807 - mae: 0.2209 - val_loss: 0.0780 - val_mae: 0.2203\n",
      "Epoch 277/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0770 - mae: 0.2175 - val_loss: 0.0951 - val_mae: 0.2524\n",
      "Epoch 278/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0880 - mae: 0.2369 - val_loss: 0.0788 - val_mae: 0.2219\n",
      "Epoch 279/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0794 - mae: 0.2216 - val_loss: 0.0760 - val_mae: 0.2112\n",
      "Epoch 280/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.0771 - mae: 0.2177 - val_loss: 0.0878 - val_mae: 0.2398\n",
      "Epoch 281/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0811 - mae: 0.2252 - val_loss: 0.0720 - val_mae: 0.2092\n",
      "Epoch 282/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0799 - mae: 0.2213 - val_loss: 0.0658 - val_mae: 0.1965\n",
      "Epoch 283/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0753 - mae: 0.2129 - val_loss: 0.0709 - val_mae: 0.2087\n",
      "Epoch 284/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0765 - mae: 0.2158 - val_loss: 0.0800 - val_mae: 0.2274\n",
      "Epoch 285/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0854 - mae: 0.2326 - val_loss: 0.0858 - val_mae: 0.2296\n",
      "Epoch 286/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0887 - mae: 0.2352 - val_loss: 0.0803 - val_mae: 0.2215\n",
      "Epoch 287/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0748 - mae: 0.2137 - val_loss: 0.0798 - val_mae: 0.2210\n",
      "Epoch 288/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0761 - mae: 0.2155 - val_loss: 0.0898 - val_mae: 0.2344\n",
      "Epoch 289/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0835 - mae: 0.2270 - val_loss: 0.0735 - val_mae: 0.2121\n",
      "Epoch 290/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0808 - mae: 0.2238 - val_loss: 0.0929 - val_mae: 0.2357\n",
      "Epoch 291/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0867 - mae: 0.2338 - val_loss: 0.0929 - val_mae: 0.2375\n",
      "Epoch 292/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0903 - mae: 0.2392 - val_loss: 0.0700 - val_mae: 0.2076\n",
      "Epoch 293/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0892 - mae: 0.2345 - val_loss: 0.1047 - val_mae: 0.2601\n",
      "Epoch 294/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1056 - mae: 0.2623 - val_loss: 0.1002 - val_mae: 0.2505\n",
      "Epoch 295/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0826 - mae: 0.2262 - val_loss: 0.0833 - val_mae: 0.2287\n",
      "Epoch 296/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0793 - mae: 0.2230 - val_loss: 0.0787 - val_mae: 0.2171\n",
      "Epoch 297/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0862 - mae: 0.2334 - val_loss: 0.0806 - val_mae: 0.2205\n",
      "Epoch 298/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0777 - mae: 0.2200 - val_loss: 0.0752 - val_mae: 0.2199\n",
      "Epoch 299/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0751 - mae: 0.2141 - val_loss: 0.0744 - val_mae: 0.2147\n",
      "Epoch 300/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0811 - mae: 0.2234 - val_loss: 0.0935 - val_mae: 0.2358\n",
      "Epoch 301/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0807 - mae: 0.2238 - val_loss: 0.0808 - val_mae: 0.2228\n",
      "Epoch 302/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0786 - mae: 0.2222 - val_loss: 0.0782 - val_mae: 0.2251\n",
      "Epoch 303/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0814 - mae: 0.2247 - val_loss: 0.0670 - val_mae: 0.2030\n",
      "Epoch 304/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0685 - mae: 0.2039 - val_loss: 0.0723 - val_mae: 0.2063\n",
      "Epoch 305/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0756 - mae: 0.2148 - val_loss: 0.0925 - val_mae: 0.2417\n",
      "Epoch 306/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0884 - mae: 0.2340 - val_loss: 0.0802 - val_mae: 0.2256\n",
      "Epoch 307/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0781 - mae: 0.2207 - val_loss: 0.0823 - val_mae: 0.2278\n",
      "Epoch 308/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0798 - mae: 0.2210 - val_loss: 0.0704 - val_mae: 0.2117\n",
      "Epoch 309/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0714 - mae: 0.2089 - val_loss: 0.0843 - val_mae: 0.2340\n",
      "Epoch 310/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0752 - mae: 0.2150 - val_loss: 0.0734 - val_mae: 0.2106\n",
      "Epoch 311/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0697 - mae: 0.2077 - val_loss: 0.0652 - val_mae: 0.1972\n",
      "Epoch 312/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0694 - mae: 0.2054 - val_loss: 0.0744 - val_mae: 0.2108\n",
      "Epoch 313/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0725 - mae: 0.2117 - val_loss: 0.0721 - val_mae: 0.2072\n",
      "Epoch 314/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0689 - mae: 0.2047 - val_loss: 0.0669 - val_mae: 0.2047\n",
      "Epoch 315/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0724 - mae: 0.2106 - val_loss: 0.0973 - val_mae: 0.2477\n",
      "Epoch 316/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0785 - mae: 0.2215 - val_loss: 0.0920 - val_mae: 0.2458\n",
      "Epoch 317/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0835 - mae: 0.2263 - val_loss: 0.0843 - val_mae: 0.2272\n",
      "Epoch 318/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0780 - mae: 0.2208 - val_loss: 0.0769 - val_mae: 0.2246\n",
      "Epoch 319/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0767 - mae: 0.2175 - val_loss: 0.0663 - val_mae: 0.2023\n",
      "Epoch 320/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0733 - mae: 0.2130 - val_loss: 0.0761 - val_mae: 0.2098\n",
      "Epoch 321/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0722 - mae: 0.2099 - val_loss: 0.0840 - val_mae: 0.2288\n",
      "Epoch 322/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0888 - mae: 0.2363 - val_loss: 0.0768 - val_mae: 0.2202\n",
      "Epoch 323/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0893 - mae: 0.2343 - val_loss: 0.0893 - val_mae: 0.2326\n",
      "Epoch 324/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0861 - mae: 0.2304 - val_loss: 0.0770 - val_mae: 0.2170\n",
      "Epoch 325/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0840 - mae: 0.2261 - val_loss: 0.0951 - val_mae: 0.2401\n",
      "Epoch 326/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0844 - mae: 0.2292 - val_loss: 0.1171 - val_mae: 0.2673\n",
      "Epoch 327/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0916 - mae: 0.2381 - val_loss: 0.0881 - val_mae: 0.2312\n",
      "Epoch 328/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0861 - mae: 0.2328 - val_loss: 0.0785 - val_mae: 0.2171\n",
      "Epoch 329/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0856 - mae: 0.2312 - val_loss: 0.0704 - val_mae: 0.2089\n",
      "Epoch 330/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0805 - mae: 0.2240 - val_loss: 0.0693 - val_mae: 0.2060\n",
      "Epoch 331/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0731 - mae: 0.2140 - val_loss: 0.0822 - val_mae: 0.2264\n",
      "Epoch 332/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0745 - mae: 0.2164 - val_loss: 0.0676 - val_mae: 0.2006\n",
      "Epoch 333/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0706 - mae: 0.2069 - val_loss: 0.0668 - val_mae: 0.2059\n",
      "Epoch 334/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0749 - mae: 0.2156 - val_loss: 0.0785 - val_mae: 0.2235\n",
      "Epoch 335/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0775 - mae: 0.2162 - val_loss: 0.0749 - val_mae: 0.2191\n",
      "Epoch 336/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0792 - mae: 0.2189 - val_loss: 0.0727 - val_mae: 0.2125\n",
      "Epoch 337/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0714 - mae: 0.2102 - val_loss: 0.0745 - val_mae: 0.2132\n",
      "Epoch 338/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0715 - mae: 0.2087 - val_loss: 0.0798 - val_mae: 0.2219\n",
      "Epoch 339/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0752 - mae: 0.2143 - val_loss: 0.0722 - val_mae: 0.2125\n",
      "Epoch 340/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0732 - mae: 0.2112 - val_loss: 0.0847 - val_mae: 0.2324\n",
      "Epoch 341/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0851 - mae: 0.2318 - val_loss: 0.0867 - val_mae: 0.2366\n",
      "Epoch 342/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0896 - mae: 0.2402 - val_loss: 0.0868 - val_mae: 0.2294\n",
      "Epoch 343/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0822 - mae: 0.2260 - val_loss: 0.0825 - val_mae: 0.2293\n",
      "Epoch 344/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0774 - mae: 0.2179 - val_loss: 0.0710 - val_mae: 0.2119\n",
      "Epoch 345/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0792 - mae: 0.2227 - val_loss: 0.0804 - val_mae: 0.2285\n",
      "Epoch 346/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0826 - mae: 0.2280 - val_loss: 0.0898 - val_mae: 0.2349\n",
      "Epoch 347/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0795 - mae: 0.2213 - val_loss: 0.0802 - val_mae: 0.2216\n",
      "Epoch 348/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0810 - mae: 0.2251 - val_loss: 0.1116 - val_mae: 0.2608\n",
      "Epoch 349/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0866 - mae: 0.2333 - val_loss: 0.0738 - val_mae: 0.2123\n",
      "Epoch 350/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0790 - mae: 0.2214 - val_loss: 0.0807 - val_mae: 0.2256\n",
      "Epoch 351/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0777 - mae: 0.2185 - val_loss: 0.0693 - val_mae: 0.2117\n",
      "Epoch 352/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0804 - mae: 0.2244 - val_loss: 0.1068 - val_mae: 0.2567\n",
      "Epoch 353/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0975 - mae: 0.2472 - val_loss: 0.1016 - val_mae: 0.2615\n",
      "Epoch 354/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0907 - mae: 0.2389 - val_loss: 0.0758 - val_mae: 0.2198\n",
      "Epoch 355/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0870 - mae: 0.2320 - val_loss: 0.0968 - val_mae: 0.2390\n",
      "Epoch 356/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0990 - mae: 0.2491 - val_loss: 0.0764 - val_mae: 0.2174\n",
      "Epoch 357/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0821 - mae: 0.2282 - val_loss: 0.0964 - val_mae: 0.2505\n",
      "Epoch 358/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0822 - mae: 0.2283 - val_loss: 0.0726 - val_mae: 0.2087\n",
      "Epoch 359/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0677 - mae: 0.2005 - val_loss: 0.0662 - val_mae: 0.2014\n",
      "Epoch 360/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0646 - mae: 0.1975 - val_loss: 0.0736 - val_mae: 0.2111\n",
      "Epoch 361/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0707 - mae: 0.2071 - val_loss: 0.0745 - val_mae: 0.2111\n",
      "Epoch 362/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0756 - mae: 0.2151 - val_loss: 0.0856 - val_mae: 0.2279\n",
      "Epoch 363/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0792 - mae: 0.2210 - val_loss: 0.0783 - val_mae: 0.2150\n",
      "Epoch 364/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0761 - mae: 0.2163 - val_loss: 0.0765 - val_mae: 0.2163\n",
      "Epoch 365/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0738 - mae: 0.2114 - val_loss: 0.0825 - val_mae: 0.2307\n",
      "Epoch 366/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0707 - mae: 0.2090 - val_loss: 0.0746 - val_mae: 0.2154\n",
      "Epoch 367/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.0798 - mae: 0.2218 - val_loss: 0.0877 - val_mae: 0.2366\n",
      "Epoch 368/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0826 - mae: 0.2277 - val_loss: 0.0854 - val_mae: 0.2273\n",
      "Epoch 369/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.0903 - mae: 0.2400 - val_loss: 0.0914 - val_mae: 0.2434\n",
      "Epoch 370/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0917 - mae: 0.2413 - val_loss: 0.1047 - val_mae: 0.2535\n",
      "Epoch 371/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0983 - mae: 0.2514 - val_loss: 0.0800 - val_mae: 0.2244\n",
      "Epoch 372/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0910 - mae: 0.2397 - val_loss: 0.0856 - val_mae: 0.2319\n",
      "Epoch 373/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0926 - mae: 0.2415 - val_loss: 0.1169 - val_mae: 0.2724\n",
      "Epoch 374/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0958 - mae: 0.2442 - val_loss: 0.0868 - val_mae: 0.2314\n",
      "Epoch 375/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0933 - mae: 0.2438 - val_loss: 0.0958 - val_mae: 0.2401\n",
      "Epoch 376/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0936 - mae: 0.2384 - val_loss: 0.0736 - val_mae: 0.2120\n",
      "Epoch 377/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0888 - mae: 0.2357 - val_loss: 0.0801 - val_mae: 0.2262\n",
      "Epoch 378/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0895 - mae: 0.2343 - val_loss: 0.0856 - val_mae: 0.2380\n",
      "Epoch 379/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0882 - mae: 0.2366 - val_loss: 0.0733 - val_mae: 0.2151\n",
      "Epoch 380/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0782 - mae: 0.2188 - val_loss: 0.0748 - val_mae: 0.2183\n",
      "Epoch 381/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0734 - mae: 0.2123 - val_loss: 0.0738 - val_mae: 0.2118\n",
      "Epoch 382/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0707 - mae: 0.2075 - val_loss: 0.0689 - val_mae: 0.2054\n",
      "Epoch 383/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0742 - mae: 0.2143 - val_loss: 0.1046 - val_mae: 0.2547\n",
      "Epoch 384/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0873 - mae: 0.2330 - val_loss: 0.0756 - val_mae: 0.2164\n",
      "Epoch 385/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0795 - mae: 0.2231 - val_loss: 0.0793 - val_mae: 0.2175\n",
      "Epoch 386/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0842 - mae: 0.2283 - val_loss: 0.0736 - val_mae: 0.2149\n",
      "Epoch 387/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0729 - mae: 0.2122 - val_loss: 0.0765 - val_mae: 0.2222\n",
      "Epoch 388/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0748 - mae: 0.2147 - val_loss: 0.0780 - val_mae: 0.2226\n",
      "Epoch 389/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0844 - mae: 0.2274 - val_loss: 0.0780 - val_mae: 0.2223\n",
      "Epoch 390/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0909 - mae: 0.2353 - val_loss: 0.0915 - val_mae: 0.2471\n",
      "Epoch 391/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0915 - mae: 0.2393 - val_loss: 0.0826 - val_mae: 0.2278\n",
      "Epoch 392/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0788 - mae: 0.2210 - val_loss: 0.0806 - val_mae: 0.2298\n",
      "Epoch 393/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0785 - mae: 0.2212 - val_loss: 0.0723 - val_mae: 0.2072\n",
      "Epoch 394/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0768 - mae: 0.2172 - val_loss: 0.0783 - val_mae: 0.2183\n",
      "Epoch 395/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0779 - mae: 0.2204 - val_loss: 0.0917 - val_mae: 0.2366\n",
      "Epoch 396/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0819 - mae: 0.2286 - val_loss: 0.0748 - val_mae: 0.2119\n",
      "Epoch 397/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0730 - mae: 0.2101 - val_loss: 0.0813 - val_mae: 0.2261\n",
      "Epoch 398/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0759 - mae: 0.2169 - val_loss: 0.0859 - val_mae: 0.2357\n",
      "Epoch 399/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0757 - mae: 0.2175 - val_loss: 0.0830 - val_mae: 0.2317\n",
      "Epoch 400/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0807 - mae: 0.2218 - val_loss: 0.0827 - val_mae: 0.2195\n",
      "Epoch 401/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0772 - mae: 0.2179 - val_loss: 0.0912 - val_mae: 0.2432\n",
      "Epoch 402/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0797 - mae: 0.2221 - val_loss: 0.1132 - val_mae: 0.2577\n",
      "Epoch 403/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0909 - mae: 0.2389 - val_loss: 0.0826 - val_mae: 0.2320\n",
      "Epoch 404/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0825 - mae: 0.2264 - val_loss: 0.0903 - val_mae: 0.2415\n",
      "Epoch 405/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0892 - mae: 0.2338 - val_loss: 0.0712 - val_mae: 0.2071\n",
      "Epoch 406/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0720 - mae: 0.2093 - val_loss: 0.0817 - val_mae: 0.2322\n",
      "Epoch 407/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0809 - mae: 0.2248 - val_loss: 0.1001 - val_mae: 0.2387\n",
      "Epoch 408/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0854 - mae: 0.2271 - val_loss: 0.0932 - val_mae: 0.2387\n",
      "Epoch 409/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0880 - mae: 0.2346 - val_loss: 0.0806 - val_mae: 0.2224\n",
      "Epoch 410/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0845 - mae: 0.2278 - val_loss: 0.0949 - val_mae: 0.2490\n",
      "Epoch 411/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0925 - mae: 0.2403 - val_loss: 0.0957 - val_mae: 0.2497\n",
      "Epoch 412/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0847 - mae: 0.2307 - val_loss: 0.0832 - val_mae: 0.2314\n",
      "Epoch 413/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0846 - mae: 0.2306 - val_loss: 0.0822 - val_mae: 0.2285\n",
      "Epoch 414/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0855 - mae: 0.2303 - val_loss: 0.0994 - val_mae: 0.2535\n",
      "Epoch 415/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0941 - mae: 0.2454 - val_loss: 0.0845 - val_mae: 0.2285\n",
      "Epoch 416/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0834 - mae: 0.2285 - val_loss: 0.1347 - val_mae: 0.2852\n",
      "Epoch 417/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1054 - mae: 0.2594 - val_loss: 0.0953 - val_mae: 0.2521\n",
      "Epoch 418/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0953 - mae: 0.2462 - val_loss: 0.0761 - val_mae: 0.2202\n",
      "Epoch 419/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0860 - mae: 0.2292 - val_loss: 0.0760 - val_mae: 0.2124\n",
      "Epoch 420/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0865 - mae: 0.2302 - val_loss: 0.0783 - val_mae: 0.2136\n",
      "Epoch 421/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0842 - mae: 0.2277 - val_loss: 0.0877 - val_mae: 0.2393\n",
      "Epoch 422/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0815 - mae: 0.2275 - val_loss: 0.1055 - val_mae: 0.2635\n",
      "Epoch 423/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0900 - mae: 0.2388 - val_loss: 0.0848 - val_mae: 0.2310\n",
      "Epoch 424/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0907 - mae: 0.2351 - val_loss: 0.0823 - val_mae: 0.2264\n",
      "Epoch 425/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0862 - mae: 0.2303 - val_loss: 0.0814 - val_mae: 0.2237\n",
      "Epoch 426/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0886 - mae: 0.2320 - val_loss: 0.0786 - val_mae: 0.2224\n",
      "Epoch 427/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0866 - mae: 0.2311 - val_loss: 0.0800 - val_mae: 0.2307\n",
      "Epoch 428/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0929 - mae: 0.2427 - val_loss: 0.0757 - val_mae: 0.2167\n",
      "Epoch 429/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0897 - mae: 0.2353 - val_loss: 0.0797 - val_mae: 0.2238\n",
      "Epoch 430/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0811 - mae: 0.2251 - val_loss: 0.1254 - val_mae: 0.2747\n",
      "Epoch 431/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0945 - mae: 0.2417 - val_loss: 0.1006 - val_mae: 0.2563\n",
      "Epoch 432/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1047 - mae: 0.2593 - val_loss: 0.0848 - val_mae: 0.2291\n",
      "Epoch 433/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0986 - mae: 0.2484 - val_loss: 0.1163 - val_mae: 0.2724\n",
      "Epoch 434/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1001 - mae: 0.2516 - val_loss: 0.0776 - val_mae: 0.2177\n",
      "Epoch 435/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0749 - mae: 0.2141 - val_loss: 0.0795 - val_mae: 0.2188\n",
      "Epoch 436/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0768 - mae: 0.2192 - val_loss: 0.1112 - val_mae: 0.2605\n",
      "Epoch 437/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0850 - mae: 0.2299 - val_loss: 0.0881 - val_mae: 0.2385\n",
      "Epoch 438/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0829 - mae: 0.2269 - val_loss: 0.1047 - val_mae: 0.2530\n",
      "Epoch 439/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0898 - mae: 0.2344 - val_loss: 0.0921 - val_mae: 0.2403\n",
      "Epoch 440/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0971 - mae: 0.2448 - val_loss: 0.0898 - val_mae: 0.2426\n",
      "Epoch 441/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0995 - mae: 0.2508 - val_loss: 0.0892 - val_mae: 0.2337\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0912 - mae: 0.2380 - val_loss: 0.0791 - val_mae: 0.2201\n",
      "Epoch 443/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0831 - mae: 0.2267 - val_loss: 0.0822 - val_mae: 0.2254\n",
      "Epoch 444/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0795 - mae: 0.2218 - val_loss: 0.0729 - val_mae: 0.2090\n",
      "Epoch 445/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0792 - mae: 0.2213 - val_loss: 0.0745 - val_mae: 0.2118\n",
      "Epoch 446/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0765 - mae: 0.2181 - val_loss: 0.0824 - val_mae: 0.2275\n",
      "Epoch 447/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0783 - mae: 0.2218 - val_loss: 0.0736 - val_mae: 0.2175\n",
      "Epoch 448/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0831 - mae: 0.2291 - val_loss: 0.1027 - val_mae: 0.2532\n",
      "Epoch 449/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0926 - mae: 0.2430 - val_loss: 0.0847 - val_mae: 0.2291\n",
      "Epoch 450/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0860 - mae: 0.2282 - val_loss: 0.0726 - val_mae: 0.2155\n",
      "Epoch 451/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0773 - mae: 0.2184 - val_loss: 0.0748 - val_mae: 0.2126\n",
      "Epoch 452/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0760 - mae: 0.2156 - val_loss: 0.0839 - val_mae: 0.2290\n",
      "Epoch 453/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0809 - mae: 0.2236 - val_loss: 0.1010 - val_mae: 0.2534\n",
      "Epoch 454/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0927 - mae: 0.2432 - val_loss: 0.0964 - val_mae: 0.2428\n",
      "Epoch 455/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0814 - mae: 0.2248 - val_loss: 0.1304 - val_mae: 0.2931\n",
      "Epoch 456/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1117 - mae: 0.2683 - val_loss: 0.0999 - val_mae: 0.2492\n",
      "Epoch 457/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0976 - mae: 0.2503 - val_loss: 0.0865 - val_mae: 0.2371\n",
      "Epoch 458/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0822 - mae: 0.2250 - val_loss: 0.0791 - val_mae: 0.2192\n",
      "Epoch 459/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0754 - mae: 0.2143 - val_loss: 0.0733 - val_mae: 0.2084\n",
      "Epoch 460/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0788 - mae: 0.2208 - val_loss: 0.0719 - val_mae: 0.2097\n",
      "Epoch 461/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0832 - mae: 0.2273 - val_loss: 0.0804 - val_mae: 0.2211\n",
      "Epoch 462/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0935 - mae: 0.2417 - val_loss: 0.0880 - val_mae: 0.2370\n",
      "Epoch 463/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0922 - mae: 0.2420 - val_loss: 0.1063 - val_mae: 0.2671\n",
      "Epoch 464/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1041 - mae: 0.2565 - val_loss: 0.0958 - val_mae: 0.2516\n",
      "Epoch 465/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1169 - mae: 0.2756 - val_loss: 0.1714 - val_mae: 0.3401\n",
      "Epoch 466/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1150 - mae: 0.2700 - val_loss: 0.0863 - val_mae: 0.2365\n",
      "Epoch 467/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0934 - mae: 0.2432 - val_loss: 0.0842 - val_mae: 0.2347\n",
      "Epoch 468/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0869 - mae: 0.2354 - val_loss: 0.1296 - val_mae: 0.2775\n",
      "Epoch 469/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0933 - mae: 0.2399 - val_loss: 0.0918 - val_mae: 0.2424\n",
      "Epoch 470/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0864 - mae: 0.2302 - val_loss: 0.1018 - val_mae: 0.2506\n",
      "Epoch 471/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0909 - mae: 0.2414 - val_loss: 0.0924 - val_mae: 0.2358\n",
      "Epoch 472/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0913 - mae: 0.2375 - val_loss: 0.0843 - val_mae: 0.2279\n",
      "Epoch 473/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0852 - mae: 0.2329 - val_loss: 0.0852 - val_mae: 0.2279\n",
      "Epoch 474/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0850 - mae: 0.2290 - val_loss: 0.0970 - val_mae: 0.2440\n",
      "Epoch 475/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0951 - mae: 0.2445 - val_loss: 0.1255 - val_mae: 0.2837\n",
      "Epoch 476/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0966 - mae: 0.2471 - val_loss: 0.1121 - val_mae: 0.2586\n",
      "Epoch 477/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0936 - mae: 0.2428 - val_loss: 0.1241 - val_mae: 0.2908\n",
      "Epoch 478/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1119 - mae: 0.2679 - val_loss: 0.1007 - val_mae: 0.2553\n",
      "Epoch 479/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1155 - mae: 0.2685 - val_loss: 0.1001 - val_mae: 0.2517\n",
      "Epoch 480/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0934 - mae: 0.2387 - val_loss: 0.1016 - val_mae: 0.2438\n",
      "Epoch 481/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0998 - mae: 0.2501 - val_loss: 0.1233 - val_mae: 0.2831\n",
      "Epoch 482/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1030 - mae: 0.2559 - val_loss: 0.0985 - val_mae: 0.2558\n",
      "Epoch 483/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1101 - mae: 0.2628 - val_loss: 0.1018 - val_mae: 0.2510\n",
      "Epoch 484/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0991 - mae: 0.2482 - val_loss: 0.1045 - val_mae: 0.2635\n",
      "Epoch 485/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1410 - mae: 0.3083 - val_loss: 0.5092 - val_mae: 0.6476\n",
      "Epoch 486/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2358 - mae: 0.3875 - val_loss: 0.2113 - val_mae: 0.3753\n",
      "Epoch 487/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1966 - mae: 0.3580 - val_loss: 0.1599 - val_mae: 0.3285\n",
      "Epoch 488/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.3767 - mae: 0.4914 - val_loss: 0.5831 - val_mae: 0.6517\n",
      "Epoch 489/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.3677 - mae: 0.4918 - val_loss: 0.2858 - val_mae: 0.4323\n",
      "Epoch 490/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2714 - mae: 0.4265 - val_loss: 0.2282 - val_mae: 0.3904\n",
      "Epoch 491/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2351 - mae: 0.3958 - val_loss: 0.2141 - val_mae: 0.3779\n",
      "Epoch 492/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1899 - mae: 0.3542 - val_loss: 0.2122 - val_mae: 0.3756\n",
      "Epoch 493/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1839 - mae: 0.3463 - val_loss: 0.1733 - val_mae: 0.3397\n",
      "Epoch 494/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1710 - mae: 0.3324 - val_loss: 0.1318 - val_mae: 0.2959\n",
      "Epoch 495/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1200 - mae: 0.2773 - val_loss: 0.1341 - val_mae: 0.2957\n",
      "Epoch 496/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1283 - mae: 0.2848 - val_loss: 0.1168 - val_mae: 0.2806\n",
      "Epoch 497/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1016 - mae: 0.2535 - val_loss: 0.1208 - val_mae: 0.2742\n",
      "Epoch 498/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1046 - mae: 0.2562 - val_loss: 0.0801 - val_mae: 0.2289\n",
      "Epoch 499/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0947 - mae: 0.2444 - val_loss: 0.0954 - val_mae: 0.2484\n",
      "Epoch 500/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1028 - mae: 0.2502 - val_loss: 0.0951 - val_mae: 0.2399\n",
      "Epoch 501/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0941 - mae: 0.2425 - val_loss: 0.1432 - val_mae: 0.3028\n",
      "Epoch 502/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1298 - mae: 0.2852 - val_loss: 0.1594 - val_mae: 0.3233\n",
      "Epoch 503/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1435 - mae: 0.2988 - val_loss: 0.1192 - val_mae: 0.2726\n",
      "Epoch 504/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1223 - mae: 0.2774 - val_loss: 0.1120 - val_mae: 0.2752\n",
      "Epoch 505/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1177 - mae: 0.2752 - val_loss: 0.1233 - val_mae: 0.2801\n",
      "Epoch 506/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1073 - mae: 0.2576 - val_loss: 0.1030 - val_mae: 0.2590\n",
      "Epoch 507/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0911 - mae: 0.2355 - val_loss: 0.1015 - val_mae: 0.2581\n",
      "Epoch 508/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1226 - mae: 0.2787 - val_loss: 0.1429 - val_mae: 0.3096\n",
      "Epoch 509/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1059 - mae: 0.2594 - val_loss: 0.1094 - val_mae: 0.2699\n",
      "Epoch 510/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1389 - mae: 0.3031 - val_loss: 0.2491 - val_mae: 0.4244\n",
      "Epoch 511/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1594 - mae: 0.3183 - val_loss: 0.1129 - val_mae: 0.2720\n",
      "Epoch 512/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1322 - mae: 0.2933 - val_loss: 0.1220 - val_mae: 0.2833\n",
      "Epoch 513/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1152 - mae: 0.2701 - val_loss: 0.1126 - val_mae: 0.2653\n",
      "Epoch 514/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1398 - mae: 0.3024 - val_loss: 0.1679 - val_mae: 0.3387\n",
      "Epoch 515/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1744 - mae: 0.3391 - val_loss: 0.2145 - val_mae: 0.3968\n",
      "Epoch 516/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2025 - mae: 0.3692 - val_loss: 0.2083 - val_mae: 0.3764\n",
      "Epoch 517/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1835 - mae: 0.3438 - val_loss: 0.1642 - val_mae: 0.3316\n",
      "Epoch 518/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1315 - mae: 0.2901 - val_loss: 0.1101 - val_mae: 0.2664\n",
      "Epoch 519/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1004 - mae: 0.2494 - val_loss: 0.0884 - val_mae: 0.2343\n",
      "Epoch 520/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1026 - mae: 0.2572 - val_loss: 0.1038 - val_mae: 0.2607\n",
      "Epoch 521/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0992 - mae: 0.2507 - val_loss: 0.0829 - val_mae: 0.2277\n",
      "Epoch 522/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0833 - mae: 0.2268 - val_loss: 0.0907 - val_mae: 0.2378\n",
      "Epoch 523/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0835 - mae: 0.2309 - val_loss: 0.0732 - val_mae: 0.2162\n",
      "Epoch 524/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0884 - mae: 0.2380 - val_loss: 0.0884 - val_mae: 0.2297\n",
      "Epoch 525/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0880 - mae: 0.2343 - val_loss: 0.0785 - val_mae: 0.2230\n",
      "Epoch 526/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0920 - mae: 0.2367 - val_loss: 0.1411 - val_mae: 0.3015\n",
      "Epoch 527/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1176 - mae: 0.2686 - val_loss: 0.1127 - val_mae: 0.2618\n",
      "Epoch 528/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1116 - mae: 0.2636 - val_loss: 0.0956 - val_mae: 0.2464\n",
      "Epoch 529/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1047 - mae: 0.2586 - val_loss: 0.1797 - val_mae: 0.3399\n",
      "Epoch 530/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1302 - mae: 0.2924 - val_loss: 0.1644 - val_mae: 0.3446\n",
      "Epoch 531/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1232 - mae: 0.2822 - val_loss: 0.1051 - val_mae: 0.2558\n",
      "Epoch 532/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1011 - mae: 0.2550 - val_loss: 0.1068 - val_mae: 0.2615\n",
      "Epoch 533/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1021 - mae: 0.2519 - val_loss: 0.1245 - val_mae: 0.2853\n",
      "Epoch 534/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1345 - mae: 0.2953 - val_loss: 0.1541 - val_mae: 0.3125\n",
      "Epoch 535/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1343 - mae: 0.2903 - val_loss: 0.1302 - val_mae: 0.2911\n",
      "Epoch 536/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1288 - mae: 0.2874 - val_loss: 0.2136 - val_mae: 0.3718\n",
      "Epoch 537/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1523 - mae: 0.3127 - val_loss: 0.1127 - val_mae: 0.2738\n",
      "Epoch 538/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1285 - mae: 0.2868 - val_loss: 0.0879 - val_mae: 0.2361\n",
      "Epoch 539/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1181 - mae: 0.2685 - val_loss: 0.2318 - val_mae: 0.3932\n",
      "Epoch 540/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.2095 - mae: 0.3704 - val_loss: 0.1481 - val_mae: 0.3110\n",
      "Epoch 541/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1994 - mae: 0.3615 - val_loss: 0.1518 - val_mae: 0.3211\n",
      "Epoch 542/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1700 - mae: 0.3362 - val_loss: 0.1478 - val_mae: 0.3189\n",
      "Epoch 543/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1501 - mae: 0.3184 - val_loss: 0.1278 - val_mae: 0.2947\n",
      "Epoch 544/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1275 - mae: 0.2896 - val_loss: 0.1406 - val_mae: 0.3080\n",
      "Epoch 545/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1282 - mae: 0.2904 - val_loss: 0.1543 - val_mae: 0.3093\n",
      "Epoch 546/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1443 - mae: 0.3037 - val_loss: 0.1048 - val_mae: 0.2627\n",
      "Epoch 547/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1153 - mae: 0.2720 - val_loss: 0.0775 - val_mae: 0.2216\n",
      "Epoch 548/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0908 - mae: 0.2393 - val_loss: 0.0854 - val_mae: 0.2337\n",
      "Epoch 549/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0872 - mae: 0.2324 - val_loss: 0.1157 - val_mae: 0.2687\n",
      "Epoch 550/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1038 - mae: 0.2594 - val_loss: 0.1023 - val_mae: 0.2628\n",
      "Epoch 551/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0951 - mae: 0.2459 - val_loss: 0.0818 - val_mae: 0.2279\n",
      "Epoch 552/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1360 - mae: 0.3012 - val_loss: 0.1025 - val_mae: 0.2579\n",
      "Epoch 553/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1151 - mae: 0.2719 - val_loss: 0.1310 - val_mae: 0.2940\n",
      "Epoch 554/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1284 - mae: 0.2866 - val_loss: 0.2088 - val_mae: 0.3829\n",
      "Epoch 555/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1484 - mae: 0.3053 - val_loss: 0.0986 - val_mae: 0.2502\n",
      "Epoch 556/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1426 - mae: 0.3056 - val_loss: 0.2125 - val_mae: 0.3784\n",
      "Epoch 557/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1703 - mae: 0.3356 - val_loss: 0.1830 - val_mae: 0.3511\n",
      "Epoch 558/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1338 - mae: 0.2916 - val_loss: 0.1087 - val_mae: 0.2610\n",
      "Epoch 559/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1423 - mae: 0.3029 - val_loss: 0.1361 - val_mae: 0.2987\n",
      "Epoch 560/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1225 - mae: 0.2816 - val_loss: 0.1144 - val_mae: 0.2778\n",
      "Epoch 561/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1680 - mae: 0.3336 - val_loss: 0.1177 - val_mae: 0.2765\n",
      "Epoch 562/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1079 - mae: 0.2629 - val_loss: 0.1442 - val_mae: 0.3048\n",
      "Epoch 563/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1078 - mae: 0.2608 - val_loss: 0.0984 - val_mae: 0.2507\n",
      "Epoch 564/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0970 - mae: 0.2445 - val_loss: 0.0952 - val_mae: 0.2494\n",
      "Epoch 565/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1019 - mae: 0.2553 - val_loss: 0.0756 - val_mae: 0.2145\n",
      "Epoch 566/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0899 - mae: 0.2328 - val_loss: 0.0956 - val_mae: 0.2400\n",
      "Epoch 567/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0890 - mae: 0.2353 - val_loss: 0.1552 - val_mae: 0.3204\n",
      "Epoch 568/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1231 - mae: 0.2828 - val_loss: 0.1510 - val_mae: 0.3280\n",
      "Epoch 569/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1334 - mae: 0.2932 - val_loss: 0.2864 - val_mae: 0.4560\n",
      "Epoch 570/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2054 - mae: 0.3703 - val_loss: 0.7211 - val_mae: 0.7643\n",
      "Epoch 571/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.4259 - mae: 0.5314 - val_loss: 0.1720 - val_mae: 0.3385\n",
      "Epoch 572/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2174 - mae: 0.3758 - val_loss: 0.2845 - val_mae: 0.4292\n",
      "Epoch 573/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.2793 - mae: 0.4350 - val_loss: 0.1909 - val_mae: 0.3636\n",
      "Epoch 574/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1956 - mae: 0.3639 - val_loss: 0.2122 - val_mae: 0.3754\n",
      "Epoch 575/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1979 - mae: 0.3605 - val_loss: 0.1981 - val_mae: 0.3630\n",
      "Epoch 576/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2002 - mae: 0.3666 - val_loss: 0.1799 - val_mae: 0.3514\n",
      "Epoch 577/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1831 - mae: 0.3537 - val_loss: 0.1690 - val_mae: 0.3398\n",
      "Epoch 578/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1789 - mae: 0.3503 - val_loss: 0.2072 - val_mae: 0.3730\n",
      "Epoch 579/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1970 - mae: 0.3623 - val_loss: 0.1637 - val_mae: 0.3360\n",
      "Epoch 580/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1781 - mae: 0.3458 - val_loss: 0.1521 - val_mae: 0.3239\n",
      "Epoch 581/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1880 - mae: 0.3520 - val_loss: 0.1832 - val_mae: 0.3491\n",
      "Epoch 582/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1661 - mae: 0.3309 - val_loss: 0.1674 - val_mae: 0.3376\n",
      "Epoch 583/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1763 - mae: 0.3440 - val_loss: 0.2644 - val_mae: 0.4270\n",
      "Epoch 584/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2123 - mae: 0.3785 - val_loss: 0.2393 - val_mae: 0.3924\n",
      "Epoch 585/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2493 - mae: 0.4118 - val_loss: 0.1774 - val_mae: 0.3478\n",
      "Epoch 586/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1792 - mae: 0.3474 - val_loss: 0.2129 - val_mae: 0.3759\n",
      "Epoch 587/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2189 - mae: 0.3785 - val_loss: 0.3686 - val_mae: 0.4979\n",
      "Epoch 588/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.3003 - mae: 0.4438 - val_loss: 0.2980 - val_mae: 0.4414\n",
      "Epoch 589/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2703 - mae: 0.4211 - val_loss: 0.3941 - val_mae: 0.5113\n",
      "Epoch 590/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.3064 - mae: 0.4536 - val_loss: 0.2149 - val_mae: 0.3815\n",
      "Epoch 591/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2336 - mae: 0.3970 - val_loss: 0.2312 - val_mae: 0.3879\n",
      "Epoch 592/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2452 - mae: 0.4014 - val_loss: 0.2374 - val_mae: 0.3896\n",
      "Epoch 593/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2299 - mae: 0.3898 - val_loss: 0.2439 - val_mae: 0.3948\n",
      "Epoch 594/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2954 - mae: 0.4421 - val_loss: 0.2789 - val_mae: 0.4242\n",
      "Epoch 595/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2452 - mae: 0.4000 - val_loss: 0.2107 - val_mae: 0.3772\n",
      "Epoch 596/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2100 - mae: 0.3783 - val_loss: 0.2171 - val_mae: 0.3850\n",
      "Epoch 597/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2161 - mae: 0.3793 - val_loss: 0.2852 - val_mae: 0.4305\n",
      "Epoch 598/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2118 - mae: 0.3719 - val_loss: 0.1967 - val_mae: 0.3675\n",
      "Epoch 599/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1935 - mae: 0.3626 - val_loss: 0.1931 - val_mae: 0.3573\n",
      "Epoch 600/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2026 - mae: 0.3611 - val_loss: 0.1788 - val_mae: 0.3456\n",
      "Epoch 601/2000\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.1864 - mae: 0.3530 - val_loss: 0.2248 - val_mae: 0.3870\n",
      "Epoch 602/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2030 - mae: 0.3695 - val_loss: 0.1752 - val_mae: 0.3440\n",
      "Epoch 603/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1797 - mae: 0.3472 - val_loss: 0.2107 - val_mae: 0.3763\n",
      "Epoch 604/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1870 - mae: 0.3549 - val_loss: 0.2681 - val_mae: 0.4159\n",
      "Epoch 605/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2765 - mae: 0.4308 - val_loss: 0.3299 - val_mae: 0.4697\n",
      "Epoch 606/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2596 - mae: 0.4123 - val_loss: 0.2330 - val_mae: 0.3929\n",
      "Epoch 607/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2515 - mae: 0.4074 - val_loss: 0.2500 - val_mae: 0.4068\n",
      "Epoch 608/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2190 - mae: 0.3792 - val_loss: 0.2535 - val_mae: 0.4044\n",
      "Epoch 609/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2357 - mae: 0.3959 - val_loss: 0.1875 - val_mae: 0.3533\n",
      "Epoch 610/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2438 - mae: 0.3993 - val_loss: 0.2056 - val_mae: 0.3709\n",
      "Epoch 611/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2471 - mae: 0.4062 - val_loss: 0.2463 - val_mae: 0.4009\n",
      "Epoch 612/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2074 - mae: 0.3668 - val_loss: 0.1811 - val_mae: 0.3488\n",
      "Epoch 613/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1777 - mae: 0.3461 - val_loss: 0.1873 - val_mae: 0.3516\n",
      "Epoch 614/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2186 - mae: 0.3794 - val_loss: 0.1846 - val_mae: 0.3522\n",
      "Epoch 615/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2370 - mae: 0.3957 - val_loss: 0.2214 - val_mae: 0.3829\n",
      "Epoch 616/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.3002 - mae: 0.4463 - val_loss: 0.2231 - val_mae: 0.3867\n",
      "Epoch 617/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2532 - mae: 0.4095 - val_loss: 0.2042 - val_mae: 0.3716\n",
      "Epoch 618/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2012 - mae: 0.3666 - val_loss: 0.2446 - val_mae: 0.4031\n",
      "Epoch 619/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1995 - mae: 0.3637 - val_loss: 0.1710 - val_mae: 0.3439\n",
      "Epoch 620/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2014 - mae: 0.3671 - val_loss: 0.1941 - val_mae: 0.3608\n",
      "Epoch 621/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2417 - mae: 0.4000 - val_loss: 0.1995 - val_mae: 0.3658\n",
      "Epoch 622/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2086 - mae: 0.3727 - val_loss: 0.1743 - val_mae: 0.3443\n",
      "Epoch 623/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1820 - mae: 0.3462 - val_loss: 0.1641 - val_mae: 0.3348\n",
      "Epoch 624/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1713 - mae: 0.3368 - val_loss: 0.1808 - val_mae: 0.3476\n",
      "Epoch 625/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1817 - mae: 0.3500 - val_loss: 0.1495 - val_mae: 0.3172\n",
      "Epoch 626/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1575 - mae: 0.3220 - val_loss: 0.1689 - val_mae: 0.3293\n",
      "Epoch 627/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1790 - mae: 0.3433 - val_loss: 0.1433 - val_mae: 0.3128\n",
      "Epoch 628/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1899 - mae: 0.3477 - val_loss: 0.3709 - val_mae: 0.5129\n",
      "Epoch 629/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2442 - mae: 0.4008 - val_loss: 0.1476 - val_mae: 0.3165\n",
      "Epoch 630/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1517 - mae: 0.3147 - val_loss: 0.1342 - val_mae: 0.3028\n",
      "Epoch 631/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.1454 - mae: 0.3093 - val_loss: 0.1227 - val_mae: 0.2837\n",
      "Epoch 632/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.1442 - mae: 0.3049 - val_loss: 0.1387 - val_mae: 0.3004\n",
      "Epoch 633/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1466 - mae: 0.3096 - val_loss: 0.1351 - val_mae: 0.2999\n",
      "Epoch 634/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1299 - mae: 0.2887 - val_loss: 0.1166 - val_mae: 0.2758\n",
      "Epoch 635/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1249 - mae: 0.2830 - val_loss: 0.1535 - val_mae: 0.3192\n",
      "Epoch 636/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1204 - mae: 0.2778 - val_loss: 0.1079 - val_mae: 0.2592\n",
      "Epoch 637/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1060 - mae: 0.2578 - val_loss: 0.1291 - val_mae: 0.2916\n",
      "Epoch 638/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1209 - mae: 0.2787 - val_loss: 0.1498 - val_mae: 0.3143\n",
      "Epoch 639/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1546 - mae: 0.3159 - val_loss: 0.1092 - val_mae: 0.2676\n",
      "Epoch 640/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1240 - mae: 0.2831 - val_loss: 0.1203 - val_mae: 0.2807\n",
      "Epoch 641/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.1353 - mae: 0.2967 - val_loss: 0.1839 - val_mae: 0.3504\n",
      "Epoch 642/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1228 - mae: 0.2839 - val_loss: 0.1075 - val_mae: 0.2615\n",
      "Epoch 643/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1118 - mae: 0.2666 - val_loss: 0.1109 - val_mae: 0.2710\n",
      "Epoch 644/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1189 - mae: 0.2744 - val_loss: 0.1407 - val_mae: 0.3045\n",
      "Epoch 645/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1315 - mae: 0.2928 - val_loss: 0.1349 - val_mae: 0.2975\n",
      "Epoch 646/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1072 - mae: 0.2598 - val_loss: 0.0978 - val_mae: 0.2531\n",
      "Epoch 647/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0916 - mae: 0.2396 - val_loss: 0.0878 - val_mae: 0.2350\n",
      "Epoch 648/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0968 - mae: 0.2461 - val_loss: 0.1000 - val_mae: 0.2548\n",
      "Epoch 649/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1148 - mae: 0.2708 - val_loss: 0.1022 - val_mae: 0.2581\n",
      "Epoch 650/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1143 - mae: 0.2698 - val_loss: 0.0980 - val_mae: 0.2477\n",
      "Epoch 651/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1251 - mae: 0.2835 - val_loss: 0.1208 - val_mae: 0.2803\n",
      "Epoch 652/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1436 - mae: 0.3069 - val_loss: 0.0925 - val_mae: 0.2430\n",
      "Epoch 653/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1382 - mae: 0.2979 - val_loss: 0.0799 - val_mae: 0.2224\n",
      "Epoch 654/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1174 - mae: 0.2729 - val_loss: 0.1761 - val_mae: 0.3421\n",
      "Epoch 655/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1244 - mae: 0.2823 - val_loss: 0.0959 - val_mae: 0.2484\n",
      "Epoch 656/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0991 - mae: 0.2491 - val_loss: 0.0948 - val_mae: 0.2461\n",
      "Epoch 657/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0903 - mae: 0.2377 - val_loss: 0.0880 - val_mae: 0.2388\n",
      "Epoch 658/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0999 - mae: 0.2518 - val_loss: 0.0890 - val_mae: 0.2362\n",
      "Epoch 659/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0858 - mae: 0.2307 - val_loss: 0.0884 - val_mae: 0.2335\n",
      "Epoch 660/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0953 - mae: 0.2451 - val_loss: 0.0990 - val_mae: 0.2513\n",
      "Epoch 661/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1261 - mae: 0.2845 - val_loss: 0.2045 - val_mae: 0.3679\n",
      "Epoch 662/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2989 - mae: 0.4552 - val_loss: 0.1752 - val_mae: 0.3450\n",
      "Epoch 663/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.2523 - mae: 0.4021 - val_loss: 0.1579 - val_mae: 0.3305\n",
      "Epoch 664/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1660 - mae: 0.3329 - val_loss: 0.1683 - val_mae: 0.3381\n",
      "Epoch 665/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1624 - mae: 0.3309 - val_loss: 0.1391 - val_mae: 0.3031\n",
      "Epoch 666/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1408 - mae: 0.3034 - val_loss: 0.2197 - val_mae: 0.3913\n",
      "Epoch 667/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1802 - mae: 0.3452 - val_loss: 0.1300 - val_mae: 0.2962\n",
      "Epoch 668/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1884 - mae: 0.3500 - val_loss: 0.2519 - val_mae: 0.4093\n",
      "Epoch 669/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1843 - mae: 0.3421 - val_loss: 0.1852 - val_mae: 0.3481\n",
      "Epoch 670/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1739 - mae: 0.3343 - val_loss: 0.1527 - val_mae: 0.3173\n",
      "Epoch 671/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1527 - mae: 0.3147 - val_loss: 0.1142 - val_mae: 0.2704\n",
      "Epoch 672/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1381 - mae: 0.2942 - val_loss: 0.2000 - val_mae: 0.3700\n",
      "Epoch 673/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1697 - mae: 0.3295 - val_loss: 0.2477 - val_mae: 0.4187\n",
      "Epoch 674/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1744 - mae: 0.3355 - val_loss: 0.1574 - val_mae: 0.3283\n",
      "Epoch 675/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1388 - mae: 0.2988 - val_loss: 0.1134 - val_mae: 0.2684\n",
      "Epoch 676/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1464 - mae: 0.3063 - val_loss: 0.1271 - val_mae: 0.2864\n",
      "Epoch 677/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1174 - mae: 0.2709 - val_loss: 0.1440 - val_mae: 0.3090\n",
      "Epoch 678/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1178 - mae: 0.2775 - val_loss: 0.1147 - val_mae: 0.2649\n",
      "Epoch 679/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1176 - mae: 0.2736 - val_loss: 0.1001 - val_mae: 0.2552\n",
      "Epoch 680/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1292 - mae: 0.2873 - val_loss: 0.1409 - val_mae: 0.3060\n",
      "Epoch 681/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1827 - mae: 0.3499 - val_loss: 0.1696 - val_mae: 0.3395\n",
      "Epoch 682/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1756 - mae: 0.3395 - val_loss: 0.2509 - val_mae: 0.4159\n",
      "Epoch 683/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1989 - mae: 0.3570 - val_loss: 0.1627 - val_mae: 0.3308\n",
      "Epoch 684/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1817 - mae: 0.3477 - val_loss: 0.2092 - val_mae: 0.3727\n",
      "Epoch 685/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2127 - mae: 0.3768 - val_loss: 0.2621 - val_mae: 0.4161\n",
      "Epoch 686/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2052 - mae: 0.3663 - val_loss: 0.2692 - val_mae: 0.4188\n",
      "Epoch 687/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2383 - mae: 0.3950 - val_loss: 0.2679 - val_mae: 0.4206\n",
      "Epoch 688/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2506 - mae: 0.4074 - val_loss: 0.1607 - val_mae: 0.3328\n",
      "Epoch 689/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1785 - mae: 0.3464 - val_loss: 0.1746 - val_mae: 0.3434\n",
      "Epoch 690/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1847 - mae: 0.3495 - val_loss: 0.1755 - val_mae: 0.3451\n",
      "Epoch 691/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1621 - mae: 0.3274 - val_loss: 0.1417 - val_mae: 0.3069\n",
      "Epoch 692/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2142 - mae: 0.3755 - val_loss: 0.3716 - val_mae: 0.5169\n",
      "Epoch 693/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2628 - mae: 0.4182 - val_loss: 0.1986 - val_mae: 0.3628\n",
      "Epoch 694/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2420 - mae: 0.3977 - val_loss: 0.1715 - val_mae: 0.3428\n",
      "Epoch 695/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2084 - mae: 0.3684 - val_loss: 0.1825 - val_mae: 0.3513\n",
      "Epoch 696/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2020 - mae: 0.3677 - val_loss: 0.2294 - val_mae: 0.3883\n",
      "Epoch 697/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2112 - mae: 0.3762 - val_loss: 0.1951 - val_mae: 0.3622\n",
      "Epoch 698/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1825 - mae: 0.3500 - val_loss: 0.1859 - val_mae: 0.3511\n",
      "Epoch 699/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1726 - mae: 0.3380 - val_loss: 0.1776 - val_mae: 0.3430\n",
      "Epoch 700/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1890 - mae: 0.3505 - val_loss: 0.1572 - val_mae: 0.3228\n",
      "Epoch 701/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1666 - mae: 0.3304 - val_loss: 0.1518 - val_mae: 0.3164\n",
      "Epoch 702/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1596 - mae: 0.3255 - val_loss: 0.1479 - val_mae: 0.3140\n",
      "Epoch 703/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1426 - mae: 0.3086 - val_loss: 0.1391 - val_mae: 0.3042\n",
      "Epoch 704/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1417 - mae: 0.3054 - val_loss: 0.1375 - val_mae: 0.3012\n",
      "Epoch 705/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1472 - mae: 0.3083 - val_loss: 0.1168 - val_mae: 0.2777\n",
      "Epoch 706/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1208 - mae: 0.2787 - val_loss: 0.1207 - val_mae: 0.2793\n",
      "Epoch 707/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1240 - mae: 0.2847 - val_loss: 0.1188 - val_mae: 0.2799\n",
      "Epoch 708/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1167 - mae: 0.2750 - val_loss: 0.1174 - val_mae: 0.2769\n",
      "Epoch 709/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1160 - mae: 0.2752 - val_loss: 0.1820 - val_mae: 0.3477\n",
      "Epoch 710/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1993 - mae: 0.3639 - val_loss: 0.1103 - val_mae: 0.2691\n",
      "Epoch 711/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1292 - mae: 0.2886 - val_loss: 0.3375 - val_mae: 0.4819\n",
      "Epoch 712/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2201 - mae: 0.3747 - val_loss: 0.2115 - val_mae: 0.3801\n",
      "Epoch 713/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1827 - mae: 0.3460 - val_loss: 0.1222 - val_mae: 0.2874\n",
      "Epoch 714/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1293 - mae: 0.2909 - val_loss: 0.1336 - val_mae: 0.2938\n",
      "Epoch 715/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1391 - mae: 0.3006 - val_loss: 0.1200 - val_mae: 0.2838\n",
      "Epoch 716/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1343 - mae: 0.2959 - val_loss: 0.1281 - val_mae: 0.2883\n",
      "Epoch 717/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1243 - mae: 0.2829 - val_loss: 0.1053 - val_mae: 0.2615\n",
      "Epoch 718/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1265 - mae: 0.2845 - val_loss: 0.1112 - val_mae: 0.2689\n",
      "Epoch 719/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1182 - mae: 0.2749 - val_loss: 0.1552 - val_mae: 0.3289\n",
      "Epoch 720/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1340 - mae: 0.2968 - val_loss: 0.2587 - val_mae: 0.4279\n",
      "Epoch 721/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1644 - mae: 0.3242 - val_loss: 0.1101 - val_mae: 0.2667\n",
      "Epoch 722/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1400 - mae: 0.3007 - val_loss: 0.1898 - val_mae: 0.3607\n",
      "Epoch 723/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1367 - mae: 0.2974 - val_loss: 0.1576 - val_mae: 0.3221\n",
      "Epoch 724/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1354 - mae: 0.2931 - val_loss: 0.1165 - val_mae: 0.2742\n",
      "Epoch 725/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1384 - mae: 0.2988 - val_loss: 0.1110 - val_mae: 0.2723\n",
      "Epoch 726/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1230 - mae: 0.2819 - val_loss: 0.1278 - val_mae: 0.2869\n",
      "Epoch 727/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1249 - mae: 0.2823 - val_loss: 0.0866 - val_mae: 0.2339\n",
      "Epoch 728/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1249 - mae: 0.2837 - val_loss: 0.1068 - val_mae: 0.2614\n",
      "Epoch 729/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1116 - mae: 0.2645 - val_loss: 0.1282 - val_mae: 0.2964\n",
      "Epoch 730/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1274 - mae: 0.2865 - val_loss: 0.1207 - val_mae: 0.2767\n",
      "Epoch 731/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0959 - mae: 0.2461 - val_loss: 0.0862 - val_mae: 0.2284\n",
      "Epoch 732/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0930 - mae: 0.2392 - val_loss: 0.0938 - val_mae: 0.2477\n",
      "Epoch 733/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0992 - mae: 0.2477 - val_loss: 0.0753 - val_mae: 0.2191\n",
      "Epoch 734/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1164 - mae: 0.2751 - val_loss: 0.1032 - val_mae: 0.2560\n",
      "Epoch 735/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1074 - mae: 0.2616 - val_loss: 0.0927 - val_mae: 0.2457\n",
      "Epoch 736/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0931 - mae: 0.2440 - val_loss: 0.0896 - val_mae: 0.2336\n",
      "Epoch 737/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1039 - mae: 0.2564 - val_loss: 0.1285 - val_mae: 0.2893\n",
      "Epoch 738/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1118 - mae: 0.2664 - val_loss: 0.0854 - val_mae: 0.2267\n",
      "Epoch 739/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0936 - mae: 0.2439 - val_loss: 0.0863 - val_mae: 0.2347\n",
      "Epoch 740/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0895 - mae: 0.2373 - val_loss: 0.1026 - val_mae: 0.2493\n",
      "Epoch 741/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0881 - mae: 0.2328 - val_loss: 0.1366 - val_mae: 0.2879\n",
      "Epoch 742/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1110 - mae: 0.2652 - val_loss: 0.0874 - val_mae: 0.2363\n",
      "Epoch 743/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0918 - mae: 0.2410 - val_loss: 0.0869 - val_mae: 0.2349\n",
      "Epoch 744/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0920 - mae: 0.2400 - val_loss: 0.0986 - val_mae: 0.2498\n",
      "Epoch 745/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0997 - mae: 0.2494 - val_loss: 0.1294 - val_mae: 0.2953\n",
      "Epoch 746/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1981 - mae: 0.3696 - val_loss: 0.1923 - val_mae: 0.3657\n",
      "Epoch 747/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1619 - mae: 0.3272 - val_loss: 0.1873 - val_mae: 0.3603\n",
      "Epoch 748/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1534 - mae: 0.3192 - val_loss: 0.2188 - val_mae: 0.3906\n",
      "Epoch 749/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1876 - mae: 0.3468 - val_loss: 0.1700 - val_mae: 0.3361\n",
      "Epoch 750/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2020 - mae: 0.3594 - val_loss: 0.3128 - val_mae: 0.4593\n",
      "Epoch 751/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2647 - mae: 0.4177 - val_loss: 0.2231 - val_mae: 0.3878\n",
      "Epoch 752/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2470 - mae: 0.4042 - val_loss: 0.3992 - val_mae: 0.5273\n",
      "Epoch 753/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2543 - mae: 0.4019 - val_loss: 0.2173 - val_mae: 0.3813\n",
      "Epoch 754/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2374 - mae: 0.3960 - val_loss: 0.1802 - val_mae: 0.3476\n",
      "Epoch 755/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1929 - mae: 0.3624 - val_loss: 0.1796 - val_mae: 0.3483\n",
      "Epoch 756/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1745 - mae: 0.3369 - val_loss: 0.1582 - val_mae: 0.3299\n",
      "Epoch 757/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2092 - mae: 0.3714 - val_loss: 0.2592 - val_mae: 0.4136\n",
      "Epoch 758/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2496 - mae: 0.4035 - val_loss: 0.2723 - val_mae: 0.4254\n",
      "Epoch 759/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2144 - mae: 0.3736 - val_loss: 0.2084 - val_mae: 0.3733\n",
      "Epoch 760/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1952 - mae: 0.3625 - val_loss: 0.2043 - val_mae: 0.3713\n",
      "Epoch 761/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1918 - mae: 0.3588 - val_loss: 0.1673 - val_mae: 0.3351\n",
      "Epoch 762/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1754 - mae: 0.3443 - val_loss: 0.1871 - val_mae: 0.3516\n",
      "Epoch 763/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2057 - mae: 0.3683 - val_loss: 0.2676 - val_mae: 0.4273\n",
      "Epoch 764/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2380 - mae: 0.3988 - val_loss: 0.3057 - val_mae: 0.4556\n",
      "Epoch 765/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2572 - mae: 0.4102 - val_loss: 0.2208 - val_mae: 0.3811\n",
      "Epoch 766/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2185 - mae: 0.3812 - val_loss: 0.2636 - val_mae: 0.4167\n",
      "Epoch 767/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2198 - mae: 0.3829 - val_loss: 0.1739 - val_mae: 0.3405\n",
      "Epoch 768/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1843 - mae: 0.3543 - val_loss: 0.1669 - val_mae: 0.3325\n",
      "Epoch 769/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1675 - mae: 0.3333 - val_loss: 0.1636 - val_mae: 0.3340\n",
      "Epoch 770/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1835 - mae: 0.3475 - val_loss: 0.2302 - val_mae: 0.3938\n",
      "Epoch 771/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2038 - mae: 0.3629 - val_loss: 0.2695 - val_mae: 0.4297\n",
      "Epoch 772/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2181 - mae: 0.3799 - val_loss: 0.1731 - val_mae: 0.3411\n",
      "Epoch 773/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1783 - mae: 0.3454 - val_loss: 0.2203 - val_mae: 0.3860\n",
      "Epoch 774/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2118 - mae: 0.3669 - val_loss: 0.1562 - val_mae: 0.3277\n",
      "Epoch 775/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1863 - mae: 0.3535 - val_loss: 0.1492 - val_mae: 0.3195\n",
      "Epoch 776/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1655 - mae: 0.3315 - val_loss: 0.1767 - val_mae: 0.3421\n",
      "Epoch 777/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2831 - mae: 0.4345 - val_loss: 0.1798 - val_mae: 0.3498\n",
      "Epoch 778/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1752 - mae: 0.3416 - val_loss: 0.1543 - val_mae: 0.3187\n",
      "Epoch 779/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1668 - mae: 0.3326 - val_loss: 0.1388 - val_mae: 0.3096\n",
      "Epoch 780/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1535 - mae: 0.3195 - val_loss: 0.1956 - val_mae: 0.3550\n",
      "Epoch 781/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1866 - mae: 0.3460 - val_loss: 0.2302 - val_mae: 0.3923\n",
      "Epoch 782/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2042 - mae: 0.3661 - val_loss: 0.1454 - val_mae: 0.3100\n",
      "Epoch 783/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1907 - mae: 0.3520 - val_loss: 0.1818 - val_mae: 0.3432\n",
      "Epoch 784/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1667 - mae: 0.3305 - val_loss: 0.1288 - val_mae: 0.2934\n",
      "Epoch 785/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1570 - mae: 0.3229 - val_loss: 0.2992 - val_mae: 0.4571\n",
      "Epoch 786/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2275 - mae: 0.3860 - val_loss: 0.1287 - val_mae: 0.2965\n",
      "Epoch 787/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1533 - mae: 0.3138 - val_loss: 0.1257 - val_mae: 0.2871\n",
      "Epoch 788/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1846 - mae: 0.3488 - val_loss: 0.2260 - val_mae: 0.3874\n",
      "Epoch 789/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1854 - mae: 0.3514 - val_loss: 0.1211 - val_mae: 0.2848\n",
      "Epoch 790/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1639 - mae: 0.3248 - val_loss: 0.2466 - val_mae: 0.4112\n",
      "Epoch 791/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1717 - mae: 0.3350 - val_loss: 0.1417 - val_mae: 0.3053\n",
      "Epoch 792/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1580 - mae: 0.3184 - val_loss: 0.1999 - val_mae: 0.3588\n",
      "Epoch 793/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1977 - mae: 0.3618 - val_loss: 0.1330 - val_mae: 0.2989\n",
      "Epoch 794/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1534 - mae: 0.3171 - val_loss: 0.1692 - val_mae: 0.3296\n",
      "Epoch 795/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1738 - mae: 0.3362 - val_loss: 0.1299 - val_mae: 0.2923\n",
      "Epoch 796/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1618 - mae: 0.3254 - val_loss: 0.1395 - val_mae: 0.3056\n",
      "Epoch 797/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1603 - mae: 0.3233 - val_loss: 0.1999 - val_mae: 0.3673\n",
      "Epoch 798/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1969 - mae: 0.3598 - val_loss: 0.1243 - val_mae: 0.2877\n",
      "Epoch 799/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2013 - mae: 0.3642 - val_loss: 0.1458 - val_mae: 0.3066\n",
      "Epoch 800/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2191 - mae: 0.3818 - val_loss: 0.2064 - val_mae: 0.3617\n",
      "Epoch 801/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2344 - mae: 0.3942 - val_loss: 0.3852 - val_mae: 0.5220\n",
      "Epoch 802/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2681 - mae: 0.4162 - val_loss: 0.1647 - val_mae: 0.3299\n",
      "Epoch 803/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1667 - mae: 0.3298 - val_loss: 0.1658 - val_mae: 0.3280\n",
      "Epoch 804/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1518 - mae: 0.3154 - val_loss: 0.1895 - val_mae: 0.3495\n",
      "Epoch 805/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1652 - mae: 0.3278 - val_loss: 0.1642 - val_mae: 0.3243\n",
      "Epoch 806/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1766 - mae: 0.3412 - val_loss: 0.1378 - val_mae: 0.2962\n",
      "Epoch 807/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1593 - mae: 0.3217 - val_loss: 0.1417 - val_mae: 0.3101\n",
      "Epoch 808/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1534 - mae: 0.3171 - val_loss: 0.1130 - val_mae: 0.2734\n",
      "Epoch 809/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1431 - mae: 0.3079 - val_loss: 0.1506 - val_mae: 0.3139\n",
      "Epoch 810/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1347 - mae: 0.2959 - val_loss: 0.0993 - val_mae: 0.2518\n",
      "Epoch 811/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1103 - mae: 0.2665 - val_loss: 0.0837 - val_mae: 0.2279\n",
      "Epoch 812/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1047 - mae: 0.2580 - val_loss: 0.1122 - val_mae: 0.2695\n",
      "Epoch 813/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0988 - mae: 0.2465 - val_loss: 0.0910 - val_mae: 0.2375\n",
      "Epoch 814/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1020 - mae: 0.2550 - val_loss: 0.1203 - val_mae: 0.2834\n",
      "Epoch 815/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1214 - mae: 0.2782 - val_loss: 0.1360 - val_mae: 0.2930\n",
      "Epoch 816/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1093 - mae: 0.2639 - val_loss: 0.1148 - val_mae: 0.2721\n",
      "Epoch 817/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1118 - mae: 0.2672 - val_loss: 0.0949 - val_mae: 0.2499\n",
      "Epoch 818/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0992 - mae: 0.2486 - val_loss: 0.0898 - val_mae: 0.2416\n",
      "Epoch 819/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1007 - mae: 0.2534 - val_loss: 0.1080 - val_mae: 0.2590\n",
      "Epoch 820/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1373 - mae: 0.2964 - val_loss: 0.2006 - val_mae: 0.3695\n",
      "Epoch 821/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2244 - mae: 0.3880 - val_loss: 0.5845 - val_mae: 0.6822\n",
      "Epoch 822/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.3772 - mae: 0.5015 - val_loss: 0.2703 - val_mae: 0.4261\n",
      "Epoch 823/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.3211 - mae: 0.4611 - val_loss: 0.3742 - val_mae: 0.5068\n",
      "Epoch 824/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2649 - mae: 0.4142 - val_loss: 0.2061 - val_mae: 0.3782\n",
      "Epoch 825/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2280 - mae: 0.3926 - val_loss: 0.1915 - val_mae: 0.3659\n",
      "Epoch 826/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1812 - mae: 0.3502 - val_loss: 0.3444 - val_mae: 0.4842\n",
      "Epoch 827/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2450 - mae: 0.4010 - val_loss: 0.1831 - val_mae: 0.3559\n",
      "Epoch 828/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2334 - mae: 0.3972 - val_loss: 0.2472 - val_mae: 0.4048\n",
      "Epoch 829/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2029 - mae: 0.3705 - val_loss: 0.1769 - val_mae: 0.3488\n",
      "Epoch 830/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1900 - mae: 0.3586 - val_loss: 0.2528 - val_mae: 0.4119\n",
      "Epoch 831/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2306 - mae: 0.3869 - val_loss: 0.2393 - val_mae: 0.4005\n",
      "Epoch 832/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2405 - mae: 0.4049 - val_loss: 0.2398 - val_mae: 0.4045\n",
      "Epoch 833/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2399 - mae: 0.3951 - val_loss: 0.2295 - val_mae: 0.3919\n",
      "Epoch 834/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2314 - mae: 0.3936 - val_loss: 0.1896 - val_mae: 0.3604\n",
      "Epoch 835/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1989 - mae: 0.3670 - val_loss: 0.1888 - val_mae: 0.3554\n",
      "Epoch 836/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2020 - mae: 0.3666 - val_loss: 0.2938 - val_mae: 0.4420\n",
      "Epoch 837/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.2463 - mae: 0.4006 - val_loss: 0.2771 - val_mae: 0.4272\n",
      "Epoch 838/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2728 - mae: 0.4254 - val_loss: 0.2486 - val_mae: 0.4089\n",
      "Epoch 839/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.2287 - mae: 0.3847 - val_loss: 0.3339 - val_mae: 0.4764\n",
      "Epoch 840/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2642 - mae: 0.4181 - val_loss: 0.2917 - val_mae: 0.4436\n",
      "Epoch 841/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2697 - mae: 0.4203 - val_loss: 0.2117 - val_mae: 0.3732\n",
      "Epoch 842/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2042 - mae: 0.3701 - val_loss: 0.1939 - val_mae: 0.3641\n",
      "Epoch 843/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1964 - mae: 0.3634 - val_loss: 0.1782 - val_mae: 0.3498\n",
      "Epoch 844/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2020 - mae: 0.3676 - val_loss: 0.2627 - val_mae: 0.4187\n",
      "Epoch 845/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2245 - mae: 0.3866 - val_loss: 0.2043 - val_mae: 0.3693\n",
      "Epoch 846/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2140 - mae: 0.3792 - val_loss: 0.1793 - val_mae: 0.3510\n",
      "Epoch 847/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1828 - mae: 0.3524 - val_loss: 0.1680 - val_mae: 0.3386\n",
      "Epoch 848/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1706 - mae: 0.3424 - val_loss: 0.1590 - val_mae: 0.3278\n",
      "Epoch 849/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1696 - mae: 0.3373 - val_loss: 0.1547 - val_mae: 0.3241\n",
      "Epoch 850/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1785 - mae: 0.3476 - val_loss: 0.3413 - val_mae: 0.4882\n",
      "Epoch 851/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.2490 - mae: 0.4048 - val_loss: 0.2289 - val_mae: 0.3908\n",
      "Epoch 852/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.2567 - mae: 0.4126 - val_loss: 0.2810 - val_mae: 0.4326\n",
      "Epoch 853/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2978 - mae: 0.4423 - val_loss: 0.3680 - val_mae: 0.5023\n",
      "Epoch 854/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2826 - mae: 0.4312 - val_loss: 0.2737 - val_mae: 0.4306\n",
      "Epoch 855/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.4642 - mae: 0.4484 - val_loss: 0.4099 - val_mae: 0.5233\n",
      "Epoch 856/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.4477 - mae: 0.4738 - val_loss: 0.2608 - val_mae: 0.4126\n",
      "Epoch 857/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.4340 - mae: 0.4861 - val_loss: 0.1954 - val_mae: 0.3629\n",
      "Epoch 858/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.3003 - mae: 0.4197 - val_loss: 0.4067 - val_mae: 0.5287\n",
      "Epoch 859/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.3480 - mae: 0.4710 - val_loss: 0.2590 - val_mae: 0.4161\n",
      "Epoch 860/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2565 - mae: 0.4061 - val_loss: 0.2062 - val_mae: 0.3767\n",
      "Epoch 861/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2387 - mae: 0.4024 - val_loss: 0.2661 - val_mae: 0.4175\n",
      "Epoch 862/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2239 - mae: 0.3830 - val_loss: 0.1904 - val_mae: 0.3600\n",
      "Epoch 863/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2117 - mae: 0.3737 - val_loss: 0.2244 - val_mae: 0.3862\n",
      "Epoch 864/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2187 - mae: 0.3798 - val_loss: 0.2908 - val_mae: 0.4421\n",
      "Epoch 865/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2280 - mae: 0.3873 - val_loss: 0.1833 - val_mae: 0.3517\n",
      "Epoch 866/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2136 - mae: 0.3763 - val_loss: 0.2289 - val_mae: 0.3944\n",
      "Epoch 867/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2092 - mae: 0.3720 - val_loss: 0.2019 - val_mae: 0.3597\n",
      "Epoch 868/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1913 - mae: 0.3537 - val_loss: 0.1657 - val_mae: 0.3314\n",
      "Epoch 869/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1935 - mae: 0.3581 - val_loss: 0.1963 - val_mae: 0.3646\n",
      "Epoch 870/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2001 - mae: 0.3638 - val_loss: 0.2390 - val_mae: 0.4007\n",
      "Epoch 871/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1761 - mae: 0.3434 - val_loss: 0.1764 - val_mae: 0.3397\n",
      "Epoch 872/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1767 - mae: 0.3424 - val_loss: 0.1523 - val_mae: 0.3217\n",
      "Epoch 873/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1748 - mae: 0.3412 - val_loss: 0.1954 - val_mae: 0.3596\n",
      "Epoch 874/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1625 - mae: 0.3289 - val_loss: 0.2153 - val_mae: 0.3806\n",
      "Epoch 875/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2209 - mae: 0.3810 - val_loss: 0.1876 - val_mae: 0.3576\n",
      "Epoch 876/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2145 - mae: 0.3752 - val_loss: 0.1748 - val_mae: 0.3485\n",
      "Epoch 877/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2399 - mae: 0.3957 - val_loss: 0.2332 - val_mae: 0.3938\n",
      "Epoch 878/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2174 - mae: 0.3787 - val_loss: 0.2090 - val_mae: 0.3720\n",
      "Epoch 879/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1918 - mae: 0.3582 - val_loss: 0.2198 - val_mae: 0.3870\n",
      "Epoch 880/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2135 - mae: 0.3788 - val_loss: 0.2420 - val_mae: 0.4034\n",
      "Epoch 881/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2079 - mae: 0.3708 - val_loss: 0.1723 - val_mae: 0.3458\n",
      "Epoch 882/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1770 - mae: 0.3473 - val_loss: 0.1751 - val_mae: 0.3502\n",
      "Epoch 883/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1732 - mae: 0.3424 - val_loss: 0.1602 - val_mae: 0.3273\n",
      "Epoch 884/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1598 - mae: 0.3275 - val_loss: 0.2259 - val_mae: 0.3939\n",
      "Epoch 885/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1923 - mae: 0.3588 - val_loss: 0.1656 - val_mae: 0.3347\n",
      "Epoch 886/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1922 - mae: 0.3537 - val_loss: 0.1903 - val_mae: 0.3604\n",
      "Epoch 887/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1998 - mae: 0.3664 - val_loss: 0.2030 - val_mae: 0.3661\n",
      "Epoch 888/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1836 - mae: 0.3505 - val_loss: 0.2148 - val_mae: 0.3700\n",
      "Epoch 889/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2059 - mae: 0.3655 - val_loss: 0.1956 - val_mae: 0.3615\n",
      "Epoch 890/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1980 - mae: 0.3616 - val_loss: 0.1318 - val_mae: 0.2998\n",
      "Epoch 891/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1447 - mae: 0.3101 - val_loss: 0.3019 - val_mae: 0.4513\n",
      "Epoch 892/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2583 - mae: 0.4113 - val_loss: 0.2020 - val_mae: 0.3603\n",
      "Epoch 893/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2166 - mae: 0.3796 - val_loss: 0.1693 - val_mae: 0.3369\n",
      "Epoch 894/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1906 - mae: 0.3559 - val_loss: 0.1598 - val_mae: 0.3281\n",
      "Epoch 895/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1539 - mae: 0.3211 - val_loss: 0.1407 - val_mae: 0.3059\n",
      "Epoch 896/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1460 - mae: 0.3123 - val_loss: 0.1245 - val_mae: 0.2896\n",
      "Epoch 897/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1272 - mae: 0.2910 - val_loss: 0.1529 - val_mae: 0.3202\n",
      "Epoch 898/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1424 - mae: 0.3064 - val_loss: 0.1240 - val_mae: 0.2866\n",
      "Epoch 899/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1384 - mae: 0.3009 - val_loss: 0.1332 - val_mae: 0.2943\n",
      "Epoch 900/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1265 - mae: 0.2854 - val_loss: 0.1066 - val_mae: 0.2665\n",
      "Epoch 901/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1206 - mae: 0.2794 - val_loss: 0.2296 - val_mae: 0.4026\n",
      "Epoch 902/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1701 - mae: 0.3349 - val_loss: 0.2124 - val_mae: 0.3717\n",
      "Epoch 903/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1775 - mae: 0.3384 - val_loss: 0.1367 - val_mae: 0.3016\n",
      "Epoch 904/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1476 - mae: 0.3108 - val_loss: 0.1432 - val_mae: 0.3056\n",
      "Epoch 905/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1331 - mae: 0.2974 - val_loss: 0.1415 - val_mae: 0.3047\n",
      "Epoch 906/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1244 - mae: 0.2841 - val_loss: 0.1350 - val_mae: 0.2992\n",
      "Epoch 907/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1366 - mae: 0.2972 - val_loss: 0.1162 - val_mae: 0.2747\n",
      "Epoch 908/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1743 - mae: 0.3336 - val_loss: 0.3625 - val_mae: 0.5177\n",
      "Epoch 909/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.2317 - mae: 0.3929 - val_loss: 0.1196 - val_mae: 0.2813\n",
      "Epoch 910/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1498 - mae: 0.3120 - val_loss: 0.1176 - val_mae: 0.2777\n",
      "Epoch 911/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1129 - mae: 0.2714 - val_loss: 0.1133 - val_mae: 0.2756\n",
      "Epoch 912/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1086 - mae: 0.2646 - val_loss: 0.1366 - val_mae: 0.2993\n",
      "Epoch 913/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1182 - mae: 0.2772 - val_loss: 0.1030 - val_mae: 0.2586\n",
      "Epoch 914/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1118 - mae: 0.2679 - val_loss: 0.1116 - val_mae: 0.2666\n",
      "Epoch 915/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1257 - mae: 0.2853 - val_loss: 0.1134 - val_mae: 0.2746\n",
      "Epoch 916/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1419 - mae: 0.3042 - val_loss: 0.1317 - val_mae: 0.2929\n",
      "Epoch 917/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1426 - mae: 0.3055 - val_loss: 0.1729 - val_mae: 0.3314\n",
      "Epoch 918/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1532 - mae: 0.3155 - val_loss: 0.1211 - val_mae: 0.2802\n",
      "Epoch 919/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1330 - mae: 0.2953 - val_loss: 0.1559 - val_mae: 0.3229\n",
      "Epoch 920/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.2858 - mae: 0.4344 - val_loss: 0.2525 - val_mae: 0.4095\n",
      "Epoch 921/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1719 - mae: 0.3331 - val_loss: 0.1989 - val_mae: 0.3622\n",
      "Epoch 922/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1729 - mae: 0.3405 - val_loss: 0.1740 - val_mae: 0.3376\n",
      "Epoch 923/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1453 - mae: 0.3100 - val_loss: 0.1295 - val_mae: 0.2928\n",
      "Epoch 924/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1376 - mae: 0.3034 - val_loss: 0.1196 - val_mae: 0.2794\n",
      "Epoch 925/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1243 - mae: 0.2857 - val_loss: 0.1230 - val_mae: 0.2848\n",
      "Epoch 926/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1422 - mae: 0.3031 - val_loss: 0.2469 - val_mae: 0.4155\n",
      "Epoch 927/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1560 - mae: 0.3161 - val_loss: 0.1129 - val_mae: 0.2756\n",
      "Epoch 928/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2031 - mae: 0.3681 - val_loss: 0.1328 - val_mae: 0.3001\n",
      "Epoch 929/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1380 - mae: 0.3041 - val_loss: 0.1158 - val_mae: 0.2736\n",
      "Epoch 930/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1180 - mae: 0.2775 - val_loss: 0.1476 - val_mae: 0.3138\n",
      "Epoch 931/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1548 - mae: 0.3202 - val_loss: 0.1298 - val_mae: 0.2918\n",
      "Epoch 932/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1204 - mae: 0.2802 - val_loss: 0.1431 - val_mae: 0.3062\n",
      "Epoch 933/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1388 - mae: 0.2989 - val_loss: 0.2464 - val_mae: 0.4183\n",
      "Epoch 934/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1657 - mae: 0.3240 - val_loss: 0.1516 - val_mae: 0.3188\n",
      "Epoch 935/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1683 - mae: 0.3297 - val_loss: 0.1363 - val_mae: 0.2990\n",
      "Epoch 936/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1713 - mae: 0.3369 - val_loss: 0.1505 - val_mae: 0.3177\n",
      "Epoch 937/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1630 - mae: 0.3253 - val_loss: 0.1124 - val_mae: 0.2717\n",
      "Epoch 938/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1132 - mae: 0.2690 - val_loss: 0.1093 - val_mae: 0.2611\n",
      "Epoch 939/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1109 - mae: 0.2666 - val_loss: 0.0893 - val_mae: 0.2418\n",
      "Epoch 940/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1158 - mae: 0.2716 - val_loss: 0.0947 - val_mae: 0.2462\n",
      "Epoch 941/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0920 - mae: 0.2398 - val_loss: 0.0842 - val_mae: 0.2267\n",
      "Epoch 942/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0868 - mae: 0.2335 - val_loss: 0.0972 - val_mae: 0.2433\n",
      "Epoch 943/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0937 - mae: 0.2426 - val_loss: 0.0826 - val_mae: 0.2272\n",
      "Epoch 944/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0887 - mae: 0.2366 - val_loss: 0.0986 - val_mae: 0.2457\n",
      "Epoch 945/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0971 - mae: 0.2463 - val_loss: 0.1077 - val_mae: 0.2631\n",
      "Epoch 946/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1158 - mae: 0.2710 - val_loss: 0.1030 - val_mae: 0.2569\n",
      "Epoch 947/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1087 - mae: 0.2651 - val_loss: 0.1664 - val_mae: 0.3311\n",
      "Epoch 948/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1601 - mae: 0.3220 - val_loss: 0.1728 - val_mae: 0.3371\n",
      "Epoch 949/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1566 - mae: 0.3201 - val_loss: 0.1583 - val_mae: 0.3241\n",
      "Epoch 950/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1462 - mae: 0.3100 - val_loss: 0.1315 - val_mae: 0.2980\n",
      "Epoch 951/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1484 - mae: 0.3131 - val_loss: 0.1389 - val_mae: 0.3042\n",
      "Epoch 952/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1420 - mae: 0.3051 - val_loss: 0.1216 - val_mae: 0.2827\n",
      "Epoch 953/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1562 - mae: 0.3212 - val_loss: 0.2071 - val_mae: 0.3709\n",
      "Epoch 954/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2257 - mae: 0.3854 - val_loss: 0.2051 - val_mae: 0.3750\n",
      "Epoch 955/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1573 - mae: 0.3207 - val_loss: 0.2603 - val_mae: 0.4175\n",
      "Epoch 956/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1748 - mae: 0.3355 - val_loss: 0.1470 - val_mae: 0.3161\n",
      "Epoch 957/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1485 - mae: 0.3117 - val_loss: 0.1266 - val_mae: 0.2862\n",
      "Epoch 958/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1260 - mae: 0.2861 - val_loss: 0.2393 - val_mae: 0.3988\n",
      "Epoch 959/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1517 - mae: 0.3112 - val_loss: 0.1385 - val_mae: 0.3052\n",
      "Epoch 960/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1211 - mae: 0.2811 - val_loss: 0.1675 - val_mae: 0.3305\n",
      "Epoch 961/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1339 - mae: 0.2921 - val_loss: 0.1056 - val_mae: 0.2643\n",
      "Epoch 962/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1217 - mae: 0.2796 - val_loss: 0.0915 - val_mae: 0.2368\n",
      "Epoch 963/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0972 - mae: 0.2490 - val_loss: 0.0969 - val_mae: 0.2481\n",
      "Epoch 964/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0926 - mae: 0.2428 - val_loss: 0.1056 - val_mae: 0.2595\n",
      "Epoch 965/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1280 - mae: 0.2846 - val_loss: 0.1333 - val_mae: 0.2953\n",
      "Epoch 966/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1091 - mae: 0.2646 - val_loss: 0.1006 - val_mae: 0.2491\n",
      "Epoch 967/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0977 - mae: 0.2469 - val_loss: 0.0936 - val_mae: 0.2428\n",
      "Epoch 968/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1352 - mae: 0.2986 - val_loss: 0.1464 - val_mae: 0.3080\n",
      "Epoch 969/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1530 - mae: 0.3121 - val_loss: 0.1039 - val_mae: 0.2625\n",
      "Epoch 970/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1346 - mae: 0.2942 - val_loss: 0.0996 - val_mae: 0.2562\n",
      "Epoch 971/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1387 - mae: 0.3014 - val_loss: 0.1741 - val_mae: 0.3439\n",
      "Epoch 972/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1701 - mae: 0.3333 - val_loss: 0.2331 - val_mae: 0.4067\n",
      "Epoch 973/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1565 - mae: 0.3191 - val_loss: 0.1278 - val_mae: 0.2893\n",
      "Epoch 974/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.1172 - mae: 0.2778 - val_loss: 0.1127 - val_mae: 0.2704\n",
      "Epoch 975/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1030 - mae: 0.2583 - val_loss: 0.0884 - val_mae: 0.2356\n",
      "Epoch 976/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0976 - mae: 0.2481 - val_loss: 0.0843 - val_mae: 0.2293\n",
      "Epoch 977/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0894 - mae: 0.2364 - val_loss: 0.0879 - val_mae: 0.2298\n",
      "Epoch 978/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0901 - mae: 0.2377 - val_loss: 0.0906 - val_mae: 0.2376\n",
      "Epoch 979/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1322 - mae: 0.2582 - val_loss: 0.0794 - val_mae: 0.2228\n",
      "Epoch 980/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1302 - mae: 0.2669 - val_loss: 0.1073 - val_mae: 0.2602\n",
      "Epoch 981/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1618 - mae: 0.3104 - val_loss: 0.1021 - val_mae: 0.2546\n",
      "Epoch 982/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1220 - mae: 0.2586 - val_loss: 0.0971 - val_mae: 0.2455\n",
      "Epoch 983/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1305 - mae: 0.2691 - val_loss: 0.1028 - val_mae: 0.2519\n",
      "Epoch 984/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1336 - mae: 0.2714 - val_loss: 0.0807 - val_mae: 0.2230\n",
      "Epoch 985/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1237 - mae: 0.2613 - val_loss: 0.0992 - val_mae: 0.2511\n",
      "Epoch 986/2000\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.1221 - mae: 0.2614 - val_loss: 0.1364 - val_mae: 0.2987\n",
      "Epoch 987/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1390 - mae: 0.2763 - val_loss: 0.0893 - val_mae: 0.2391\n",
      "Epoch 988/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1203 - mae: 0.2574 - val_loss: 0.0891 - val_mae: 0.2338\n",
      "Epoch 989/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1305 - mae: 0.2678 - val_loss: 0.0974 - val_mae: 0.2482\n",
      "Epoch 990/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1321 - mae: 0.2720 - val_loss: 0.1062 - val_mae: 0.2668\n",
      "Epoch 991/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1302 - mae: 0.2724 - val_loss: 0.1000 - val_mae: 0.2527\n",
      "Epoch 992/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1162 - mae: 0.2530 - val_loss: 0.1062 - val_mae: 0.2539\n",
      "Epoch 993/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1335 - mae: 0.2694 - val_loss: 0.1305 - val_mae: 0.2986\n",
      "Epoch 994/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1597 - mae: 0.2990 - val_loss: 0.0941 - val_mae: 0.2423\n",
      "Epoch 995/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1712 - mae: 0.3141 - val_loss: 0.2785 - val_mae: 0.4542\n",
      "Epoch 996/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2020 - mae: 0.3529 - val_loss: 0.1322 - val_mae: 0.2968\n",
      "Epoch 997/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1682 - mae: 0.3045 - val_loss: 0.0969 - val_mae: 0.2445\n",
      "Epoch 998/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1581 - mae: 0.2943 - val_loss: 0.1698 - val_mae: 0.3431\n",
      "Epoch 999/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1982 - mae: 0.3441 - val_loss: 0.1029 - val_mae: 0.2542\n",
      "Epoch 1000/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1640 - mae: 0.3029 - val_loss: 0.1019 - val_mae: 0.2544\n",
      "Epoch 1001/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1398 - mae: 0.2792 - val_loss: 0.1687 - val_mae: 0.3344\n",
      "Epoch 1002/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1761 - mae: 0.3067 - val_loss: 0.0889 - val_mae: 0.2368\n",
      "Epoch 1003/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1541 - mae: 0.2806 - val_loss: 0.0944 - val_mae: 0.2492\n",
      "Epoch 1004/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1525 - mae: 0.2876 - val_loss: 0.1180 - val_mae: 0.2785\n",
      "Epoch 1005/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1801 - mae: 0.3255 - val_loss: 0.0914 - val_mae: 0.2401\n",
      "Epoch 1006/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1492 - mae: 0.2886 - val_loss: 0.0886 - val_mae: 0.2348\n",
      "Epoch 1007/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1423 - mae: 0.2754 - val_loss: 0.0897 - val_mae: 0.2402\n",
      "Epoch 1008/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1467 - mae: 0.2834 - val_loss: 0.1111 - val_mae: 0.2591\n",
      "Epoch 1009/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1449 - mae: 0.2816 - val_loss: 0.0957 - val_mae: 0.2436\n",
      "Epoch 1010/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1379 - mae: 0.2699 - val_loss: 0.0916 - val_mae: 0.2440\n",
      "Epoch 1011/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1478 - mae: 0.2709 - val_loss: 0.0790 - val_mae: 0.2229\n",
      "Epoch 1012/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1431 - mae: 0.2696 - val_loss: 0.0762 - val_mae: 0.2180\n",
      "Epoch 1013/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1310 - mae: 0.2561 - val_loss: 0.0704 - val_mae: 0.2086\n",
      "Epoch 1014/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1262 - mae: 0.2517 - val_loss: 0.0764 - val_mae: 0.2172\n",
      "Epoch 1015/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1280 - mae: 0.2546 - val_loss: 0.0878 - val_mae: 0.2354\n",
      "Epoch 1016/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1271 - mae: 0.2602 - val_loss: 0.0834 - val_mae: 0.2269\n",
      "Epoch 1017/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1487 - mae: 0.2852 - val_loss: 0.0720 - val_mae: 0.2107\n",
      "Epoch 1018/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1373 - mae: 0.2678 - val_loss: 0.0780 - val_mae: 0.2213\n",
      "Epoch 1019/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1476 - mae: 0.2814 - val_loss: 0.1197 - val_mae: 0.2788\n",
      "Epoch 1020/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1647 - mae: 0.3007 - val_loss: 0.1477 - val_mae: 0.3130\n",
      "Epoch 1021/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1938 - mae: 0.3393 - val_loss: 0.1015 - val_mae: 0.2534\n",
      "Epoch 1022/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1569 - mae: 0.2940 - val_loss: 0.1343 - val_mae: 0.2901\n",
      "Epoch 1023/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1660 - mae: 0.3089 - val_loss: 0.1674 - val_mae: 0.3373\n",
      "Epoch 1024/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2004 - mae: 0.3543 - val_loss: 0.1289 - val_mae: 0.2954\n",
      "Epoch 1025/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2008 - mae: 0.3480 - val_loss: 0.1255 - val_mae: 0.2872\n",
      "Epoch 1026/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1789 - mae: 0.3213 - val_loss: 0.1194 - val_mae: 0.2772\n",
      "Epoch 1027/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1817 - mae: 0.3157 - val_loss: 0.4594 - val_mae: 0.5923\n",
      "Epoch 1028/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.3500 - mae: 0.4833 - val_loss: 0.2218 - val_mae: 0.3847\n",
      "Epoch 1029/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2920 - mae: 0.4317 - val_loss: 0.1990 - val_mae: 0.3715\n",
      "Epoch 1030/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.2403 - mae: 0.3843 - val_loss: 0.2496 - val_mae: 0.4111\n",
      "Epoch 1031/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2548 - mae: 0.4051 - val_loss: 0.1872 - val_mae: 0.3580\n",
      "Epoch 1032/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2341 - mae: 0.3753 - val_loss: 0.1756 - val_mae: 0.3439\n",
      "Epoch 1033/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2322 - mae: 0.3786 - val_loss: 0.2329 - val_mae: 0.3934\n",
      "Epoch 1034/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2494 - mae: 0.3960 - val_loss: 0.2216 - val_mae: 0.3795\n",
      "Epoch 1035/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2547 - mae: 0.4024 - val_loss: 0.1930 - val_mae: 0.3587\n",
      "Epoch 1036/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2332 - mae: 0.3848 - val_loss: 0.2019 - val_mae: 0.3609\n",
      "Epoch 1037/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2870 - mae: 0.4277 - val_loss: 0.3028 - val_mae: 0.4462\n",
      "Epoch 1038/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2862 - mae: 0.4289 - val_loss: 0.1958 - val_mae: 0.3653\n",
      "Epoch 1039/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.2502 - mae: 0.3905 - val_loss: 0.1823 - val_mae: 0.3443\n",
      "Epoch 1040/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2387 - mae: 0.3768 - val_loss: 0.1631 - val_mae: 0.3332\n",
      "Epoch 1041/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2119 - mae: 0.3599 - val_loss: 0.1771 - val_mae: 0.3507\n",
      "Epoch 1042/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2312 - mae: 0.3813 - val_loss: 0.2585 - val_mae: 0.4205\n",
      "Epoch 1043/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2593 - mae: 0.4038 - val_loss: 0.2425 - val_mae: 0.4032\n",
      "Epoch 1044/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2565 - mae: 0.4042 - val_loss: 0.2121 - val_mae: 0.3785\n",
      "Epoch 1045/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2477 - mae: 0.3886 - val_loss: 0.1750 - val_mae: 0.3454\n",
      "Epoch 1046/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2271 - mae: 0.3660 - val_loss: 0.1825 - val_mae: 0.3487\n",
      "Epoch 1047/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2220 - mae: 0.3693 - val_loss: 0.1802 - val_mae: 0.3503\n",
      "Epoch 1048/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2416 - mae: 0.3925 - val_loss: 0.2301 - val_mae: 0.3966\n",
      "Epoch 1049/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2316 - mae: 0.3751 - val_loss: 0.1696 - val_mae: 0.3392\n",
      "Epoch 1050/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2194 - mae: 0.3654 - val_loss: 0.1677 - val_mae: 0.3373\n",
      "Epoch 1051/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2482 - mae: 0.3915 - val_loss: 0.2806 - val_mae: 0.4412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1052/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2866 - mae: 0.4237 - val_loss: 0.1900 - val_mae: 0.3600\n",
      "Epoch 1053/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2247 - mae: 0.3703 - val_loss: 0.2777 - val_mae: 0.4343\n",
      "Epoch 1054/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2494 - mae: 0.3968 - val_loss: 0.2640 - val_mae: 0.4242\n",
      "Epoch 1055/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2680 - mae: 0.4052 - val_loss: 0.1975 - val_mae: 0.3637\n",
      "Epoch 1056/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2280 - mae: 0.3761 - val_loss: 0.1929 - val_mae: 0.3625\n",
      "Epoch 1057/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2307 - mae: 0.3700 - val_loss: 0.1486 - val_mae: 0.3218\n",
      "Epoch 1058/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1927 - mae: 0.3409 - val_loss: 0.1588 - val_mae: 0.3299\n",
      "Epoch 1059/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1995 - mae: 0.3522 - val_loss: 0.1584 - val_mae: 0.3268\n",
      "Epoch 1060/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2041 - mae: 0.3570 - val_loss: 0.2464 - val_mae: 0.4103\n",
      "Epoch 1061/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2423 - mae: 0.3839 - val_loss: 0.1595 - val_mae: 0.3296\n",
      "Epoch 1062/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2061 - mae: 0.3526 - val_loss: 0.1718 - val_mae: 0.3382\n",
      "Epoch 1063/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1954 - mae: 0.3424 - val_loss: 0.2743 - val_mae: 0.4248\n",
      "Epoch 1064/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2843 - mae: 0.4256 - val_loss: 0.1813 - val_mae: 0.3470\n",
      "Epoch 1065/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2461 - mae: 0.3931 - val_loss: 0.1785 - val_mae: 0.3497\n",
      "Epoch 1066/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2119 - mae: 0.3637 - val_loss: 0.1745 - val_mae: 0.3490\n",
      "Epoch 1067/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1764 - mae: 0.3375 - val_loss: 0.1563 - val_mae: 0.3279\n",
      "Epoch 1068/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2002 - mae: 0.3300 - val_loss: 0.1443 - val_mae: 0.3136\n",
      "Epoch 1069/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2068 - mae: 0.3443 - val_loss: 0.1659 - val_mae: 0.3318\n",
      "Epoch 1070/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2229 - mae: 0.3726 - val_loss: 0.3174 - val_mae: 0.4650\n",
      "Epoch 1071/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2741 - mae: 0.4121 - val_loss: 0.1804 - val_mae: 0.3490\n",
      "Epoch 1072/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1887 - mae: 0.3398 - val_loss: 0.1917 - val_mae: 0.3549\n",
      "Epoch 1073/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1975 - mae: 0.3472 - val_loss: 0.2972 - val_mae: 0.4429\n",
      "Epoch 1074/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2696 - mae: 0.4118 - val_loss: 0.3339 - val_mae: 0.4737\n",
      "Epoch 1075/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2775 - mae: 0.4265 - val_loss: 0.2768 - val_mae: 0.4278\n",
      "Epoch 1076/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.3077 - mae: 0.4439 - val_loss: 0.1860 - val_mae: 0.3518\n",
      "Epoch 1077/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2368 - mae: 0.3811 - val_loss: 0.1860 - val_mae: 0.3551\n",
      "Epoch 1078/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1959 - mae: 0.3450 - val_loss: 0.1610 - val_mae: 0.3324\n",
      "Epoch 1079/2000\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.1833 - mae: 0.3363 - val_loss: 0.1756 - val_mae: 0.3466\n",
      "Epoch 1080/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1838 - mae: 0.3403 - val_loss: 0.1612 - val_mae: 0.3317\n",
      "Epoch 1081/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1761 - mae: 0.3343 - val_loss: 0.2249 - val_mae: 0.3819\n",
      "Epoch 1082/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2100 - mae: 0.3691 - val_loss: 0.1667 - val_mae: 0.3364\n",
      "Epoch 1083/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1995 - mae: 0.3446 - val_loss: 0.1782 - val_mae: 0.3404\n",
      "Epoch 1084/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1975 - mae: 0.3318 - val_loss: 0.1359 - val_mae: 0.3032\n",
      "Epoch 1085/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1712 - mae: 0.3136 - val_loss: 0.1332 - val_mae: 0.2969\n",
      "Epoch 1086/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1905 - mae: 0.3368 - val_loss: 0.1526 - val_mae: 0.3164\n",
      "Epoch 1087/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1792 - mae: 0.3281 - val_loss: 0.1442 - val_mae: 0.3112\n",
      "Epoch 1088/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2128 - mae: 0.3400 - val_loss: 0.1742 - val_mae: 0.3365\n",
      "Epoch 1089/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1983 - mae: 0.3394 - val_loss: 0.1362 - val_mae: 0.3017\n",
      "Epoch 1090/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1956 - mae: 0.3471 - val_loss: 0.1741 - val_mae: 0.3447\n",
      "Epoch 1091/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1981 - mae: 0.3466 - val_loss: 0.1280 - val_mae: 0.2923\n",
      "Epoch 1092/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2287 - mae: 0.3629 - val_loss: 0.2616 - val_mae: 0.4171\n",
      "Epoch 1093/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1994 - mae: 0.3503 - val_loss: 0.1347 - val_mae: 0.2944\n",
      "Epoch 1094/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1605 - mae: 0.3084 - val_loss: 0.1252 - val_mae: 0.2879\n",
      "Epoch 1095/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1824 - mae: 0.3186 - val_loss: 0.2545 - val_mae: 0.4267\n",
      "Epoch 1096/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2137 - mae: 0.3764 - val_loss: 0.2040 - val_mae: 0.3730\n",
      "Epoch 1097/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1886 - mae: 0.3493 - val_loss: 0.1633 - val_mae: 0.3319\n",
      "Epoch 1098/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1657 - mae: 0.3201 - val_loss: 0.1155 - val_mae: 0.2755\n",
      "Epoch 1099/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1303 - mae: 0.2710 - val_loss: 0.0942 - val_mae: 0.2474\n",
      "Epoch 1100/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1157 - mae: 0.2591 - val_loss: 0.0912 - val_mae: 0.2414\n",
      "Epoch 1101/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1106 - mae: 0.2528 - val_loss: 0.0887 - val_mae: 0.2363\n",
      "Epoch 1102/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1428 - mae: 0.2759 - val_loss: 0.1342 - val_mae: 0.3012\n",
      "Epoch 1103/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1941 - mae: 0.3448 - val_loss: 0.1849 - val_mae: 0.3510\n",
      "Epoch 1104/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1932 - mae: 0.3396 - val_loss: 0.1820 - val_mae: 0.3523\n",
      "Epoch 1105/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1561 - mae: 0.3114 - val_loss: 0.1400 - val_mae: 0.3083\n",
      "Epoch 1106/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1546 - mae: 0.3000 - val_loss: 0.1295 - val_mae: 0.2891\n",
      "Epoch 1107/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1638 - mae: 0.3072 - val_loss: 0.1758 - val_mae: 0.3380\n",
      "Epoch 1108/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1448 - mae: 0.2930 - val_loss: 0.1041 - val_mae: 0.2594\n",
      "Epoch 1109/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1364 - mae: 0.2881 - val_loss: 0.1734 - val_mae: 0.3399\n",
      "Epoch 1110/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1954 - mae: 0.3302 - val_loss: 0.1037 - val_mae: 0.2589\n",
      "Epoch 1111/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1410 - mae: 0.2689 - val_loss: 0.0937 - val_mae: 0.2492\n",
      "Epoch 1112/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1594 - mae: 0.3020 - val_loss: 0.0940 - val_mae: 0.2464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1113/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1619 - mae: 0.3019 - val_loss: 0.0977 - val_mae: 0.2477\n",
      "Epoch 1114/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2567 - mae: 0.3950 - val_loss: 0.1570 - val_mae: 0.3188\n",
      "Epoch 1115/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1739 - mae: 0.3115 - val_loss: 0.1277 - val_mae: 0.2900\n",
      "Epoch 1116/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1717 - mae: 0.3141 - val_loss: 0.1407 - val_mae: 0.3025\n",
      "Epoch 1117/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1466 - mae: 0.3020 - val_loss: 0.1609 - val_mae: 0.3292\n",
      "Epoch 1118/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1993 - mae: 0.3278 - val_loss: 0.2210 - val_mae: 0.3810\n",
      "Epoch 1119/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1832 - mae: 0.3391 - val_loss: 0.1384 - val_mae: 0.3029\n",
      "Epoch 1120/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1996 - mae: 0.3474 - val_loss: 0.1728 - val_mae: 0.3437\n",
      "Epoch 1121/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2142 - mae: 0.3603 - val_loss: 0.1981 - val_mae: 0.3558\n",
      "Epoch 1122/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2278 - mae: 0.3750 - val_loss: 0.1971 - val_mae: 0.3625\n",
      "Epoch 1123/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2236 - mae: 0.3720 - val_loss: 0.1740 - val_mae: 0.3390\n",
      "Epoch 1124/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1940 - mae: 0.3436 - val_loss: 0.1515 - val_mae: 0.3241\n",
      "Epoch 1125/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1632 - mae: 0.3137 - val_loss: 0.2071 - val_mae: 0.3722\n",
      "Epoch 1126/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1886 - mae: 0.3426 - val_loss: 0.2573 - val_mae: 0.4211\n",
      "Epoch 1127/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2404 - mae: 0.3787 - val_loss: 0.1961 - val_mae: 0.3629\n",
      "Epoch 1128/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2074 - mae: 0.3516 - val_loss: 0.2687 - val_mae: 0.4236\n",
      "Epoch 1129/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2345 - mae: 0.3801 - val_loss: 0.1791 - val_mae: 0.3499\n",
      "Epoch 1130/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2206 - mae: 0.3658 - val_loss: 0.1669 - val_mae: 0.3326\n",
      "Epoch 1131/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2464 - mae: 0.3746 - val_loss: 0.1484 - val_mae: 0.3143\n",
      "Epoch 1132/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2101 - mae: 0.3576 - val_loss: 0.1521 - val_mae: 0.3208\n",
      "Epoch 1133/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1895 - mae: 0.3505 - val_loss: 0.1335 - val_mae: 0.2981\n",
      "Epoch 1134/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1508 - mae: 0.2989 - val_loss: 0.1413 - val_mae: 0.3067\n",
      "Epoch 1135/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1811 - mae: 0.3127 - val_loss: 0.1214 - val_mae: 0.2867\n",
      "Epoch 1136/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1905 - mae: 0.3379 - val_loss: 0.1728 - val_mae: 0.3386\n",
      "Epoch 1137/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1803 - mae: 0.3280 - val_loss: 0.1149 - val_mae: 0.2778\n",
      "Epoch 1138/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1535 - mae: 0.2897 - val_loss: 0.1020 - val_mae: 0.2562\n",
      "Epoch 1139/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1522 - mae: 0.2863 - val_loss: 0.1433 - val_mae: 0.3087\n",
      "Epoch 1140/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1572 - mae: 0.2934 - val_loss: 0.1021 - val_mae: 0.2586\n",
      "Epoch 1141/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1700 - mae: 0.3119 - val_loss: 0.1056 - val_mae: 0.2571\n",
      "Epoch 1142/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1318 - mae: 0.2718 - val_loss: 0.0960 - val_mae: 0.2453\n",
      "Epoch 1143/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1567 - mae: 0.2827 - val_loss: 0.1741 - val_mae: 0.3400\n",
      "Epoch 1144/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1676 - mae: 0.3042 - val_loss: 0.0988 - val_mae: 0.2498\n",
      "Epoch 1145/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1473 - mae: 0.2898 - val_loss: 0.1059 - val_mae: 0.2625\n",
      "Epoch 1146/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1549 - mae: 0.2892 - val_loss: 0.0977 - val_mae: 0.2494\n",
      "Epoch 1147/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1415 - mae: 0.2764 - val_loss: 0.0946 - val_mae: 0.2448\n",
      "Epoch 1148/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1346 - mae: 0.2710 - val_loss: 0.0881 - val_mae: 0.2385\n",
      "Epoch 1149/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1342 - mae: 0.2583 - val_loss: 0.0876 - val_mae: 0.2364\n",
      "Epoch 1150/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1316 - mae: 0.2630 - val_loss: 0.1416 - val_mae: 0.3033\n",
      "Epoch 1151/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1623 - mae: 0.3056 - val_loss: 0.1024 - val_mae: 0.2554\n",
      "Epoch 1152/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1658 - mae: 0.2917 - val_loss: 0.1128 - val_mae: 0.2746\n",
      "Epoch 1153/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1518 - mae: 0.2826 - val_loss: 0.1049 - val_mae: 0.2611\n",
      "Epoch 1154/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1303 - mae: 0.2679 - val_loss: 0.0957 - val_mae: 0.2504\n",
      "Epoch 1155/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1357 - mae: 0.2639 - val_loss: 0.0763 - val_mae: 0.2182\n",
      "Epoch 1156/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1325 - mae: 0.2597 - val_loss: 0.1282 - val_mae: 0.2856\n",
      "Epoch 1157/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1613 - mae: 0.3029 - val_loss: 0.1221 - val_mae: 0.2759\n",
      "Epoch 1158/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1496 - mae: 0.2839 - val_loss: 0.0741 - val_mae: 0.2116\n",
      "Epoch 1159/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1403 - mae: 0.2660 - val_loss: 0.1598 - val_mae: 0.3240\n",
      "Epoch 1160/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1693 - mae: 0.3194 - val_loss: 0.1599 - val_mae: 0.3246\n",
      "Epoch 1161/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1828 - mae: 0.3285 - val_loss: 0.1296 - val_mae: 0.2910\n",
      "Epoch 1162/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1659 - mae: 0.3032 - val_loss: 0.1393 - val_mae: 0.3026\n",
      "Epoch 1163/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1585 - mae: 0.2933 - val_loss: 0.1325 - val_mae: 0.2949\n",
      "Epoch 1164/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1509 - mae: 0.2892 - val_loss: 0.0979 - val_mae: 0.2494\n",
      "Epoch 1165/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1396 - mae: 0.2714 - val_loss: 0.1056 - val_mae: 0.2628\n",
      "Epoch 1166/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1565 - mae: 0.3000 - val_loss: 0.1777 - val_mae: 0.3533\n",
      "Epoch 1167/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1845 - mae: 0.3321 - val_loss: 0.1220 - val_mae: 0.2828\n",
      "Epoch 1168/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1712 - mae: 0.3048 - val_loss: 0.1294 - val_mae: 0.2930\n",
      "Epoch 1169/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1867 - mae: 0.3329 - val_loss: 0.1682 - val_mae: 0.3399\n",
      "Epoch 1170/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1784 - mae: 0.3193 - val_loss: 0.1281 - val_mae: 0.2849\n",
      "Epoch 1171/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1634 - mae: 0.3118 - val_loss: 0.0985 - val_mae: 0.2527\n",
      "Epoch 1172/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1434 - mae: 0.2818 - val_loss: 0.0838 - val_mae: 0.2308\n",
      "Epoch 1173/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1371 - mae: 0.2653 - val_loss: 0.0804 - val_mae: 0.2259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1174/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1766 - mae: 0.3267 - val_loss: 0.1863 - val_mae: 0.3556\n",
      "Epoch 1175/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1600 - mae: 0.2951 - val_loss: 0.1240 - val_mae: 0.2832\n",
      "Epoch 1176/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1448 - mae: 0.2729 - val_loss: 0.1142 - val_mae: 0.2729\n",
      "Epoch 1177/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.2000 - mae: 0.3525 - val_loss: 0.1230 - val_mae: 0.2741\n",
      "Epoch 1178/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1599 - mae: 0.3053 - val_loss: 0.1410 - val_mae: 0.3046\n",
      "Epoch 1179/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2147 - mae: 0.3470 - val_loss: 0.1418 - val_mae: 0.3025\n",
      "Epoch 1180/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2024 - mae: 0.3609 - val_loss: 0.1436 - val_mae: 0.3094\n",
      "Epoch 1181/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2007 - mae: 0.3475 - val_loss: 0.1415 - val_mae: 0.3096\n",
      "Epoch 1182/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2120 - mae: 0.3443 - val_loss: 0.1948 - val_mae: 0.3578\n",
      "Epoch 1183/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2123 - mae: 0.3662 - val_loss: 0.1935 - val_mae: 0.3564\n",
      "Epoch 1184/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2004 - mae: 0.3466 - val_loss: 0.1691 - val_mae: 0.3364\n",
      "Epoch 1185/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1953 - mae: 0.3324 - val_loss: 0.1500 - val_mae: 0.3195\n",
      "Epoch 1186/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1724 - mae: 0.3198 - val_loss: 0.1256 - val_mae: 0.2890\n",
      "Epoch 1187/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1845 - mae: 0.3313 - val_loss: 0.1242 - val_mae: 0.2862\n",
      "Epoch 1188/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1782 - mae: 0.3216 - val_loss: 0.1379 - val_mae: 0.3044\n",
      "Epoch 1189/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1766 - mae: 0.3305 - val_loss: 0.1684 - val_mae: 0.3306\n",
      "Epoch 1190/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2212 - mae: 0.3552 - val_loss: 0.1281 - val_mae: 0.2956\n",
      "Epoch 1191/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1961 - mae: 0.3426 - val_loss: 0.1656 - val_mae: 0.3355\n",
      "Epoch 1192/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1874 - mae: 0.3462 - val_loss: 0.1407 - val_mae: 0.3080\n",
      "Epoch 1193/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1935 - mae: 0.3254 - val_loss: 0.1299 - val_mae: 0.2912\n",
      "Epoch 1194/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1544 - mae: 0.2882 - val_loss: 0.1897 - val_mae: 0.3546\n",
      "Epoch 1195/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.2125 - mae: 0.3644 - val_loss: 0.1223 - val_mae: 0.2893\n",
      "Epoch 1196/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1530 - mae: 0.3026 - val_loss: 0.1146 - val_mae: 0.2770\n",
      "Epoch 1197/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1540 - mae: 0.2949 - val_loss: 0.1073 - val_mae: 0.2650\n",
      "Epoch 1198/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1552 - mae: 0.2886 - val_loss: 0.1215 - val_mae: 0.2845\n",
      "Epoch 1199/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2137 - mae: 0.3708 - val_loss: 0.1355 - val_mae: 0.3011\n",
      "Epoch 1200/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1760 - mae: 0.3254 - val_loss: 0.1263 - val_mae: 0.2919\n",
      "Epoch 1201/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1609 - mae: 0.2944 - val_loss: 0.1455 - val_mae: 0.3107\n",
      "Epoch 1202/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1803 - mae: 0.3297 - val_loss: 0.2859 - val_mae: 0.4436\n",
      "Epoch 1203/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2147 - mae: 0.3566 - val_loss: 0.3579 - val_mae: 0.4951\n",
      "Epoch 1204/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.2489 - mae: 0.3852 - val_loss: 0.1625 - val_mae: 0.3351\n",
      "Epoch 1205/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1877 - mae: 0.3451 - val_loss: 0.2398 - val_mae: 0.3961\n",
      "Epoch 1206/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.2222 - mae: 0.3703 - val_loss: 0.1605 - val_mae: 0.3350\n",
      "Epoch 1207/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1716 - mae: 0.3264 - val_loss: 0.1777 - val_mae: 0.3435\n",
      "Epoch 1208/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1621 - mae: 0.3166 - val_loss: 0.1715 - val_mae: 0.3365\n",
      "Epoch 1209/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1870 - mae: 0.3402 - val_loss: 0.1689 - val_mae: 0.3389\n",
      "Epoch 1210/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1711 - mae: 0.3234 - val_loss: 0.1797 - val_mae: 0.3420\n",
      "Epoch 1211/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1671 - mae: 0.3154 - val_loss: 0.1725 - val_mae: 0.3368\n",
      "Epoch 1212/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1628 - mae: 0.3171 - val_loss: 0.1514 - val_mae: 0.3174\n",
      "Epoch 1213/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1811 - mae: 0.3219 - val_loss: 0.1548 - val_mae: 0.3194\n",
      "Epoch 1214/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1820 - mae: 0.3260 - val_loss: 0.1477 - val_mae: 0.3125\n",
      "Epoch 1215/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1704 - mae: 0.3262 - val_loss: 0.1494 - val_mae: 0.3169\n",
      "Epoch 1216/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1933 - mae: 0.3410 - val_loss: 0.1568 - val_mae: 0.3226\n",
      "Epoch 1217/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1780 - mae: 0.3164 - val_loss: 0.1406 - val_mae: 0.3080\n",
      "Epoch 1218/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1553 - mae: 0.3041 - val_loss: 0.1221 - val_mae: 0.2906\n",
      "Epoch 1219/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1581 - mae: 0.3094 - val_loss: 0.1118 - val_mae: 0.2750\n",
      "Epoch 1220/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1822 - mae: 0.3283 - val_loss: 0.1163 - val_mae: 0.2785\n",
      "Epoch 1221/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1740 - mae: 0.3196 - val_loss: 0.1253 - val_mae: 0.2948\n",
      "Epoch 1222/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1607 - mae: 0.2998 - val_loss: 0.1430 - val_mae: 0.3062\n",
      "Epoch 1223/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1871 - mae: 0.3432 - val_loss: 0.1769 - val_mae: 0.3435\n",
      "Epoch 1224/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2201 - mae: 0.3649 - val_loss: 0.1688 - val_mae: 0.3361\n",
      "Epoch 1225/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2000 - mae: 0.3440 - val_loss: 0.2197 - val_mae: 0.3831\n",
      "Epoch 1226/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2009 - mae: 0.3641 - val_loss: 0.1864 - val_mae: 0.3510\n",
      "Epoch 1227/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2039 - mae: 0.3565 - val_loss: 0.1634 - val_mae: 0.3337\n",
      "Epoch 1228/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1566 - mae: 0.3141 - val_loss: 0.1766 - val_mae: 0.3487\n",
      "Epoch 1229/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1645 - mae: 0.3307 - val_loss: 0.1703 - val_mae: 0.3323\n",
      "Epoch 1230/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1688 - mae: 0.3169 - val_loss: 0.1483 - val_mae: 0.3153\n",
      "Epoch 1231/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1412 - mae: 0.2979 - val_loss: 0.1392 - val_mae: 0.3078\n",
      "Epoch 1232/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1353 - mae: 0.2955 - val_loss: 0.1500 - val_mae: 0.3102\n",
      "Epoch 1233/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1637 - mae: 0.3095 - val_loss: 0.1612 - val_mae: 0.3269\n",
      "Epoch 1234/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1385 - mae: 0.2971 - val_loss: 0.1473 - val_mae: 0.3159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1235/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1522 - mae: 0.3066 - val_loss: 0.1311 - val_mae: 0.2974\n",
      "Epoch 1236/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1443 - mae: 0.2918 - val_loss: 0.1513 - val_mae: 0.3174\n",
      "Epoch 1237/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1777 - mae: 0.3368 - val_loss: 0.1716 - val_mae: 0.3345\n",
      "Epoch 1238/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.1575 - mae: 0.3168 - val_loss: 0.1381 - val_mae: 0.3073\n",
      "Epoch 1239/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1521 - mae: 0.3040 - val_loss: 0.1364 - val_mae: 0.2998\n",
      "Epoch 1240/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1397 - mae: 0.2908 - val_loss: 0.1502 - val_mae: 0.3162\n",
      "Epoch 1241/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1478 - mae: 0.3060 - val_loss: 0.1503 - val_mae: 0.3133\n",
      "Epoch 1242/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1419 - mae: 0.2917 - val_loss: 0.1138 - val_mae: 0.2733\n",
      "Epoch 1243/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1318 - mae: 0.2805 - val_loss: 0.1370 - val_mae: 0.3060\n",
      "Epoch 1244/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1458 - mae: 0.2887 - val_loss: 0.1678 - val_mae: 0.3296\n",
      "Epoch 1245/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1678 - mae: 0.3112 - val_loss: 0.2285 - val_mae: 0.3972\n",
      "Epoch 1246/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1813 - mae: 0.3311 - val_loss: 0.1742 - val_mae: 0.3355\n",
      "Epoch 1247/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1656 - mae: 0.3119 - val_loss: 0.1661 - val_mae: 0.3297\n",
      "Epoch 1248/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1744 - mae: 0.3214 - val_loss: 0.1447 - val_mae: 0.3120\n",
      "Epoch 1249/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1588 - mae: 0.3054 - val_loss: 0.1321 - val_mae: 0.2990\n",
      "Epoch 1250/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1675 - mae: 0.3117 - val_loss: 0.1391 - val_mae: 0.3009\n",
      "Epoch 1251/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1624 - mae: 0.3054 - val_loss: 0.2135 - val_mae: 0.3716\n",
      "Epoch 1252/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1731 - mae: 0.3285 - val_loss: 0.1514 - val_mae: 0.3192\n",
      "Epoch 1253/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1464 - mae: 0.2967 - val_loss: 0.1393 - val_mae: 0.3109\n",
      "Epoch 1254/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1516 - mae: 0.3063 - val_loss: 0.1444 - val_mae: 0.3109\n",
      "Epoch 1255/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1736 - mae: 0.3288 - val_loss: 0.1369 - val_mae: 0.3063\n",
      "Epoch 1256/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1484 - mae: 0.3035 - val_loss: 0.1300 - val_mae: 0.2933\n",
      "Epoch 1257/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1337 - mae: 0.2849 - val_loss: 0.1178 - val_mae: 0.2849\n",
      "Epoch 1258/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1434 - mae: 0.3009 - val_loss: 0.2142 - val_mae: 0.3753\n",
      "Epoch 1259/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1634 - mae: 0.3177 - val_loss: 0.1336 - val_mae: 0.2989\n",
      "Epoch 1260/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1292 - mae: 0.2785 - val_loss: 0.1164 - val_mae: 0.2779\n",
      "Epoch 1261/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1310 - mae: 0.2847 - val_loss: 0.1917 - val_mae: 0.3536\n",
      "Epoch 1262/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1539 - mae: 0.3063 - val_loss: 0.1252 - val_mae: 0.2924\n",
      "Epoch 1263/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1311 - mae: 0.2827 - val_loss: 0.1257 - val_mae: 0.2911\n",
      "Epoch 1264/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1297 - mae: 0.2760 - val_loss: 0.1400 - val_mae: 0.3025\n",
      "Epoch 1265/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1501 - mae: 0.3096 - val_loss: 0.1371 - val_mae: 0.3010\n",
      "Epoch 1266/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1729 - mae: 0.3229 - val_loss: 0.1361 - val_mae: 0.3019\n",
      "Epoch 1267/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1323 - mae: 0.2925 - val_loss: 0.1270 - val_mae: 0.2920\n",
      "Epoch 1268/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1151 - mae: 0.2766 - val_loss: 0.1209 - val_mae: 0.2813\n",
      "Epoch 1269/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1159 - mae: 0.2731 - val_loss: 0.1310 - val_mae: 0.2944\n",
      "Epoch 1270/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1191 - mae: 0.2781 - val_loss: 0.1133 - val_mae: 0.2714\n",
      "Epoch 1271/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1119 - mae: 0.2694 - val_loss: 0.1121 - val_mae: 0.2711\n",
      "Epoch 1272/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1259 - mae: 0.2852 - val_loss: 0.1225 - val_mae: 0.2807\n",
      "Epoch 1273/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1096 - mae: 0.2644 - val_loss: 0.1026 - val_mae: 0.2591\n",
      "Epoch 1274/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1101 - mae: 0.2697 - val_loss: 0.1167 - val_mae: 0.2710\n",
      "Epoch 1275/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1045 - mae: 0.2571 - val_loss: 0.1085 - val_mae: 0.2683\n",
      "Epoch 1276/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1141 - mae: 0.2610 - val_loss: 0.1694 - val_mae: 0.3377\n",
      "Epoch 1277/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1746 - mae: 0.3331 - val_loss: 0.5252 - val_mae: 0.6325\n",
      "Epoch 1278/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.2711 - mae: 0.4185 - val_loss: 0.2223 - val_mae: 0.3845\n",
      "Epoch 1279/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1908 - mae: 0.3532 - val_loss: 0.1790 - val_mae: 0.3332\n",
      "Epoch 1280/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1749 - mae: 0.3392 - val_loss: 0.2444 - val_mae: 0.3893\n",
      "Epoch 1281/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1711 - mae: 0.3318 - val_loss: 0.1409 - val_mae: 0.3090\n",
      "Epoch 1282/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1446 - mae: 0.3034 - val_loss: 0.2110 - val_mae: 0.3720\n",
      "Epoch 1283/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1692 - mae: 0.3292 - val_loss: 0.1392 - val_mae: 0.3092\n",
      "Epoch 1284/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1505 - mae: 0.3157 - val_loss: 0.2004 - val_mae: 0.3530\n",
      "Epoch 1285/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1600 - mae: 0.3209 - val_loss: 0.1417 - val_mae: 0.3095\n",
      "Epoch 1286/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1396 - mae: 0.3043 - val_loss: 0.1498 - val_mae: 0.3190\n",
      "Epoch 1287/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1274 - mae: 0.2884 - val_loss: 0.1596 - val_mae: 0.3189\n",
      "Epoch 1288/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1302 - mae: 0.2980 - val_loss: 0.1321 - val_mae: 0.2974\n",
      "Epoch 1289/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1271 - mae: 0.2878 - val_loss: 0.1619 - val_mae: 0.3249\n",
      "Epoch 1290/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1404 - mae: 0.3026 - val_loss: 0.1627 - val_mae: 0.3213\n",
      "Epoch 1291/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1482 - mae: 0.3105 - val_loss: 0.1702 - val_mae: 0.3288\n",
      "Epoch 1292/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1328 - mae: 0.2966 - val_loss: 0.1646 - val_mae: 0.3303\n",
      "Epoch 1293/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.1378 - mae: 0.3007 - val_loss: 0.1695 - val_mae: 0.3360\n",
      "Epoch 1294/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1515 - mae: 0.3128 - val_loss: 0.1836 - val_mae: 0.3418\n",
      "Epoch 1295/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1570 - mae: 0.3178 - val_loss: 0.1676 - val_mae: 0.3261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1296/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1337 - mae: 0.2936 - val_loss: 0.1739 - val_mae: 0.3396\n",
      "Epoch 1297/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1442 - mae: 0.3064 - val_loss: 0.1382 - val_mae: 0.3004\n",
      "Epoch 1298/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1264 - mae: 0.2887 - val_loss: 0.1915 - val_mae: 0.3439\n",
      "Epoch 1299/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1521 - mae: 0.3125 - val_loss: 0.1509 - val_mae: 0.3192\n",
      "Epoch 1300/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1285 - mae: 0.2938 - val_loss: 0.1408 - val_mae: 0.3073\n",
      "Epoch 1301/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1217 - mae: 0.2813 - val_loss: 0.1357 - val_mae: 0.2969\n",
      "Epoch 1302/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1228 - mae: 0.2863 - val_loss: 0.1453 - val_mae: 0.3079\n",
      "Epoch 1303/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1241 - mae: 0.2870 - val_loss: 0.1438 - val_mae: 0.3129\n",
      "Epoch 1304/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1241 - mae: 0.2875 - val_loss: 0.1374 - val_mae: 0.3024\n",
      "Epoch 1305/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1254 - mae: 0.2884 - val_loss: 0.1774 - val_mae: 0.3431\n",
      "Epoch 1306/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1396 - mae: 0.2989 - val_loss: 0.1577 - val_mae: 0.3174\n",
      "Epoch 1307/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1358 - mae: 0.2975 - val_loss: 0.1583 - val_mae: 0.3203\n",
      "Epoch 1308/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1289 - mae: 0.2925 - val_loss: 0.2252 - val_mae: 0.3783\n",
      "Epoch 1309/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1413 - mae: 0.3049 - val_loss: 0.1461 - val_mae: 0.3127\n",
      "Epoch 1310/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1410 - mae: 0.3049 - val_loss: 0.1493 - val_mae: 0.3153\n",
      "Epoch 1311/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1344 - mae: 0.2968 - val_loss: 0.1525 - val_mae: 0.3137\n",
      "Epoch 1312/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1357 - mae: 0.2972 - val_loss: 0.1367 - val_mae: 0.3026\n",
      "Epoch 1313/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1241 - mae: 0.2832 - val_loss: 0.1739 - val_mae: 0.3356\n",
      "Epoch 1314/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1408 - mae: 0.3027 - val_loss: 0.1328 - val_mae: 0.3013\n",
      "Epoch 1315/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1376 - mae: 0.3025 - val_loss: 0.1819 - val_mae: 0.3325\n",
      "Epoch 1316/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1549 - mae: 0.3160 - val_loss: 0.1571 - val_mae: 0.3175\n",
      "Epoch 1317/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1369 - mae: 0.3014 - val_loss: 0.1453 - val_mae: 0.3116\n",
      "Epoch 1318/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1325 - mae: 0.2952 - val_loss: 0.1346 - val_mae: 0.3000\n",
      "Epoch 1319/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1312 - mae: 0.2908 - val_loss: 0.1392 - val_mae: 0.3024\n",
      "Epoch 1320/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1379 - mae: 0.2986 - val_loss: 0.1411 - val_mae: 0.3082\n",
      "Epoch 1321/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1293 - mae: 0.2946 - val_loss: 0.1824 - val_mae: 0.3411\n",
      "Epoch 1322/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1513 - mae: 0.3155 - val_loss: 0.1806 - val_mae: 0.3341\n",
      "Epoch 1323/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1726 - mae: 0.3344 - val_loss: 0.1321 - val_mae: 0.2983\n",
      "Epoch 1324/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1335 - mae: 0.2922 - val_loss: 0.1461 - val_mae: 0.3157\n",
      "Epoch 1325/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1221 - mae: 0.2861 - val_loss: 0.1327 - val_mae: 0.2999\n",
      "Epoch 1326/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1299 - mae: 0.2962 - val_loss: 0.1302 - val_mae: 0.2921\n",
      "Epoch 1327/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1208 - mae: 0.2841 - val_loss: 0.1242 - val_mae: 0.2889\n",
      "Epoch 1328/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1187 - mae: 0.2829 - val_loss: 0.1331 - val_mae: 0.2980\n",
      "Epoch 1329/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1262 - mae: 0.2886 - val_loss: 0.1302 - val_mae: 0.2965\n",
      "Epoch 1330/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1237 - mae: 0.2866 - val_loss: 0.1645 - val_mae: 0.3282\n",
      "Epoch 1331/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1486 - mae: 0.3097 - val_loss: 0.1728 - val_mae: 0.3381\n",
      "Epoch 1332/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1613 - mae: 0.3221 - val_loss: 0.1350 - val_mae: 0.2966\n",
      "Epoch 1333/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1397 - mae: 0.3052 - val_loss: 0.1251 - val_mae: 0.2917\n",
      "Epoch 1334/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1234 - mae: 0.2876 - val_loss: 0.1383 - val_mae: 0.3023\n",
      "Epoch 1335/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1235 - mae: 0.2865 - val_loss: 0.1672 - val_mae: 0.3312\n",
      "Epoch 1336/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1579 - mae: 0.3164 - val_loss: 0.1511 - val_mae: 0.3128\n",
      "Epoch 1337/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1723 - mae: 0.3333 - val_loss: 0.1225 - val_mae: 0.2857\n",
      "Epoch 1338/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1566 - mae: 0.3180 - val_loss: 0.1556 - val_mae: 0.3119\n",
      "Epoch 1339/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1551 - mae: 0.3184 - val_loss: 0.1469 - val_mae: 0.3055\n",
      "Epoch 1340/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1453 - mae: 0.3060 - val_loss: 0.1724 - val_mae: 0.3322\n",
      "Epoch 1341/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1524 - mae: 0.3164 - val_loss: 0.1267 - val_mae: 0.2944\n",
      "Epoch 1342/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1265 - mae: 0.2926 - val_loss: 0.1368 - val_mae: 0.3058\n",
      "Epoch 1343/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1386 - mae: 0.3054 - val_loss: 0.1195 - val_mae: 0.2852\n",
      "Epoch 1344/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1249 - mae: 0.2855 - val_loss: 0.1679 - val_mae: 0.3346\n",
      "Epoch 1345/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1307 - mae: 0.2924 - val_loss: 0.1298 - val_mae: 0.2943\n",
      "Epoch 1346/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1365 - mae: 0.2994 - val_loss: 0.1496 - val_mae: 0.3163\n",
      "Epoch 1347/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1361 - mae: 0.2978 - val_loss: 0.1300 - val_mae: 0.2964\n",
      "Epoch 1348/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1469 - mae: 0.3111 - val_loss: 0.1302 - val_mae: 0.2915\n",
      "Epoch 1349/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1414 - mae: 0.3020 - val_loss: 0.1809 - val_mae: 0.3367\n",
      "Epoch 1350/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1799 - mae: 0.3450 - val_loss: 0.2075 - val_mae: 0.3621\n",
      "Epoch 1351/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.2040 - mae: 0.3655 - val_loss: 0.1188 - val_mae: 0.2860\n",
      "Epoch 1352/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1667 - mae: 0.3296 - val_loss: 0.1438 - val_mae: 0.3114\n",
      "Epoch 1353/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1394 - mae: 0.2996 - val_loss: 0.1465 - val_mae: 0.3119\n",
      "Epoch 1354/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1477 - mae: 0.3100 - val_loss: 0.1438 - val_mae: 0.3111\n",
      "Epoch 1355/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1655 - mae: 0.3306 - val_loss: 0.1666 - val_mae: 0.3202\n",
      "Epoch 1356/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.1588 - mae: 0.3267 - val_loss: 0.1280 - val_mae: 0.2909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1357/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1366 - mae: 0.2939 - val_loss: 0.1257 - val_mae: 0.2902\n",
      "Epoch 1358/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1251 - mae: 0.2869 - val_loss: 0.1287 - val_mae: 0.2928\n",
      "Epoch 1359/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1245 - mae: 0.2872 - val_loss: 0.1316 - val_mae: 0.3003\n",
      "Epoch 1360/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.1281 - mae: 0.2933 - val_loss: 0.1556 - val_mae: 0.3083\n",
      "Epoch 1361/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1445 - mae: 0.3051 - val_loss: 0.1371 - val_mae: 0.3001\n",
      "Epoch 1362/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1276 - mae: 0.2907 - val_loss: 0.1344 - val_mae: 0.3001\n",
      "Epoch 1363/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1261 - mae: 0.2884 - val_loss: 0.1229 - val_mae: 0.2856\n",
      "Epoch 1364/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1192 - mae: 0.2811 - val_loss: 0.1322 - val_mae: 0.2970\n",
      "Epoch 1365/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1391 - mae: 0.3007 - val_loss: 0.1828 - val_mae: 0.3464\n",
      "Epoch 1366/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1845 - mae: 0.3472 - val_loss: 0.1301 - val_mae: 0.2933\n",
      "Epoch 1367/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1448 - mae: 0.3093 - val_loss: 0.1507 - val_mae: 0.3027\n",
      "Epoch 1368/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1489 - mae: 0.3122 - val_loss: 0.1177 - val_mae: 0.2796\n",
      "Epoch 1369/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1331 - mae: 0.2939 - val_loss: 0.1515 - val_mae: 0.3206\n",
      "Epoch 1370/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1394 - mae: 0.3034 - val_loss: 0.1296 - val_mae: 0.2965\n",
      "Epoch 1371/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1486 - mae: 0.3128 - val_loss: 0.1712 - val_mae: 0.3226\n",
      "Epoch 1372/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1572 - mae: 0.3137 - val_loss: 0.1371 - val_mae: 0.3028\n",
      "Epoch 1373/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1451 - mae: 0.3065 - val_loss: 0.1927 - val_mae: 0.3548\n",
      "Epoch 1374/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1491 - mae: 0.3092 - val_loss: 0.1365 - val_mae: 0.2953\n",
      "Epoch 1375/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1405 - mae: 0.3022 - val_loss: 0.1323 - val_mae: 0.2952\n",
      "Epoch 1376/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1314 - mae: 0.2937 - val_loss: 0.1312 - val_mae: 0.2926\n",
      "Epoch 1377/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1298 - mae: 0.2918 - val_loss: 0.1193 - val_mae: 0.2823\n",
      "Epoch 1378/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1207 - mae: 0.2834 - val_loss: 0.1433 - val_mae: 0.3000\n",
      "Epoch 1379/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1510 - mae: 0.3155 - val_loss: 0.1307 - val_mae: 0.2920\n",
      "Epoch 1380/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1228 - mae: 0.2826 - val_loss: 0.1639 - val_mae: 0.3268\n",
      "Epoch 1381/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1483 - mae: 0.3131 - val_loss: 0.1551 - val_mae: 0.3062\n",
      "Epoch 1382/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1605 - mae: 0.3207 - val_loss: 0.1616 - val_mae: 0.3144\n",
      "Epoch 1383/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1718 - mae: 0.3317 - val_loss: 0.1406 - val_mae: 0.3050\n",
      "Epoch 1384/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1404 - mae: 0.2962 - val_loss: 0.1893 - val_mae: 0.3536\n",
      "Epoch 1385/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1957 - mae: 0.3563 - val_loss: 0.1339 - val_mae: 0.2917\n",
      "Epoch 1386/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1556 - mae: 0.3197 - val_loss: 0.1467 - val_mae: 0.3024\n",
      "Epoch 1387/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1456 - mae: 0.3077 - val_loss: 0.1606 - val_mae: 0.3307\n",
      "Epoch 1388/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1469 - mae: 0.3084 - val_loss: 0.1534 - val_mae: 0.3187\n",
      "Epoch 1389/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1594 - mae: 0.3235 - val_loss: 0.1384 - val_mae: 0.2955\n",
      "Epoch 1390/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1479 - mae: 0.3109 - val_loss: 0.1516 - val_mae: 0.3065\n",
      "Epoch 1391/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1575 - mae: 0.3145 - val_loss: 0.1625 - val_mae: 0.3271\n",
      "Epoch 1392/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1563 - mae: 0.3175 - val_loss: 0.1322 - val_mae: 0.2986\n",
      "Epoch 1393/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1347 - mae: 0.2977 - val_loss: 0.1436 - val_mae: 0.3037\n",
      "Epoch 1394/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1313 - mae: 0.2922 - val_loss: 0.1537 - val_mae: 0.3194\n",
      "Epoch 1395/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1353 - mae: 0.2949 - val_loss: 0.1340 - val_mae: 0.3012\n",
      "Epoch 1396/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1247 - mae: 0.2862 - val_loss: 0.1302 - val_mae: 0.2957\n",
      "Epoch 1397/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1306 - mae: 0.2963 - val_loss: 0.1494 - val_mae: 0.3159\n",
      "Epoch 1398/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1352 - mae: 0.2982 - val_loss: 0.1302 - val_mae: 0.2961\n",
      "Epoch 1399/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1250 - mae: 0.2891 - val_loss: 0.1348 - val_mae: 0.2985\n",
      "Epoch 1400/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1297 - mae: 0.2922 - val_loss: 0.1311 - val_mae: 0.2934\n",
      "Epoch 1401/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1350 - mae: 0.2994 - val_loss: 0.1555 - val_mae: 0.3208\n",
      "Epoch 1402/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1380 - mae: 0.2999 - val_loss: 0.1358 - val_mae: 0.3033\n",
      "Epoch 1403/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1267 - mae: 0.2926 - val_loss: 0.1519 - val_mae: 0.3059\n",
      "Epoch 1404/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1505 - mae: 0.3146 - val_loss: 0.1547 - val_mae: 0.3084\n",
      "Epoch 1405/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1585 - mae: 0.3181 - val_loss: 0.1348 - val_mae: 0.2980\n",
      "Epoch 1406/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1467 - mae: 0.3049 - val_loss: 0.1593 - val_mae: 0.3239\n",
      "Epoch 1407/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1367 - mae: 0.2987 - val_loss: 0.1432 - val_mae: 0.3072\n",
      "Epoch 1408/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1338 - mae: 0.2990 - val_loss: 0.1249 - val_mae: 0.2836\n",
      "Epoch 1409/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.1372 - mae: 0.2988 - val_loss: 0.1501 - val_mae: 0.3050\n",
      "Epoch 1410/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1529 - mae: 0.3160 - val_loss: 0.1322 - val_mae: 0.2853\n",
      "Epoch 1411/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1376 - mae: 0.3001 - val_loss: 0.1339 - val_mae: 0.2954\n",
      "Epoch 1412/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1244 - mae: 0.2885 - val_loss: 0.1207 - val_mae: 0.2780\n",
      "Epoch 1413/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1183 - mae: 0.2760 - val_loss: 0.1451 - val_mae: 0.3123\n",
      "Epoch 1414/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1320 - mae: 0.2919 - val_loss: 0.1632 - val_mae: 0.3264\n",
      "Epoch 1415/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1394 - mae: 0.3020 - val_loss: 0.1568 - val_mae: 0.3224\n",
      "Epoch 1416/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1430 - mae: 0.3026 - val_loss: 0.1303 - val_mae: 0.2908\n",
      "Epoch 1417/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1401 - mae: 0.3046 - val_loss: 0.1288 - val_mae: 0.2861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1418/2000\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.1322 - mae: 0.2926 - val_loss: 0.1274 - val_mae: 0.2837\n",
      "Epoch 1419/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1307 - mae: 0.2892 - val_loss: 0.1499 - val_mae: 0.3169\n",
      "Epoch 1420/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1417 - mae: 0.3009 - val_loss: 0.1602 - val_mae: 0.3217\n",
      "Epoch 1421/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1377 - mae: 0.3001 - val_loss: 0.1217 - val_mae: 0.2847\n",
      "Epoch 1422/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1269 - mae: 0.2878 - val_loss: 0.1445 - val_mae: 0.3050\n",
      "Epoch 1423/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1529 - mae: 0.3112 - val_loss: 0.1626 - val_mae: 0.3277\n",
      "Epoch 1424/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1512 - mae: 0.3130 - val_loss: 0.1314 - val_mae: 0.2928\n",
      "Epoch 1425/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1269 - mae: 0.2929 - val_loss: 0.1165 - val_mae: 0.2749\n",
      "Epoch 1426/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1146 - mae: 0.2738 - val_loss: 0.1595 - val_mae: 0.3248\n",
      "Epoch 1427/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1466 - mae: 0.3119 - val_loss: 0.1196 - val_mae: 0.2819\n",
      "Epoch 1428/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1266 - mae: 0.2920 - val_loss: 0.1219 - val_mae: 0.2780\n",
      "Epoch 1429/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1194 - mae: 0.2783 - val_loss: 0.1754 - val_mae: 0.3416\n",
      "Epoch 1430/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1459 - mae: 0.3093 - val_loss: 0.1207 - val_mae: 0.2825\n",
      "Epoch 1431/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1279 - mae: 0.2899 - val_loss: 0.1321 - val_mae: 0.2847\n",
      "Epoch 1432/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1376 - mae: 0.2972 - val_loss: 0.1553 - val_mae: 0.3224\n",
      "Epoch 1433/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1293 - mae: 0.2906 - val_loss: 0.1192 - val_mae: 0.2817\n",
      "Epoch 1434/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1221 - mae: 0.2837 - val_loss: 0.1323 - val_mae: 0.2921\n",
      "Epoch 1435/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1356 - mae: 0.2986 - val_loss: 0.1273 - val_mae: 0.2905\n",
      "Epoch 1436/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1363 - mae: 0.2958 - val_loss: 0.1252 - val_mae: 0.2882\n",
      "Epoch 1437/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1309 - mae: 0.2929 - val_loss: 0.1843 - val_mae: 0.3514\n",
      "Epoch 1438/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1467 - mae: 0.3054 - val_loss: 0.1455 - val_mae: 0.3140\n",
      "Epoch 1439/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1710 - mae: 0.3357 - val_loss: 0.2333 - val_mae: 0.3828\n",
      "Epoch 1440/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1977 - mae: 0.3587 - val_loss: 0.1315 - val_mae: 0.2870\n",
      "Epoch 1441/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1336 - mae: 0.2943 - val_loss: 0.1367 - val_mae: 0.3015\n",
      "Epoch 1442/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1231 - mae: 0.2861 - val_loss: 0.1228 - val_mae: 0.2870\n",
      "Epoch 1443/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1206 - mae: 0.2849 - val_loss: 0.1438 - val_mae: 0.2949\n",
      "Epoch 1444/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1347 - mae: 0.2946 - val_loss: 0.1299 - val_mae: 0.2893\n",
      "Epoch 1445/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1519 - mae: 0.3100 - val_loss: 0.1908 - val_mae: 0.3530\n",
      "Epoch 1446/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1416 - mae: 0.3044 - val_loss: 0.1312 - val_mae: 0.2900\n",
      "Epoch 1447/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1442 - mae: 0.3082 - val_loss: 0.1364 - val_mae: 0.2880\n",
      "Epoch 1448/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1348 - mae: 0.2993 - val_loss: 0.1454 - val_mae: 0.3050\n",
      "Epoch 1449/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1335 - mae: 0.2965 - val_loss: 0.1482 - val_mae: 0.3175\n",
      "Epoch 1450/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1484 - mae: 0.3128 - val_loss: 0.1476 - val_mae: 0.3055\n",
      "Epoch 1451/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1426 - mae: 0.3087 - val_loss: 0.1267 - val_mae: 0.2832\n",
      "Epoch 1452/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1328 - mae: 0.2952 - val_loss: 0.1345 - val_mae: 0.2874\n",
      "Epoch 1453/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1374 - mae: 0.2980 - val_loss: 0.1453 - val_mae: 0.3143\n",
      "Epoch 1454/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1389 - mae: 0.3028 - val_loss: 0.1770 - val_mae: 0.3428\n",
      "Epoch 1455/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1463 - mae: 0.3063 - val_loss: 0.1454 - val_mae: 0.3015\n",
      "Epoch 1456/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1288 - mae: 0.2900 - val_loss: 0.1274 - val_mae: 0.2926\n",
      "Epoch 1457/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1230 - mae: 0.2840 - val_loss: 0.1523 - val_mae: 0.3201\n",
      "Epoch 1458/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1337 - mae: 0.2966 - val_loss: 0.1366 - val_mae: 0.2889\n",
      "Epoch 1459/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1240 - mae: 0.2853 - val_loss: 0.1192 - val_mae: 0.2792\n",
      "Epoch 1460/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1253 - mae: 0.2847 - val_loss: 0.1556 - val_mae: 0.3226\n",
      "Epoch 1461/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1431 - mae: 0.3036 - val_loss: 0.1360 - val_mae: 0.3034\n",
      "Epoch 1462/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1410 - mae: 0.3069 - val_loss: 0.1676 - val_mae: 0.3320\n",
      "Epoch 1463/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1294 - mae: 0.2888 - val_loss: 0.1350 - val_mae: 0.2899\n",
      "Epoch 1464/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1373 - mae: 0.3021 - val_loss: 0.1425 - val_mae: 0.3072\n",
      "Epoch 1465/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1435 - mae: 0.3060 - val_loss: 0.1539 - val_mae: 0.3214\n",
      "Epoch 1466/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1389 - mae: 0.3026 - val_loss: 0.1381 - val_mae: 0.2955\n",
      "Epoch 1467/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1439 - mae: 0.3067 - val_loss: 0.1487 - val_mae: 0.3145\n",
      "Epoch 1468/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1355 - mae: 0.2968 - val_loss: 0.1422 - val_mae: 0.3116\n",
      "Epoch 1469/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1341 - mae: 0.2972 - val_loss: 0.1388 - val_mae: 0.2986\n",
      "Epoch 1470/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1404 - mae: 0.3072 - val_loss: 0.1318 - val_mae: 0.2959\n",
      "Epoch 1471/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1345 - mae: 0.2996 - val_loss: 0.1428 - val_mae: 0.3092\n",
      "Epoch 1472/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1321 - mae: 0.2957 - val_loss: 0.1570 - val_mae: 0.3116\n",
      "Epoch 1473/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1590 - mae: 0.3290 - val_loss: 0.1294 - val_mae: 0.2893\n",
      "Epoch 1474/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1236 - mae: 0.2870 - val_loss: 0.1607 - val_mae: 0.3280\n",
      "Epoch 1475/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1290 - mae: 0.2896 - val_loss: 0.1402 - val_mae: 0.2941\n",
      "Epoch 1476/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1335 - mae: 0.3013 - val_loss: 0.1306 - val_mae: 0.2936\n",
      "Epoch 1477/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1343 - mae: 0.2938 - val_loss: 0.1350 - val_mae: 0.2974\n",
      "Epoch 1478/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1362 - mae: 0.3000 - val_loss: 0.1664 - val_mae: 0.3265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1479/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1470 - mae: 0.3084 - val_loss: 0.1546 - val_mae: 0.3198\n",
      "Epoch 1480/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1466 - mae: 0.3087 - val_loss: 0.1562 - val_mae: 0.3229\n",
      "Epoch 1481/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1238 - mae: 0.2858 - val_loss: 0.1353 - val_mae: 0.2927\n",
      "Epoch 1482/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1303 - mae: 0.2945 - val_loss: 0.1359 - val_mae: 0.2969\n",
      "Epoch 1483/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1344 - mae: 0.2986 - val_loss: 0.1208 - val_mae: 0.2811\n",
      "Epoch 1484/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1289 - mae: 0.2907 - val_loss: 0.1229 - val_mae: 0.2882\n",
      "Epoch 1485/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1321 - mae: 0.2961 - val_loss: 0.1400 - val_mae: 0.2971\n",
      "Epoch 1486/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1266 - mae: 0.2899 - val_loss: 0.1357 - val_mae: 0.2898\n",
      "Epoch 1487/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1417 - mae: 0.3035 - val_loss: 0.1451 - val_mae: 0.3106\n",
      "Epoch 1488/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1500 - mae: 0.3141 - val_loss: 0.1298 - val_mae: 0.2960\n",
      "Epoch 1489/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1291 - mae: 0.2918 - val_loss: 0.1382 - val_mae: 0.3039\n",
      "Epoch 1490/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1248 - mae: 0.2887 - val_loss: 0.1206 - val_mae: 0.2807\n",
      "Epoch 1491/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1165 - mae: 0.2783 - val_loss: 0.1490 - val_mae: 0.3145\n",
      "Epoch 1492/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1329 - mae: 0.2948 - val_loss: 0.1322 - val_mae: 0.2964\n",
      "Epoch 1493/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1226 - mae: 0.2862 - val_loss: 0.1246 - val_mae: 0.2769\n",
      "Epoch 1494/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1348 - mae: 0.2995 - val_loss: 0.1381 - val_mae: 0.2965\n",
      "Epoch 1495/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1368 - mae: 0.2964 - val_loss: 0.1523 - val_mae: 0.3188\n",
      "Epoch 1496/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1356 - mae: 0.2968 - val_loss: 0.1544 - val_mae: 0.3188\n",
      "Epoch 1497/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1349 - mae: 0.2985 - val_loss: 0.1346 - val_mae: 0.2854\n",
      "Epoch 1498/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1305 - mae: 0.2892 - val_loss: 0.1385 - val_mae: 0.3003\n",
      "Epoch 1499/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1352 - mae: 0.2994 - val_loss: 0.1303 - val_mae: 0.2916\n",
      "Epoch 1500/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1342 - mae: 0.2973 - val_loss: 0.1537 - val_mae: 0.3149\n",
      "Epoch 1501/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1265 - mae: 0.2890 - val_loss: 0.1349 - val_mae: 0.2986\n",
      "Epoch 1502/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1346 - mae: 0.2967 - val_loss: 0.1692 - val_mae: 0.3371\n",
      "Epoch 1503/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1489 - mae: 0.3123 - val_loss: 0.1448 - val_mae: 0.2983\n",
      "Epoch 1504/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1532 - mae: 0.3180 - val_loss: 0.1634 - val_mae: 0.3217\n",
      "Epoch 1505/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1468 - mae: 0.3058 - val_loss: 0.2044 - val_mae: 0.3688\n",
      "Epoch 1506/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1708 - mae: 0.3319 - val_loss: 0.1641 - val_mae: 0.3331\n",
      "Epoch 1507/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1309 - mae: 0.2969 - val_loss: 0.1243 - val_mae: 0.2750\n",
      "Epoch 1508/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1332 - mae: 0.2960 - val_loss: 0.1227 - val_mae: 0.2814\n",
      "Epoch 1509/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1221 - mae: 0.2831 - val_loss: 0.1351 - val_mae: 0.2983\n",
      "Epoch 1510/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1266 - mae: 0.2911 - val_loss: 0.1284 - val_mae: 0.2843\n",
      "Epoch 1511/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1195 - mae: 0.2767 - val_loss: 0.1708 - val_mae: 0.3381\n",
      "Epoch 1512/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1571 - mae: 0.3205 - val_loss: 0.1789 - val_mae: 0.3462\n",
      "Epoch 1513/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1720 - mae: 0.3346 - val_loss: 0.1879 - val_mae: 0.3391\n",
      "Epoch 1514/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1852 - mae: 0.3463 - val_loss: 0.1314 - val_mae: 0.2865\n",
      "Epoch 1515/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1616 - mae: 0.3176 - val_loss: 0.2876 - val_mae: 0.4302\n",
      "Epoch 1516/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1815 - mae: 0.3362 - val_loss: 0.1512 - val_mae: 0.3084\n",
      "Epoch 1517/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1546 - mae: 0.3162 - val_loss: 0.1518 - val_mae: 0.3021\n",
      "Epoch 1518/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1553 - mae: 0.3145 - val_loss: 0.2050 - val_mae: 0.3684\n",
      "Epoch 1519/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1642 - mae: 0.3228 - val_loss: 0.1441 - val_mae: 0.3156\n",
      "Epoch 1520/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1365 - mae: 0.3020 - val_loss: 0.1550 - val_mae: 0.3138\n",
      "Epoch 1521/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1373 - mae: 0.3017 - val_loss: 0.1203 - val_mae: 0.2841\n",
      "Epoch 1522/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1255 - mae: 0.2881 - val_loss: 0.1230 - val_mae: 0.2834\n",
      "Epoch 1523/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1260 - mae: 0.2912 - val_loss: 0.1308 - val_mae: 0.2924\n",
      "Epoch 1524/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1189 - mae: 0.2826 - val_loss: 0.1335 - val_mae: 0.2981\n",
      "Epoch 1525/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1223 - mae: 0.2853 - val_loss: 0.1238 - val_mae: 0.2892\n",
      "Epoch 1526/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1301 - mae: 0.2960 - val_loss: 0.1413 - val_mae: 0.2970\n",
      "Epoch 1527/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1348 - mae: 0.2996 - val_loss: 0.1233 - val_mae: 0.2821\n",
      "Epoch 1528/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1320 - mae: 0.2958 - val_loss: 0.1487 - val_mae: 0.3061\n",
      "Epoch 1529/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1275 - mae: 0.2908 - val_loss: 0.1266 - val_mae: 0.2858\n",
      "Epoch 1530/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1232 - mae: 0.2841 - val_loss: 0.1422 - val_mae: 0.3111\n",
      "Epoch 1531/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1298 - mae: 0.2941 - val_loss: 0.1324 - val_mae: 0.2879\n",
      "Epoch 1532/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1245 - mae: 0.2834 - val_loss: 0.1273 - val_mae: 0.2837\n",
      "Epoch 1533/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1240 - mae: 0.2877 - val_loss: 0.1455 - val_mae: 0.3085\n",
      "Epoch 1534/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1272 - mae: 0.2893 - val_loss: 0.1354 - val_mae: 0.3033\n",
      "Epoch 1535/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1295 - mae: 0.2886 - val_loss: 0.1369 - val_mae: 0.2960\n",
      "Epoch 1536/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1264 - mae: 0.2910 - val_loss: 0.1489 - val_mae: 0.3037\n",
      "Epoch 1537/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1252 - mae: 0.2855 - val_loss: 0.1908 - val_mae: 0.3505\n",
      "Epoch 1538/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1440 - mae: 0.3060 - val_loss: 0.1351 - val_mae: 0.2988\n",
      "Epoch 1539/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1330 - mae: 0.2959 - val_loss: 0.1516 - val_mae: 0.3029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1540/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1393 - mae: 0.3018 - val_loss: 0.1336 - val_mae: 0.2976\n",
      "Epoch 1541/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1454 - mae: 0.3087 - val_loss: 0.1411 - val_mae: 0.2996\n",
      "Epoch 1542/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1413 - mae: 0.3041 - val_loss: 0.1474 - val_mae: 0.3114\n",
      "Epoch 1543/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1476 - mae: 0.3105 - val_loss: 0.1466 - val_mae: 0.3111\n",
      "Epoch 1544/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1253 - mae: 0.2856 - val_loss: 0.1274 - val_mae: 0.2813\n",
      "Epoch 1545/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1344 - mae: 0.2992 - val_loss: 0.1319 - val_mae: 0.2877\n",
      "Epoch 1546/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1372 - mae: 0.3005 - val_loss: 0.1527 - val_mae: 0.3164\n",
      "Epoch 1547/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1507 - mae: 0.3098 - val_loss: 0.1817 - val_mae: 0.3497\n",
      "Epoch 1548/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1539 - mae: 0.3189 - val_loss: 0.1824 - val_mae: 0.3341\n",
      "Epoch 1549/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1654 - mae: 0.3286 - val_loss: 0.1406 - val_mae: 0.2913\n",
      "Epoch 1550/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1721 - mae: 0.3297 - val_loss: 0.2249 - val_mae: 0.3873\n",
      "Epoch 1551/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1918 - mae: 0.3511 - val_loss: 0.1562 - val_mae: 0.3199\n",
      "Epoch 1552/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1468 - mae: 0.3105 - val_loss: 0.1814 - val_mae: 0.3331\n",
      "Epoch 1553/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1377 - mae: 0.3035 - val_loss: 0.1335 - val_mae: 0.2975\n",
      "Epoch 1554/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1320 - mae: 0.2919 - val_loss: 0.1373 - val_mae: 0.3059\n",
      "Epoch 1555/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1204 - mae: 0.2867 - val_loss: 0.1286 - val_mae: 0.2857\n",
      "Epoch 1556/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1351 - mae: 0.3028 - val_loss: 0.1656 - val_mae: 0.3182\n",
      "Epoch 1557/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1575 - mae: 0.3215 - val_loss: 0.1297 - val_mae: 0.2888\n",
      "Epoch 1558/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1301 - mae: 0.2883 - val_loss: 0.1772 - val_mae: 0.3446\n",
      "Epoch 1559/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1572 - mae: 0.3197 - val_loss: 0.1391 - val_mae: 0.3020\n",
      "Epoch 1560/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1365 - mae: 0.3065 - val_loss: 0.1410 - val_mae: 0.3050\n",
      "Epoch 1561/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1340 - mae: 0.2956 - val_loss: 0.1558 - val_mae: 0.3146\n",
      "Epoch 1562/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1376 - mae: 0.3005 - val_loss: 0.1392 - val_mae: 0.3011\n",
      "Epoch 1563/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1333 - mae: 0.2990 - val_loss: 0.1256 - val_mae: 0.2860\n",
      "Epoch 1564/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1432 - mae: 0.3075 - val_loss: 0.1393 - val_mae: 0.2998\n",
      "Epoch 1565/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1338 - mae: 0.2986 - val_loss: 0.1346 - val_mae: 0.2956\n",
      "Epoch 1566/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1347 - mae: 0.2950 - val_loss: 0.1580 - val_mae: 0.3254\n",
      "Epoch 1567/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1362 - mae: 0.2974 - val_loss: 0.1287 - val_mae: 0.2911\n",
      "Epoch 1568/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1312 - mae: 0.2954 - val_loss: 0.1783 - val_mae: 0.3416\n",
      "Epoch 1569/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1450 - mae: 0.3107 - val_loss: 0.1603 - val_mae: 0.3099\n",
      "Epoch 1570/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1489 - mae: 0.3122 - val_loss: 0.1507 - val_mae: 0.3127\n",
      "Epoch 1571/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1317 - mae: 0.2889 - val_loss: 0.1455 - val_mae: 0.3129\n",
      "Epoch 1572/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1306 - mae: 0.2923 - val_loss: 0.1334 - val_mae: 0.2901\n",
      "Epoch 1573/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1231 - mae: 0.2876 - val_loss: 0.1199 - val_mae: 0.2745\n",
      "Epoch 1574/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1197 - mae: 0.2812 - val_loss: 0.1298 - val_mae: 0.2969\n",
      "Epoch 1575/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1257 - mae: 0.2884 - val_loss: 0.1300 - val_mae: 0.2946\n",
      "Epoch 1576/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1330 - mae: 0.2973 - val_loss: 0.1259 - val_mae: 0.2856\n",
      "Epoch 1577/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1390 - mae: 0.3078 - val_loss: 0.1315 - val_mae: 0.2841\n",
      "Epoch 1578/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1206 - mae: 0.2837 - val_loss: 0.1331 - val_mae: 0.2983\n",
      "Epoch 1579/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1196 - mae: 0.2798 - val_loss: 0.1378 - val_mae: 0.3053\n",
      "Epoch 1580/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1384 - mae: 0.3036 - val_loss: 0.1375 - val_mae: 0.2894\n",
      "Epoch 1581/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1419 - mae: 0.3071 - val_loss: 0.1575 - val_mae: 0.3126\n",
      "Epoch 1582/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1379 - mae: 0.3001 - val_loss: 0.1371 - val_mae: 0.3003\n",
      "Epoch 1583/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1256 - mae: 0.2888 - val_loss: 0.1388 - val_mae: 0.3027\n",
      "Epoch 1584/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1217 - mae: 0.2853 - val_loss: 0.1426 - val_mae: 0.3035\n",
      "Epoch 1585/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1296 - mae: 0.2932 - val_loss: 0.1479 - val_mae: 0.3153\n",
      "Epoch 1586/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1330 - mae: 0.2932 - val_loss: 0.1455 - val_mae: 0.3089\n",
      "Epoch 1587/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1313 - mae: 0.2950 - val_loss: 0.1592 - val_mae: 0.3139\n",
      "Epoch 1588/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1318 - mae: 0.2912 - val_loss: 0.1436 - val_mae: 0.3107\n",
      "Epoch 1589/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1342 - mae: 0.2933 - val_loss: 0.1244 - val_mae: 0.2868\n",
      "Epoch 1590/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1229 - mae: 0.2869 - val_loss: 0.1305 - val_mae: 0.2886\n",
      "Epoch 1591/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1211 - mae: 0.2771 - val_loss: 0.1472 - val_mae: 0.3141\n",
      "Epoch 1592/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1282 - mae: 0.2942 - val_loss: 0.1290 - val_mae: 0.2811\n",
      "Epoch 1593/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1280 - mae: 0.2906 - val_loss: 0.1386 - val_mae: 0.2957\n",
      "Epoch 1594/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1273 - mae: 0.2915 - val_loss: 0.1219 - val_mae: 0.2835\n",
      "Epoch 1595/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1208 - mae: 0.2795 - val_loss: 0.1712 - val_mae: 0.3369\n",
      "Epoch 1596/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1354 - mae: 0.2968 - val_loss: 0.1539 - val_mae: 0.3118\n",
      "Epoch 1597/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1424 - mae: 0.3069 - val_loss: 0.1201 - val_mae: 0.2794\n",
      "Epoch 1598/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1362 - mae: 0.2991 - val_loss: 0.1339 - val_mae: 0.2876\n",
      "Epoch 1599/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1279 - mae: 0.2921 - val_loss: 0.1300 - val_mae: 0.2925\n",
      "Epoch 1600/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1277 - mae: 0.2892 - val_loss: 0.1300 - val_mae: 0.2908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1297 - mae: 0.2930 - val_loss: 0.1418 - val_mae: 0.2982\n",
      "Epoch 1602/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1468 - mae: 0.3079 - val_loss: 0.1486 - val_mae: 0.3039\n",
      "Epoch 1603/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1488 - mae: 0.3087 - val_loss: 0.2311 - val_mae: 0.3956\n",
      "Epoch 1604/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1803 - mae: 0.3414 - val_loss: 0.1439 - val_mae: 0.3098\n",
      "Epoch 1605/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1405 - mae: 0.3023 - val_loss: 0.1388 - val_mae: 0.2868\n",
      "Epoch 1606/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1246 - mae: 0.2838 - val_loss: 0.1504 - val_mae: 0.3205\n",
      "Epoch 1607/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1258 - mae: 0.2854 - val_loss: 0.1321 - val_mae: 0.2837\n",
      "Epoch 1608/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1437 - mae: 0.3092 - val_loss: 0.1521 - val_mae: 0.3053\n",
      "Epoch 1609/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1362 - mae: 0.2938 - val_loss: 0.1351 - val_mae: 0.3001\n",
      "Epoch 1610/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1168 - mae: 0.2760 - val_loss: 0.1338 - val_mae: 0.2958\n",
      "Epoch 1611/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1268 - mae: 0.2916 - val_loss: 0.1303 - val_mae: 0.2890\n",
      "Epoch 1612/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1192 - mae: 0.2783 - val_loss: 0.1541 - val_mae: 0.3225\n",
      "Epoch 1613/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1411 - mae: 0.3050 - val_loss: 0.1383 - val_mae: 0.3027\n",
      "Epoch 1614/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1326 - mae: 0.2962 - val_loss: 0.1386 - val_mae: 0.2881\n",
      "Epoch 1615/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1270 - mae: 0.2864 - val_loss: 0.1769 - val_mae: 0.3440\n",
      "Epoch 1616/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1481 - mae: 0.3064 - val_loss: 0.1330 - val_mae: 0.2976\n",
      "Epoch 1617/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1354 - mae: 0.3021 - val_loss: 0.1365 - val_mae: 0.2868\n",
      "Epoch 1618/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1463 - mae: 0.3107 - val_loss: 0.1346 - val_mae: 0.2924\n",
      "Epoch 1619/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1422 - mae: 0.3053 - val_loss: 0.1745 - val_mae: 0.3384\n",
      "Epoch 1620/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1551 - mae: 0.3157 - val_loss: 0.1325 - val_mae: 0.2983\n",
      "Epoch 1621/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1501 - mae: 0.3138 - val_loss: 0.1861 - val_mae: 0.3304\n",
      "Epoch 1622/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1626 - mae: 0.3239 - val_loss: 0.1477 - val_mae: 0.3121\n",
      "Epoch 1623/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1457 - mae: 0.3048 - val_loss: 0.1688 - val_mae: 0.3392\n",
      "Epoch 1624/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1505 - mae: 0.3132 - val_loss: 0.1652 - val_mae: 0.3220\n",
      "Epoch 1625/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1498 - mae: 0.3179 - val_loss: 0.1482 - val_mae: 0.2993\n",
      "Epoch 1626/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1602 - mae: 0.3240 - val_loss: 0.1347 - val_mae: 0.3004\n",
      "Epoch 1627/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1367 - mae: 0.2931 - val_loss: 0.1572 - val_mae: 0.3266\n",
      "Epoch 1628/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1443 - mae: 0.3103 - val_loss: 0.1422 - val_mae: 0.3051\n",
      "Epoch 1629/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.1509 - mae: 0.3154 - val_loss: 0.1577 - val_mae: 0.3059\n",
      "Epoch 1630/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1489 - mae: 0.3136 - val_loss: 0.1398 - val_mae: 0.2999\n",
      "Epoch 1631/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1399 - mae: 0.2983 - val_loss: 0.1676 - val_mae: 0.3366\n",
      "Epoch 1632/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1384 - mae: 0.2994 - val_loss: 0.1370 - val_mae: 0.2941\n",
      "Epoch 1633/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1272 - mae: 0.2917 - val_loss: 0.1223 - val_mae: 0.2765\n",
      "Epoch 1634/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1305 - mae: 0.2894 - val_loss: 0.1791 - val_mae: 0.3497\n",
      "Epoch 1635/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1437 - mae: 0.3054 - val_loss: 0.1573 - val_mae: 0.3119\n",
      "Epoch 1636/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1424 - mae: 0.3022 - val_loss: 0.1401 - val_mae: 0.2966\n",
      "Epoch 1637/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1326 - mae: 0.2919 - val_loss: 0.1284 - val_mae: 0.2952\n",
      "Epoch 1638/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1366 - mae: 0.2968 - val_loss: 0.1441 - val_mae: 0.3089\n",
      "Epoch 1639/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1450 - mae: 0.3119 - val_loss: 0.1754 - val_mae: 0.3371\n",
      "Epoch 1640/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1500 - mae: 0.3096 - val_loss: 0.1454 - val_mae: 0.3095\n",
      "Epoch 1641/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1298 - mae: 0.2914 - val_loss: 0.1235 - val_mae: 0.2808\n",
      "Epoch 1642/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1274 - mae: 0.2885 - val_loss: 0.1626 - val_mae: 0.3276\n",
      "Epoch 1643/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1338 - mae: 0.2968 - val_loss: 0.1214 - val_mae: 0.2873\n",
      "Epoch 1644/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1271 - mae: 0.2887 - val_loss: 0.1383 - val_mae: 0.3017\n",
      "Epoch 1645/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1385 - mae: 0.3002 - val_loss: 0.1399 - val_mae: 0.2924\n",
      "Epoch 1646/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1386 - mae: 0.3016 - val_loss: 0.1314 - val_mae: 0.2938\n",
      "Epoch 1647/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1356 - mae: 0.2969 - val_loss: 0.1366 - val_mae: 0.3003\n",
      "Epoch 1648/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1255 - mae: 0.2856 - val_loss: 0.1439 - val_mae: 0.3113\n",
      "Epoch 1649/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1257 - mae: 0.2881 - val_loss: 0.1579 - val_mae: 0.3114\n",
      "Epoch 1650/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1393 - mae: 0.3046 - val_loss: 0.1367 - val_mae: 0.3006\n",
      "Epoch 1651/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1328 - mae: 0.2868 - val_loss: 0.1314 - val_mae: 0.2989\n",
      "Epoch 1652/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1337 - mae: 0.2980 - val_loss: 0.1496 - val_mae: 0.3029\n",
      "Epoch 1653/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1421 - mae: 0.3065 - val_loss: 0.1986 - val_mae: 0.3612\n",
      "Epoch 1654/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1547 - mae: 0.3181 - val_loss: 0.1430 - val_mae: 0.2978\n",
      "Epoch 1655/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1429 - mae: 0.3003 - val_loss: 0.2315 - val_mae: 0.3962\n",
      "Epoch 1656/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1912 - mae: 0.3547 - val_loss: 0.1341 - val_mae: 0.2930\n",
      "Epoch 1657/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1754 - mae: 0.3392 - val_loss: 0.2155 - val_mae: 0.3642\n",
      "Epoch 1658/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1888 - mae: 0.3494 - val_loss: 0.1909 - val_mae: 0.3599\n",
      "Epoch 1659/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.2072 - mae: 0.3634 - val_loss: 0.2114 - val_mae: 0.3779\n",
      "Epoch 1660/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.2258 - mae: 0.3791 - val_loss: 0.1836 - val_mae: 0.3276\n",
      "Epoch 1661/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1852 - mae: 0.3475 - val_loss: 0.1386 - val_mae: 0.2877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1662/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1636 - mae: 0.3210 - val_loss: 0.1709 - val_mae: 0.3360\n",
      "Epoch 1663/2000\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.1452 - mae: 0.3061 - val_loss: 0.1245 - val_mae: 0.2843\n",
      "Epoch 1664/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1232 - mae: 0.2881 - val_loss: 0.1548 - val_mae: 0.3041\n",
      "Epoch 1665/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1563 - mae: 0.3144 - val_loss: 0.1817 - val_mae: 0.3448\n",
      "Epoch 1666/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1531 - mae: 0.3129 - val_loss: 0.1290 - val_mae: 0.2951\n",
      "Epoch 1667/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1285 - mae: 0.2960 - val_loss: 0.1531 - val_mae: 0.3029\n",
      "Epoch 1668/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1439 - mae: 0.3062 - val_loss: 0.1274 - val_mae: 0.2896\n",
      "Epoch 1669/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1191 - mae: 0.2807 - val_loss: 0.1258 - val_mae: 0.2854\n",
      "Epoch 1670/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1202 - mae: 0.2827 - val_loss: 0.1541 - val_mae: 0.3022\n",
      "Epoch 1671/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1434 - mae: 0.3029 - val_loss: 0.1439 - val_mae: 0.3136\n",
      "Epoch 1672/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1309 - mae: 0.2923 - val_loss: 0.1317 - val_mae: 0.2916\n",
      "Epoch 1673/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1231 - mae: 0.2867 - val_loss: 0.1305 - val_mae: 0.2914\n",
      "Epoch 1674/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1271 - mae: 0.2907 - val_loss: 0.1215 - val_mae: 0.2831\n",
      "Epoch 1675/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1232 - mae: 0.2838 - val_loss: 0.1425 - val_mae: 0.3111\n",
      "Epoch 1676/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1286 - mae: 0.2896 - val_loss: 0.1417 - val_mae: 0.3088\n",
      "Epoch 1677/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1367 - mae: 0.3024 - val_loss: 0.1729 - val_mae: 0.3228\n",
      "Epoch 1678/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1719 - mae: 0.3374 - val_loss: 0.1407 - val_mae: 0.2955\n",
      "Epoch 1679/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1410 - mae: 0.3026 - val_loss: 0.1343 - val_mae: 0.2985\n",
      "Epoch 1680/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1361 - mae: 0.2976 - val_loss: 0.1287 - val_mae: 0.2932\n",
      "Epoch 1681/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1286 - mae: 0.2895 - val_loss: 0.1323 - val_mae: 0.2996\n",
      "Epoch 1682/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1205 - mae: 0.2824 - val_loss: 0.1452 - val_mae: 0.3077\n",
      "Epoch 1683/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1342 - mae: 0.2945 - val_loss: 0.1433 - val_mae: 0.3041\n",
      "Epoch 1684/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1471 - mae: 0.3143 - val_loss: 0.1732 - val_mae: 0.3261\n",
      "Epoch 1685/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1787 - mae: 0.3423 - val_loss: 0.1349 - val_mae: 0.2973\n",
      "Epoch 1686/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1565 - mae: 0.3120 - val_loss: 0.1752 - val_mae: 0.3410\n",
      "Epoch 1687/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1489 - mae: 0.3132 - val_loss: 0.1478 - val_mae: 0.3007\n",
      "Epoch 1688/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1440 - mae: 0.3076 - val_loss: 0.1498 - val_mae: 0.3116\n",
      "Epoch 1689/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1411 - mae: 0.3056 - val_loss: 0.1289 - val_mae: 0.2905\n",
      "Epoch 1690/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1276 - mae: 0.2864 - val_loss: 0.1412 - val_mae: 0.3078\n",
      "Epoch 1691/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1228 - mae: 0.2867 - val_loss: 0.1234 - val_mae: 0.2849\n",
      "Epoch 1692/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1258 - mae: 0.2911 - val_loss: 0.1330 - val_mae: 0.2851\n",
      "Epoch 1693/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1269 - mae: 0.2855 - val_loss: 0.2253 - val_mae: 0.3913\n",
      "Epoch 1694/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1671 - mae: 0.3287 - val_loss: 0.1680 - val_mae: 0.3143\n",
      "Epoch 1695/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1843 - mae: 0.3504 - val_loss: 0.1505 - val_mae: 0.2988\n",
      "Epoch 1696/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1373 - mae: 0.2988 - val_loss: 0.1648 - val_mae: 0.3314\n",
      "Epoch 1697/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1343 - mae: 0.2940 - val_loss: 0.1302 - val_mae: 0.2942\n",
      "Epoch 1698/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1308 - mae: 0.2964 - val_loss: 0.1232 - val_mae: 0.2724\n",
      "Epoch 1699/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1206 - mae: 0.2820 - val_loss: 0.1245 - val_mae: 0.2822\n",
      "Epoch 1700/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1234 - mae: 0.2831 - val_loss: 0.1229 - val_mae: 0.2874\n",
      "Epoch 1701/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1331 - mae: 0.2967 - val_loss: 0.1471 - val_mae: 0.2998\n",
      "Epoch 1702/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1308 - mae: 0.2938 - val_loss: 0.1179 - val_mae: 0.2736\n",
      "Epoch 1703/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1174 - mae: 0.2760 - val_loss: 0.1409 - val_mae: 0.3083\n",
      "Epoch 1704/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1290 - mae: 0.2915 - val_loss: 0.1356 - val_mae: 0.2984\n",
      "Epoch 1705/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1262 - mae: 0.2908 - val_loss: 0.1316 - val_mae: 0.2900\n",
      "Epoch 1706/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1349 - mae: 0.2946 - val_loss: 0.1448 - val_mae: 0.2984\n",
      "Epoch 1707/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1281 - mae: 0.2931 - val_loss: 0.1396 - val_mae: 0.2971\n",
      "Epoch 1708/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1290 - mae: 0.2893 - val_loss: 0.1619 - val_mae: 0.3234\n",
      "Epoch 1709/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1383 - mae: 0.2990 - val_loss: 0.1476 - val_mae: 0.3126\n",
      "Epoch 1710/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1514 - mae: 0.3158 - val_loss: 0.1528 - val_mae: 0.3072\n",
      "Epoch 1711/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1643 - mae: 0.3249 - val_loss: 0.1493 - val_mae: 0.3007\n",
      "Epoch 1712/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1461 - mae: 0.3048 - val_loss: 0.1555 - val_mae: 0.3231\n",
      "Epoch 1713/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1349 - mae: 0.2958 - val_loss: 0.1381 - val_mae: 0.2971\n",
      "Epoch 1714/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1242 - mae: 0.2876 - val_loss: 0.1175 - val_mae: 0.2775\n",
      "Epoch 1715/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1279 - mae: 0.2875 - val_loss: 0.1378 - val_mae: 0.3023\n",
      "Epoch 1716/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1285 - mae: 0.2887 - val_loss: 0.1344 - val_mae: 0.2970\n",
      "Epoch 1717/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1420 - mae: 0.3086 - val_loss: 0.1649 - val_mae: 0.3173\n",
      "Epoch 1718/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1562 - mae: 0.3250 - val_loss: 0.1332 - val_mae: 0.2816\n",
      "Epoch 1719/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1381 - mae: 0.2959 - val_loss: 0.1596 - val_mae: 0.3268\n",
      "Epoch 1720/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1396 - mae: 0.2995 - val_loss: 0.1650 - val_mae: 0.3368\n",
      "Epoch 1721/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1516 - mae: 0.3160 - val_loss: 0.1310 - val_mae: 0.2889\n",
      "Epoch 1722/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1558 - mae: 0.3157 - val_loss: 0.1855 - val_mae: 0.3479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1723/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1848 - mae: 0.3401 - val_loss: 0.1950 - val_mae: 0.3626\n",
      "Epoch 1724/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1892 - mae: 0.3452 - val_loss: 0.2843 - val_mae: 0.4233\n",
      "Epoch 1725/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1867 - mae: 0.3415 - val_loss: 0.1477 - val_mae: 0.3098\n",
      "Epoch 1726/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.2020 - mae: 0.3546 - val_loss: 0.1351 - val_mae: 0.2958\n",
      "Epoch 1727/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1802 - mae: 0.3368 - val_loss: 0.2786 - val_mae: 0.4387\n",
      "Epoch 1728/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1992 - mae: 0.3651 - val_loss: 0.1491 - val_mae: 0.2980\n",
      "Epoch 1729/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1728 - mae: 0.3318 - val_loss: 0.1271 - val_mae: 0.2926\n",
      "Epoch 1730/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1371 - mae: 0.2965 - val_loss: 0.1465 - val_mae: 0.3130\n",
      "Epoch 1731/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1240 - mae: 0.2879 - val_loss: 0.1178 - val_mae: 0.2769\n",
      "Epoch 1732/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1280 - mae: 0.2910 - val_loss: 0.1398 - val_mae: 0.3014\n",
      "Epoch 1733/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1246 - mae: 0.2878 - val_loss: 0.1355 - val_mae: 0.2976\n",
      "Epoch 1734/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1216 - mae: 0.2845 - val_loss: 0.1398 - val_mae: 0.3041\n",
      "Epoch 1735/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1262 - mae: 0.2871 - val_loss: 0.1204 - val_mae: 0.2736\n",
      "Epoch 1736/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1218 - mae: 0.2845 - val_loss: 0.1485 - val_mae: 0.3067\n",
      "Epoch 1737/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1257 - mae: 0.2891 - val_loss: 0.1248 - val_mae: 0.2799\n",
      "Epoch 1738/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1230 - mae: 0.2798 - val_loss: 0.1566 - val_mae: 0.3237\n",
      "Epoch 1739/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1223 - mae: 0.2799 - val_loss: 0.1287 - val_mae: 0.2868\n",
      "Epoch 1740/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1256 - mae: 0.2875 - val_loss: 0.1317 - val_mae: 0.2957\n",
      "Epoch 1741/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1218 - mae: 0.2804 - val_loss: 0.1223 - val_mae: 0.2806\n",
      "Epoch 1742/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1196 - mae: 0.2819 - val_loss: 0.1398 - val_mae: 0.3076\n",
      "Epoch 1743/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.1321 - mae: 0.2966 - val_loss: 0.1357 - val_mae: 0.2953\n",
      "Epoch 1744/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1210 - mae: 0.2853 - val_loss: 0.1275 - val_mae: 0.2906\n",
      "Epoch 1745/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1259 - mae: 0.2863 - val_loss: 0.1473 - val_mae: 0.3162\n",
      "Epoch 1746/2000\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.1297 - mae: 0.2910 - val_loss: 0.1216 - val_mae: 0.2737\n",
      "Epoch 1747/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1248 - mae: 0.2877 - val_loss: 0.1301 - val_mae: 0.2929\n",
      "Epoch 1748/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1240 - mae: 0.2840 - val_loss: 0.1298 - val_mae: 0.2913\n",
      "Epoch 1749/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1238 - mae: 0.2854 - val_loss: 0.1380 - val_mae: 0.2963\n",
      "Epoch 1750/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1315 - mae: 0.2934 - val_loss: 0.1365 - val_mae: 0.2933\n",
      "Epoch 1751/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1349 - mae: 0.2975 - val_loss: 0.1298 - val_mae: 0.2887\n",
      "Epoch 1752/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1294 - mae: 0.2904 - val_loss: 0.1249 - val_mae: 0.2827\n",
      "Epoch 1753/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1173 - mae: 0.2762 - val_loss: 0.1477 - val_mae: 0.3162\n",
      "Epoch 1754/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1397 - mae: 0.3026 - val_loss: 0.1167 - val_mae: 0.2688\n",
      "Epoch 1755/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1231 - mae: 0.2869 - val_loss: 0.1537 - val_mae: 0.3034\n",
      "Epoch 1756/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1403 - mae: 0.2969 - val_loss: 0.1420 - val_mae: 0.3114\n",
      "Epoch 1757/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1314 - mae: 0.2897 - val_loss: 0.1308 - val_mae: 0.2958\n",
      "Epoch 1758/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1146 - mae: 0.2768 - val_loss: 0.1292 - val_mae: 0.2763\n",
      "Epoch 1759/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1233 - mae: 0.2823 - val_loss: 0.1490 - val_mae: 0.3171\n",
      "Epoch 1760/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1324 - mae: 0.2908 - val_loss: 0.1366 - val_mae: 0.3009\n",
      "Epoch 1761/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1226 - mae: 0.2866 - val_loss: 0.1241 - val_mae: 0.2775\n",
      "Epoch 1762/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1190 - mae: 0.2769 - val_loss: 0.1251 - val_mae: 0.2879\n",
      "Epoch 1763/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1199 - mae: 0.2777 - val_loss: 0.1363 - val_mae: 0.3037\n",
      "Epoch 1764/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1265 - mae: 0.2894 - val_loss: 0.1389 - val_mae: 0.3036\n",
      "Epoch 1765/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1391 - mae: 0.3048 - val_loss: 0.1500 - val_mae: 0.3181\n",
      "Epoch 1766/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1384 - mae: 0.3025 - val_loss: 0.1628 - val_mae: 0.3137\n",
      "Epoch 1767/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1428 - mae: 0.3034 - val_loss: 0.1297 - val_mae: 0.2896\n",
      "Epoch 1768/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1268 - mae: 0.2858 - val_loss: 0.1298 - val_mae: 0.2905\n",
      "Epoch 1769/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.1290 - mae: 0.2902 - val_loss: 0.1661 - val_mae: 0.3268\n",
      "Epoch 1770/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1287 - mae: 0.2907 - val_loss: 0.1496 - val_mae: 0.3010\n",
      "Epoch 1771/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1314 - mae: 0.2914 - val_loss: 0.1536 - val_mae: 0.3209\n",
      "Epoch 1772/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1348 - mae: 0.2983 - val_loss: 0.1481 - val_mae: 0.3054\n",
      "Epoch 1773/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1355 - mae: 0.2986 - val_loss: 0.1323 - val_mae: 0.2929\n",
      "Epoch 1774/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1234 - mae: 0.2837 - val_loss: 0.1450 - val_mae: 0.3047\n",
      "Epoch 1775/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1254 - mae: 0.2886 - val_loss: 0.1298 - val_mae: 0.2911\n",
      "Epoch 1776/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1169 - mae: 0.2731 - val_loss: 0.1706 - val_mae: 0.3384\n",
      "Epoch 1777/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1414 - mae: 0.3055 - val_loss: 0.1285 - val_mae: 0.2846\n",
      "Epoch 1778/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1611 - mae: 0.3228 - val_loss: 0.1623 - val_mae: 0.3222\n",
      "Epoch 1779/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1506 - mae: 0.3149 - val_loss: 0.1277 - val_mae: 0.2854\n",
      "Epoch 1780/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1494 - mae: 0.3142 - val_loss: 0.1178 - val_mae: 0.2792\n",
      "Epoch 1781/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1399 - mae: 0.2982 - val_loss: 0.1594 - val_mae: 0.3262\n",
      "Epoch 1782/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1391 - mae: 0.3014 - val_loss: 0.1335 - val_mae: 0.2919\n",
      "Epoch 1783/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1449 - mae: 0.3105 - val_loss: 0.1173 - val_mae: 0.2721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1784/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1292 - mae: 0.2879 - val_loss: 0.2137 - val_mae: 0.3774\n",
      "Epoch 1785/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1429 - mae: 0.3057 - val_loss: 0.1467 - val_mae: 0.3076\n",
      "Epoch 1786/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1837 - mae: 0.3507 - val_loss: 0.1506 - val_mae: 0.3068\n",
      "Epoch 1787/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1660 - mae: 0.3247 - val_loss: 0.1418 - val_mae: 0.3085\n",
      "Epoch 1788/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1361 - mae: 0.2949 - val_loss: 0.1117 - val_mae: 0.2718\n",
      "Epoch 1789/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1297 - mae: 0.2901 - val_loss: 0.1614 - val_mae: 0.3188\n",
      "Epoch 1790/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1286 - mae: 0.2858 - val_loss: 0.1702 - val_mae: 0.3269\n",
      "Epoch 1791/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1468 - mae: 0.3026 - val_loss: 0.1657 - val_mae: 0.3393\n",
      "Epoch 1792/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1538 - mae: 0.3169 - val_loss: 0.1231 - val_mae: 0.2771\n",
      "Epoch 1793/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1421 - mae: 0.3043 - val_loss: 0.1218 - val_mae: 0.2744\n",
      "Epoch 1794/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1412 - mae: 0.3004 - val_loss: 0.2109 - val_mae: 0.3795\n",
      "Epoch 1795/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1556 - mae: 0.3160 - val_loss: 0.1785 - val_mae: 0.3405\n",
      "Epoch 1796/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1520 - mae: 0.3105 - val_loss: 0.1359 - val_mae: 0.3001\n",
      "Epoch 1797/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1409 - mae: 0.3031 - val_loss: 0.1196 - val_mae: 0.2779\n",
      "Epoch 1798/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1336 - mae: 0.2927 - val_loss: 0.1464 - val_mae: 0.3115\n",
      "Epoch 1799/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1293 - mae: 0.2914 - val_loss: 0.1487 - val_mae: 0.3097\n",
      "Epoch 1800/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1380 - mae: 0.3023 - val_loss: 0.1652 - val_mae: 0.3138\n",
      "Epoch 1801/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1433 - mae: 0.3089 - val_loss: 0.1322 - val_mae: 0.2988\n",
      "Epoch 1802/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1219 - mae: 0.2825 - val_loss: 0.1506 - val_mae: 0.3192\n",
      "Epoch 1803/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1303 - mae: 0.2964 - val_loss: 0.1279 - val_mae: 0.2785\n",
      "Epoch 1804/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1299 - mae: 0.2916 - val_loss: 0.1634 - val_mae: 0.3215\n",
      "Epoch 1805/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1484 - mae: 0.3104 - val_loss: 0.1250 - val_mae: 0.2862\n",
      "Epoch 1806/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1413 - mae: 0.2975 - val_loss: 0.2198 - val_mae: 0.3893\n",
      "Epoch 1807/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1844 - mae: 0.3487 - val_loss: 0.1613 - val_mae: 0.3148\n",
      "Epoch 1808/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1459 - mae: 0.3109 - val_loss: 0.1348 - val_mae: 0.2876\n",
      "Epoch 1809/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1327 - mae: 0.2938 - val_loss: 0.2105 - val_mae: 0.3720\n",
      "Epoch 1810/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1813 - mae: 0.3413 - val_loss: 0.2030 - val_mae: 0.3730\n",
      "Epoch 1811/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.2276 - mae: 0.3849 - val_loss: 0.3285 - val_mae: 0.4547\n",
      "Epoch 1812/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.3026 - mae: 0.4413 - val_loss: 0.1552 - val_mae: 0.3218\n",
      "Epoch 1813/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2025 - mae: 0.3599 - val_loss: 0.2785 - val_mae: 0.4428\n",
      "Epoch 1814/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1960 - mae: 0.3585 - val_loss: 0.1857 - val_mae: 0.3328\n",
      "Epoch 1815/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1716 - mae: 0.3370 - val_loss: 0.1445 - val_mae: 0.3066\n",
      "Epoch 1816/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1527 - mae: 0.3097 - val_loss: 0.1851 - val_mae: 0.3563\n",
      "Epoch 1817/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1510 - mae: 0.3146 - val_loss: 0.1266 - val_mae: 0.2876\n",
      "Epoch 1818/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1529 - mae: 0.3172 - val_loss: 0.1553 - val_mae: 0.3098\n",
      "Epoch 1819/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1450 - mae: 0.3046 - val_loss: 0.1808 - val_mae: 0.3493\n",
      "Epoch 1820/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1521 - mae: 0.3125 - val_loss: 0.1413 - val_mae: 0.3062\n",
      "Epoch 1821/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1546 - mae: 0.3179 - val_loss: 0.1178 - val_mae: 0.2736\n",
      "Epoch 1822/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1422 - mae: 0.3025 - val_loss: 0.1408 - val_mae: 0.3092\n",
      "Epoch 1823/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1317 - mae: 0.2954 - val_loss: 0.1163 - val_mae: 0.2785\n",
      "Epoch 1824/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1224 - mae: 0.2845 - val_loss: 0.1129 - val_mae: 0.2737\n",
      "Epoch 1825/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1135 - mae: 0.2710 - val_loss: 0.1086 - val_mae: 0.2679\n",
      "Epoch 1826/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1188 - mae: 0.2798 - val_loss: 0.1142 - val_mae: 0.2752\n",
      "Epoch 1827/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1191 - mae: 0.2803 - val_loss: 0.1543 - val_mae: 0.3130\n",
      "Epoch 1828/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1324 - mae: 0.2947 - val_loss: 0.1425 - val_mae: 0.3033\n",
      "Epoch 1829/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1341 - mae: 0.2917 - val_loss: 0.1437 - val_mae: 0.3118\n",
      "Epoch 1830/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1366 - mae: 0.2990 - val_loss: 0.1289 - val_mae: 0.2861\n",
      "Epoch 1831/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1372 - mae: 0.2994 - val_loss: 0.1307 - val_mae: 0.2917\n",
      "Epoch 1832/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1370 - mae: 0.2994 - val_loss: 0.1156 - val_mae: 0.2690\n",
      "Epoch 1833/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1225 - mae: 0.2797 - val_loss: 0.1569 - val_mae: 0.3241\n",
      "Epoch 1834/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1329 - mae: 0.2968 - val_loss: 0.1148 - val_mae: 0.2731\n",
      "Epoch 1835/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1220 - mae: 0.2826 - val_loss: 0.1263 - val_mae: 0.2879\n",
      "Epoch 1836/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1244 - mae: 0.2831 - val_loss: 0.1417 - val_mae: 0.3064\n",
      "Epoch 1837/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1272 - mae: 0.2887 - val_loss: 0.1185 - val_mae: 0.2742\n",
      "Epoch 1838/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1221 - mae: 0.2827 - val_loss: 0.1152 - val_mae: 0.2764\n",
      "Epoch 1839/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1319 - mae: 0.2919 - val_loss: 0.1583 - val_mae: 0.3235\n",
      "Epoch 1840/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1305 - mae: 0.2916 - val_loss: 0.1244 - val_mae: 0.2848\n",
      "Epoch 1841/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1296 - mae: 0.2923 - val_loss: 0.1259 - val_mae: 0.2858\n",
      "Epoch 1842/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1482 - mae: 0.3057 - val_loss: 0.1349 - val_mae: 0.2992\n",
      "Epoch 1843/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1265 - mae: 0.2847 - val_loss: 0.1377 - val_mae: 0.3055\n",
      "Epoch 1844/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1325 - mae: 0.2926 - val_loss: 0.1564 - val_mae: 0.3174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1845/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1633 - mae: 0.3294 - val_loss: 0.1045 - val_mae: 0.2633\n",
      "Epoch 1846/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1258 - mae: 0.2861 - val_loss: 0.1771 - val_mae: 0.3434\n",
      "Epoch 1847/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1398 - mae: 0.3009 - val_loss: 0.1078 - val_mae: 0.2645\n",
      "Epoch 1848/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1289 - mae: 0.2925 - val_loss: 0.1167 - val_mae: 0.2719\n",
      "Epoch 1849/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1366 - mae: 0.2953 - val_loss: 0.1363 - val_mae: 0.3041\n",
      "Epoch 1850/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1341 - mae: 0.2949 - val_loss: 0.1450 - val_mae: 0.3101\n",
      "Epoch 1851/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1398 - mae: 0.3036 - val_loss: 0.1500 - val_mae: 0.3096\n",
      "Epoch 1852/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1488 - mae: 0.3119 - val_loss: 0.1403 - val_mae: 0.3070\n",
      "Epoch 1853/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1248 - mae: 0.2843 - val_loss: 0.1259 - val_mae: 0.2849\n",
      "Epoch 1854/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1296 - mae: 0.2922 - val_loss: 0.1180 - val_mae: 0.2762\n",
      "Epoch 1855/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1266 - mae: 0.2897 - val_loss: 0.1122 - val_mae: 0.2663\n",
      "Epoch 1856/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1395 - mae: 0.3008 - val_loss: 0.1518 - val_mae: 0.3106\n",
      "Epoch 1857/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1322 - mae: 0.2937 - val_loss: 0.1140 - val_mae: 0.2727\n",
      "Epoch 1858/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1294 - mae: 0.2934 - val_loss: 0.1160 - val_mae: 0.2726\n",
      "Epoch 1859/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1396 - mae: 0.3011 - val_loss: 0.1367 - val_mae: 0.2977\n",
      "Epoch 1860/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1493 - mae: 0.3095 - val_loss: 0.1648 - val_mae: 0.3370\n",
      "Epoch 1861/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1372 - mae: 0.2986 - val_loss: 0.1160 - val_mae: 0.2692\n",
      "Epoch 1862/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1359 - mae: 0.2969 - val_loss: 0.1063 - val_mae: 0.2631\n",
      "Epoch 1863/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1207 - mae: 0.2821 - val_loss: 0.1387 - val_mae: 0.3049\n",
      "Epoch 1864/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1278 - mae: 0.2884 - val_loss: 0.1307 - val_mae: 0.2890\n",
      "Epoch 1865/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1352 - mae: 0.2963 - val_loss: 0.1207 - val_mae: 0.2839\n",
      "Epoch 1866/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1327 - mae: 0.2931 - val_loss: 0.1720 - val_mae: 0.3414\n",
      "Epoch 1867/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1337 - mae: 0.2952 - val_loss: 0.1297 - val_mae: 0.2880\n",
      "Epoch 1868/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1350 - mae: 0.2953 - val_loss: 0.1398 - val_mae: 0.3040\n",
      "Epoch 1869/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1393 - mae: 0.2993 - val_loss: 0.1424 - val_mae: 0.3075\n",
      "Epoch 1870/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1411 - mae: 0.3039 - val_loss: 0.1332 - val_mae: 0.2917\n",
      "Epoch 1871/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1406 - mae: 0.3027 - val_loss: 0.1153 - val_mae: 0.2692\n",
      "Epoch 1872/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1218 - mae: 0.2810 - val_loss: 0.1166 - val_mae: 0.2745\n",
      "Epoch 1873/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1303 - mae: 0.2925 - val_loss: 0.1487 - val_mae: 0.3188\n",
      "Epoch 1874/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1279 - mae: 0.2872 - val_loss: 0.1116 - val_mae: 0.2674\n",
      "Epoch 1875/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1286 - mae: 0.2926 - val_loss: 0.1352 - val_mae: 0.2957\n",
      "Epoch 1876/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1191 - mae: 0.2792 - val_loss: 0.1172 - val_mae: 0.2789\n",
      "Epoch 1877/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1229 - mae: 0.2851 - val_loss: 0.1091 - val_mae: 0.2680\n",
      "Epoch 1878/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1254 - mae: 0.2858 - val_loss: 0.1457 - val_mae: 0.3101\n",
      "Epoch 1879/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1305 - mae: 0.2927 - val_loss: 0.1330 - val_mae: 0.2965\n",
      "Epoch 1880/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1350 - mae: 0.2969 - val_loss: 0.1292 - val_mae: 0.2896\n",
      "Epoch 1881/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1467 - mae: 0.3131 - val_loss: 0.1188 - val_mae: 0.2762\n",
      "Epoch 1882/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1293 - mae: 0.2912 - val_loss: 0.1334 - val_mae: 0.2937\n",
      "Epoch 1883/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1316 - mae: 0.2911 - val_loss: 0.1148 - val_mae: 0.2738\n",
      "Epoch 1884/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1209 - mae: 0.2813 - val_loss: 0.1265 - val_mae: 0.2908\n",
      "Epoch 1885/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1313 - mae: 0.2922 - val_loss: 0.1223 - val_mae: 0.2849\n",
      "Epoch 1886/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1209 - mae: 0.2854 - val_loss: 0.1160 - val_mae: 0.2849\n",
      "Epoch 1887/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1164 - mae: 0.2773 - val_loss: 0.1149 - val_mae: 0.2716\n",
      "Epoch 1888/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1182 - mae: 0.2759 - val_loss: 0.1080 - val_mae: 0.2675\n",
      "Epoch 1889/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1189 - mae: 0.2802 - val_loss: 0.1085 - val_mae: 0.2692\n",
      "Epoch 1890/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1216 - mae: 0.2848 - val_loss: 0.1210 - val_mae: 0.2793\n",
      "Epoch 1891/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1210 - mae: 0.2813 - val_loss: 0.1089 - val_mae: 0.2704\n",
      "Epoch 1892/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1130 - mae: 0.2697 - val_loss: 0.1248 - val_mae: 0.2868\n",
      "Epoch 1893/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1298 - mae: 0.2951 - val_loss: 0.1294 - val_mae: 0.2827\n",
      "Epoch 1894/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1341 - mae: 0.3006 - val_loss: 0.1148 - val_mae: 0.2717\n",
      "Epoch 1895/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1422 - mae: 0.3005 - val_loss: 0.1649 - val_mae: 0.3320\n",
      "Epoch 1896/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1303 - mae: 0.2934 - val_loss: 0.1122 - val_mae: 0.2653\n",
      "Epoch 1897/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1342 - mae: 0.3006 - val_loss: 0.1300 - val_mae: 0.2870\n",
      "Epoch 1898/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1384 - mae: 0.2969 - val_loss: 0.1326 - val_mae: 0.2945\n",
      "Epoch 1899/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1251 - mae: 0.2834 - val_loss: 0.1100 - val_mae: 0.2683\n",
      "Epoch 1900/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1251 - mae: 0.2890 - val_loss: 0.1244 - val_mae: 0.2796\n",
      "Epoch 1901/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1306 - mae: 0.2941 - val_loss: 0.1173 - val_mae: 0.2757\n",
      "Epoch 1902/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1249 - mae: 0.2826 - val_loss: 0.1132 - val_mae: 0.2752\n",
      "Epoch 1903/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1208 - mae: 0.2806 - val_loss: 0.1239 - val_mae: 0.2776\n",
      "Epoch 1904/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1297 - mae: 0.2891 - val_loss: 0.1246 - val_mae: 0.2811\n",
      "Epoch 1905/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1328 - mae: 0.2896 - val_loss: 0.1452 - val_mae: 0.3134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1906/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1300 - mae: 0.2884 - val_loss: 0.1403 - val_mae: 0.2989\n",
      "Epoch 1907/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1441 - mae: 0.3032 - val_loss: 0.1501 - val_mae: 0.3195\n",
      "Epoch 1908/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1492 - mae: 0.3085 - val_loss: 0.1511 - val_mae: 0.3113\n",
      "Epoch 1909/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1290 - mae: 0.2878 - val_loss: 0.1259 - val_mae: 0.2875\n",
      "Epoch 1910/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1219 - mae: 0.2811 - val_loss: 0.1024 - val_mae: 0.2577\n",
      "Epoch 1911/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1266 - mae: 0.2907 - val_loss: 0.1387 - val_mae: 0.2970\n",
      "Epoch 1912/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1238 - mae: 0.2800 - val_loss: 0.1439 - val_mae: 0.3096\n",
      "Epoch 1913/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1319 - mae: 0.2903 - val_loss: 0.1321 - val_mae: 0.2943\n",
      "Epoch 1914/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1354 - mae: 0.2979 - val_loss: 0.1281 - val_mae: 0.2829\n",
      "Epoch 1915/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1264 - mae: 0.2833 - val_loss: 0.1441 - val_mae: 0.3121\n",
      "Epoch 1916/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1318 - mae: 0.2881 - val_loss: 0.1195 - val_mae: 0.2823\n",
      "Epoch 1917/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1286 - mae: 0.2896 - val_loss: 0.1147 - val_mae: 0.2698\n",
      "Epoch 1918/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1220 - mae: 0.2822 - val_loss: 0.1184 - val_mae: 0.2759\n",
      "Epoch 1919/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1238 - mae: 0.2825 - val_loss: 0.1349 - val_mae: 0.3053\n",
      "Epoch 1920/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1414 - mae: 0.3025 - val_loss: 0.1312 - val_mae: 0.2890\n",
      "Epoch 1921/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1359 - mae: 0.2968 - val_loss: 0.1466 - val_mae: 0.3153\n",
      "Epoch 1922/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1358 - mae: 0.2953 - val_loss: 0.1137 - val_mae: 0.2751\n",
      "Epoch 1923/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1195 - mae: 0.2807 - val_loss: 0.1170 - val_mae: 0.2729\n",
      "Epoch 1924/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1184 - mae: 0.2772 - val_loss: 0.1207 - val_mae: 0.2804\n",
      "Epoch 1925/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1183 - mae: 0.2761 - val_loss: 0.1015 - val_mae: 0.2567\n",
      "Epoch 1926/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1138 - mae: 0.2702 - val_loss: 0.1355 - val_mae: 0.3024\n",
      "Epoch 1927/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1310 - mae: 0.2926 - val_loss: 0.1271 - val_mae: 0.2919\n",
      "Epoch 1928/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1365 - mae: 0.3036 - val_loss: 0.1145 - val_mae: 0.2678\n",
      "Epoch 1929/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1277 - mae: 0.2859 - val_loss: 0.1329 - val_mae: 0.3005\n",
      "Epoch 1930/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1171 - mae: 0.2779 - val_loss: 0.1083 - val_mae: 0.2703\n",
      "Epoch 1931/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1166 - mae: 0.2765 - val_loss: 0.1060 - val_mae: 0.2621\n",
      "Epoch 1932/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1083 - mae: 0.2637 - val_loss: 0.1040 - val_mae: 0.2638\n",
      "Epoch 1933/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1186 - mae: 0.2781 - val_loss: 0.1247 - val_mae: 0.2802\n",
      "Epoch 1934/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1289 - mae: 0.2854 - val_loss: 0.1530 - val_mae: 0.3211\n",
      "Epoch 1935/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1355 - mae: 0.2958 - val_loss: 0.1303 - val_mae: 0.2865\n",
      "Epoch 1936/2000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1629 - mae: 0.3257 - val_loss: 0.1200 - val_mae: 0.2744\n",
      "Epoch 1937/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1239 - mae: 0.2837 - val_loss: 0.1197 - val_mae: 0.2775\n",
      "Epoch 1938/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1255 - mae: 0.2876 - val_loss: 0.1372 - val_mae: 0.2985\n",
      "Epoch 1939/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1440 - mae: 0.3010 - val_loss: 0.1480 - val_mae: 0.3176\n",
      "Epoch 1940/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1324 - mae: 0.2960 - val_loss: 0.1098 - val_mae: 0.2622\n",
      "Epoch 1941/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1255 - mae: 0.2854 - val_loss: 0.1197 - val_mae: 0.2807\n",
      "Epoch 1942/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1216 - mae: 0.2792 - val_loss: 0.1013 - val_mae: 0.2578\n",
      "Epoch 1943/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1201 - mae: 0.2792 - val_loss: 0.1530 - val_mae: 0.3124\n",
      "Epoch 1944/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1321 - mae: 0.2932 - val_loss: 0.1041 - val_mae: 0.2642\n",
      "Epoch 1945/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1171 - mae: 0.2760 - val_loss: 0.1101 - val_mae: 0.2684\n",
      "Epoch 1946/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1227 - mae: 0.2807 - val_loss: 0.1278 - val_mae: 0.2850\n",
      "Epoch 1947/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1163 - mae: 0.2750 - val_loss: 0.1079 - val_mae: 0.2647\n",
      "Epoch 1948/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1105 - mae: 0.2690 - val_loss: 0.1069 - val_mae: 0.2622\n",
      "Epoch 1949/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1145 - mae: 0.2698 - val_loss: 0.1341 - val_mae: 0.3018\n",
      "Epoch 1950/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1295 - mae: 0.2895 - val_loss: 0.1325 - val_mae: 0.2924\n",
      "Epoch 1951/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1337 - mae: 0.2920 - val_loss: 0.1544 - val_mae: 0.3197\n",
      "Epoch 1952/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1342 - mae: 0.2936 - val_loss: 0.1324 - val_mae: 0.2977\n",
      "Epoch 1953/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1226 - mae: 0.2852 - val_loss: 0.1207 - val_mae: 0.2778\n",
      "Epoch 1954/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1433 - mae: 0.3071 - val_loss: 0.1510 - val_mae: 0.3144\n",
      "Epoch 1955/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1350 - mae: 0.2897 - val_loss: 0.1348 - val_mae: 0.3005\n",
      "Epoch 1956/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1278 - mae: 0.2882 - val_loss: 0.1065 - val_mae: 0.2627\n",
      "Epoch 1957/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1193 - mae: 0.2790 - val_loss: 0.1259 - val_mae: 0.2821\n",
      "Epoch 1958/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1210 - mae: 0.2777 - val_loss: 0.1351 - val_mae: 0.2996\n",
      "Epoch 1959/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1286 - mae: 0.2908 - val_loss: 0.1042 - val_mae: 0.2639\n",
      "Epoch 1960/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1218 - mae: 0.2817 - val_loss: 0.1500 - val_mae: 0.3151\n",
      "Epoch 1961/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1347 - mae: 0.2952 - val_loss: 0.1278 - val_mae: 0.2810\n",
      "Epoch 1962/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1370 - mae: 0.2938 - val_loss: 0.1244 - val_mae: 0.2891\n",
      "Epoch 1963/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1444 - mae: 0.3008 - val_loss: 0.1618 - val_mae: 0.3301\n",
      "Epoch 1964/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1365 - mae: 0.2965 - val_loss: 0.1058 - val_mae: 0.2581\n",
      "Epoch 1965/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1331 - mae: 0.2927 - val_loss: 0.1286 - val_mae: 0.2931\n",
      "Epoch 1966/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1289 - mae: 0.2866 - val_loss: 0.1174 - val_mae: 0.2780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1967/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1205 - mae: 0.2761 - val_loss: 0.1767 - val_mae: 0.3389\n",
      "Epoch 1968/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1462 - mae: 0.3075 - val_loss: 0.1437 - val_mae: 0.2968\n",
      "Epoch 1969/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1526 - mae: 0.3139 - val_loss: 0.1119 - val_mae: 0.2623\n",
      "Epoch 1970/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1361 - mae: 0.2959 - val_loss: 0.1259 - val_mae: 0.2883\n",
      "Epoch 1971/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.1300 - mae: 0.2898 - val_loss: 0.1578 - val_mae: 0.3255\n",
      "Epoch 1972/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1407 - mae: 0.3045 - val_loss: 0.1076 - val_mae: 0.2586\n",
      "Epoch 1973/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1340 - mae: 0.2972 - val_loss: 0.1282 - val_mae: 0.2822\n",
      "Epoch 1974/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1317 - mae: 0.2882 - val_loss: 0.1435 - val_mae: 0.3057\n",
      "Epoch 1975/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1308 - mae: 0.2890 - val_loss: 0.1144 - val_mae: 0.2763\n",
      "Epoch 1976/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1192 - mae: 0.2806 - val_loss: 0.1143 - val_mae: 0.2719\n",
      "Epoch 1977/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1255 - mae: 0.2834 - val_loss: 0.1477 - val_mae: 0.3059\n",
      "Epoch 1978/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1390 - mae: 0.3012 - val_loss: 0.1177 - val_mae: 0.2729\n",
      "Epoch 1979/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1349 - mae: 0.2983 - val_loss: 0.1192 - val_mae: 0.2809\n",
      "Epoch 1980/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1194 - mae: 0.2781 - val_loss: 0.1282 - val_mae: 0.2898\n",
      "Epoch 1981/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1204 - mae: 0.2814 - val_loss: 0.1066 - val_mae: 0.2574\n",
      "Epoch 1982/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1201 - mae: 0.2797 - val_loss: 0.1155 - val_mae: 0.2773\n",
      "Epoch 1983/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1205 - mae: 0.2792 - val_loss: 0.1135 - val_mae: 0.2755\n",
      "Epoch 1984/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1178 - mae: 0.2753 - val_loss: 0.1374 - val_mae: 0.2940\n",
      "Epoch 1985/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1240 - mae: 0.2812 - val_loss: 0.1241 - val_mae: 0.2878\n",
      "Epoch 1986/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1264 - mae: 0.2866 - val_loss: 0.1210 - val_mae: 0.2782\n",
      "Epoch 1987/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1311 - mae: 0.2891 - val_loss: 0.1406 - val_mae: 0.3017\n",
      "Epoch 1988/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1344 - mae: 0.2969 - val_loss: 0.1222 - val_mae: 0.2780\n",
      "Epoch 1989/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1504 - mae: 0.3126 - val_loss: 0.1303 - val_mae: 0.2936\n",
      "Epoch 1990/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.1248 - mae: 0.2834 - val_loss: 0.1251 - val_mae: 0.2883\n",
      "Epoch 1991/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.1237 - mae: 0.2838 - val_loss: 0.1067 - val_mae: 0.2573\n",
      "Epoch 1992/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1185 - mae: 0.2760 - val_loss: 0.1052 - val_mae: 0.2640\n",
      "Epoch 1993/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1120 - mae: 0.2688 - val_loss: 0.1284 - val_mae: 0.2945\n",
      "Epoch 1994/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1203 - mae: 0.2813 - val_loss: 0.1044 - val_mae: 0.2569\n",
      "Epoch 1995/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1188 - mae: 0.2802 - val_loss: 0.1086 - val_mae: 0.2637\n",
      "Epoch 1996/2000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.1234 - mae: 0.2823 - val_loss: 0.1226 - val_mae: 0.2863\n",
      "Epoch 1997/2000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1223 - mae: 0.2820 - val_loss: 0.1057 - val_mae: 0.2591\n",
      "Epoch 1998/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.1184 - mae: 0.2766 - val_loss: 0.1092 - val_mae: 0.2630\n",
      "Epoch 1999/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1273 - mae: 0.2836 - val_loss: 0.1331 - val_mae: 0.3005\n",
      "Epoch 2000/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1314 - mae: 0.2943 - val_loss: 0.1412 - val_mae: 0.2990\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.SimpleRNN(2048, input_shape=(time_step,2)))\n",
    "model.add(layers.Dense(25))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(train_input, train_label, epochs=2000, verbose=1, shuffle=True, validation_split=0.20,\n",
    "                   callbacks=[WandbCallback(log_weights=True, log_gradients=True, training_data=(train_input, train_label))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2977e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    }
   ],
   "source": [
    "test_input = test_input.reshape(1, test_input.shape[0], test_input.shape[1])\n",
    "\n",
    "y_hat = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "569d2b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b083de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.reshape(1, test_label.shape[0], test_label.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e7a073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3e0c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3392382, 1.3830621, 1.4184731, 1.2852508, 1.3297856, 1.6162837,\n",
       "        1.6561847, 1.66861  , 1.5981638, 1.267556 , 1.5720837, 1.3751409,\n",
       "        1.4142469, 1.4633213, 1.5839739, 1.3412664, 1.5445671, 1.7366174,\n",
       "        1.6617211, 1.8281894, 1.5883944, 1.4088533, 1.6169508, 1.5412167,\n",
       "        1.5757614]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e37311d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0f0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat.reshape(y_hat.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ea1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = (y_hat*data_std)+data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "702f2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca1a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e40982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat = y_hat * (scaler.data_max_[1]-scaler.data_min_[1]) + scaler.data_min_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "902bb0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RNN prediction')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAAICCAYAAAA01KfJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADWRklEQVR4nOzdd3yb5bn4/88tD8lL3pYTZ3gkZDkhOyFhhhVayiq09EALHYcC3T2nHNr+TtvTcdqe9ttJoaUDaKGT0dIWCCOhQJadxNk7seMVb8t7Sbp/fzyS4ziO4yHp0bjer1dejqVHj26bIOl67msorTVCCCGEEEIIIQLDYvYChBBCCCGEECKSSdAlhBBCCCGEEAEkQZcQQgghhBBCBJAEXUIIIYQQQggRQBJ0CSGEEEIIIUQASdAlhBBCCCGEEAEkQZcQQghhAqXU15RSWin15gj3Pem978kgrynf+7xaKZUfzOcWQohIJkGXEEKEoSEf2If/6VNK1SqlNiilPqaUihvlHPnDHvvZCzznm+cLBJRS9w45j0cpteQC5/Ide+8Yf2QxSd5/M1+TYEoIIYJPgi4hhAh/9UP+uIApwHXAL4EtSqn0MZ7ny0opux/Wo4Dv+OE80ew0cMT71V++6v2TP8oxA97nPeL9uxBCCD+QoEsIIcKc1jp3yJ8kYCZGwAWwHPjJGE+VBfynn5Z1nVJqnZ/OFXW01l/UWs/VWn8xyM9b433euVrrmmA+txBCRDIJuoQQIsJorSu11vcBb3hvep9SKvkCD/uH9+vnlVKOSS7Bd67vKqXUJM8lhBBChD0JuoQQInJt8H6NB2Zf4NhHgEogCfjKJJ/3i4AHY5ft9kme6xxKqQpfPZhSKkUp9W2l1BGlVI9Sqkkp9Vel1KpRHu+rJ7tSKZWjlPqBUuqoUqpbKaVHOP5KpdQflFKVSqlepVSbUqpEKfWQUirpAmu9QSn1mlLKqZTqVErt8T7uvLV23sddsJGGUmq6Uur/lFK7vWvqUUqdUEr9TSn1IaWUbei5hjx007Bavooh57xgIw2lVKpS6itKqV1KqXbv8x5TSj2mlCocZb1Df+8pSqlvKqUOex/frJT6x2j/3YQQIpxJ0CWEEJFr6C5TzAWO7cOo9wH4d6VU0USfVGu9H/id99tvKaViJ3quC0gHSoGHMeqU+oFM4GaMWraPXODxs4C9wOeA6Rj1cIOUUrFKqV8Cm4A7vccMYASmK4DvAjuVUjNHOrlS6mvAS8A1QKr3sfO9j3sdIxieEKXUB4GjwBeAiwEbxn/DQuAm4ClgrvfwNox6P59Wzq4DbBzH8y4A9gP/AywB4jB+rlnA/cBBpdR7L3CaKcAu4MsYqbAeIAN4N/C2Uur6sa5HCCHChQRdQggRuXwfXjVQPobjfwscwPgg/a1JPvdXMIKA2cDHJnmu8/kqkAO8D0jSWqdiBDX/wnh/+4VSaukoj/8h4ASu9j7eDswZcv/3MdZeDzwIZGqtU4AE4CqgzHv880qps95PlVI3cSaI/QswQ2udDtiBTwCrgQcm8kMrpd6FEVTZgM3AZUCC1joNI7i7HKOmrx9Aa/0ZrXXukFPcNqwOcMUYnzcF+DswDajBCJJ8v7fFwDbACjyjlLp4lFP9zLu2dRgBbDKwEqN5RxzGfzf5fCKEiCjyoiaEEBFGKTVDKfU4xodagL9rrZsv9DittQf4kvfb910gYLnQuSqBR73ffkUplTjRc40iFbhDa/0XrbXL+7yHgBuAY0As8I1RHu8BrtFab/T+7GitjwIopYqBTwPdwLVa68e01i3eYwa01m8CVwDVwFKM3aWhvu39+i/gTq11lfexPVrrR73nThvvD+zdNXwEYxfzHWCd1vqdIetv11q/rbW+T2t9cLznv4AHgQKMna31WuuXhjzvHoyOmRUYgddoQbsLuEprvUlr7dGGUuAO7/0zgUv8vHYhhDCVBF1CCBHmlFJ1Q/50AaeAf/fefRjjw/KYaK1fxNg98Ufb928B7RjpZJ+d5LlGsllr/cbwG7XWPcD3vN+uV0qlnufxv9NaV5/nvo9i/A7+qbXeN9IBWusO4K/ebwdT4pRSizB23AC+6QtMhvklxm7ReF2FEfgAfE5r3T+Bc0zU+71fn/WmkJ7F+/v4P++3N4zye39ca90wwuP3cWZHdtFkFyuEEKFEgi4hhAh/jiF/hu4o/RZYMoHW3//l/XqtUurqiS7Ku7vm+xD+kFIqc6LnOo+NY7jPgrETNZLNozz+Uu/XG4YFtWf9AT7sPW5oXddy71cX8PZIJ/cGYm+O8vzns8b7tU5rvWMCj58QpVQ8ZwKh10c59DXv19F+79tHeXyt92vG2FcnhBChT4IuIYQIc1prpbVWGK/pUzEaGjiBDwGfmsD5NmPU7gB8Z5Jt338I1GGkAn7pAseO12jB5ND7cs5zzDm7LUNM9X5N5uygdvgfX/fCocGu7/matNZ9ozzH+XbZRuOrzTo1gcdORgZnmrGM9nsf+jOd7/feMcrjfc1MRu3uKIQQ4UaCLiGEiBDe2pjTWutfALdiNND47gSHFA9t+37HBY4dbU3dwNe9335CKTVjouca6fQTvM/HPcp9vgDjYV9Qe4E/V05wDRMVyHNP5rn1ef4uhBBRTYIuIYSIQN5GD7/DqEt6RCl1oZbxwx9/ACM9EeCbk2z7/kuMxhZWjFbj/jJtjPeNtqN1PnXerwsn8Fjf82UrpayjHJc3gXOf9n4tGPUo/2vhTJA6fZTjht435lb0QggR6SToEkKIyPV1jA/K84B7JvD4r3Km7fu/X+DY8/J2Fvz/vN9+yNsZ0B+uGsN9HozW7uPlq/d6t1IqeZyP9dVaxXKmNuws3pboV05gXVu8Xx1KqeWjHnku387TuNNFvQ079nq/Ha3O7xrvVw/GLC4hhBBI0CWEEBFLa30C+JP32/9WSo2rTsbb9v1n3m+/wpn6pYn4C0YwYgH+dxLnGepSpdSVw29UStmA//B+u0Fr7ZzAuX+JEaSkcaYT4oiUUnFDAzOt9V7gkPfbL59n5tRHGH2n7nw2ASe9f/+ht8HFWLV7v6ZN4HkB/uj9evtIgbP3d/CQ99uXtNZtE3weIYSIOBJ0CSFEZPs2RvCQj9EGfby+BbRhNHAY787KIK21Bh72fvueiZ5nmDbgOaXU7b70R6XUXOCfwFyMXb6vTOTEWuvdwI+8396vlPqLUmqxr6mIUipGKXWxUuq/gRMYw4GH+rL361XA75VS07yPsyml7seYteWcwLrcwCcx/pteCryhlLrUF9gppexKqSuVUk8rpeYPe7ivzftdE5yb9hhGS/c44GWl1A1DnnchsAEj7bGfMzubQgghkKBLCCEimnee0oveb798gRqjkR7fwpm275NdyxucaSnuD/+DUTf0F6BTKeXE2GFahxGUPDDJtupf4EzgdTtGmmK3UqoJ6AV2Y6RwTmdY0wit9QucGRD8fqBKKdWC0bnvMaDE+3XctNYvA/dipH5eitGWvlsp1YoRiG4C7gKG74L93Pv1vYBTKVWtlKpQSr0zxuftwBgCXYOxS/cS0KWUasNIPVzjXdNd3mHJQgghvCToEkKIyOf78D8N+PgEHv8jzjRwmKyH8V9Xu1ZgJcYQ50qMRh0tGO3u12qtfzmZk2ut3Vrrz2HMm3ocOIKxe5bqfe7NwNeAxd42+8Mf//8BN2LMDGv3ru8Qxu/gaowdoYmu7bcYu3k/Ag5itFqPx9h1+yvwQc6kOPoe87T39neAboyh1TMZR5qjN4hfgPFz7/Y+r9X7vD8HFmitn53gjyWEEBFLGRkfQgghRHhQSlVgBAsf1lo/ae5qhBBCiAuTnS4hhBBCCCGECCAJuoQQQgghhBAigCToEkIIIYQQQogAkqBLCCGEEEIIIQJIGmkIIYQQQgghRADFmr2AUJSVlaXz8/PNXoYQQgghhBAiRO3cubNJa509lmMl6BpBfn4+O3ZMZp6mEEIIIYQQIpIppU6N9Vip6RJCCCGEEEKIAJKgSwghhBBCCCECSIIuIYQQQgghhAggqekao4GBAaqrq+nt7TV7KRHDZrMxbdo04uLizF6KEEIIIYQQASNB1xhVV1eTkpJCfn4+SimzlxP2tNY0NzdTXV1NQUGB2csRQgghhBAiYCS9cIx6e3vJzMyUgMtPlFJkZmbKzqEQQgghhIh4EnSNgwRc/iW/TyGEEEIIEQ0k6IpA73rXu3A6naMe85WvfIXXX399Qud/8803ufHGGyf0WCGEEEIIIaKN1HRFEK01WmteeumlCx779a9/PQgrEkIIIYQQQshOV5j5wQ9+QHFxMcXFxfzoRz+ioqKCefPm8eCDD7J06VKqqqrIz8+nqakJgG984xvMnTuXa6+9lg984AN8//vfB+Dee+/l2WefBSA/P5+vfvWrLF26lIULF3L48GEASkpKWLNmDUuWLGHNmjUcOXLEnB9aCCGEEEKIMCY7XRPwP38/wMHadr+ec/5UO199z4JRj9m5cydPPPEE27dvR2vNqlWruOKKKzhy5AhPPPEEjz766FnH79ixg+eee46ysjJcLhdLly5l2bJlI547KyuLXbt28eijj/L973+fX/3qV8ydO5e33nqL2NhYXn/9db70pS/x3HPP+e1nFkIIIYQQIhpI0BVG3nnnHW699VaSkpIAuO2223j77beZOXMmq1evHvH4m2++mYSEBADe8573nPfct912GwDLli3j+eefB6CtrY177rmHY8eOoZRiYGDA3z+SEEIIIYQQEU+Crgm40I5UoGitR7zdF4SN9fiRWK1WAGJiYnC5XAD893//N1dddRUvvPACFRUVXHnlleNbsBBCCCGEEEJqusLJ5Zdfzl//+le6u7vp6urihRde4LLLLjvv8Zdeeil///vf6e3tpbOzk3/+85/jer62tjby8vIAePLJJyezdCGEEEIIIaKW7HSFkaVLl3LvvfeycuVKAD72sY+Rnp5+3uNXrFjBTTfdxMUXX8zMmTNZvnw5qampY36+hx56iHvuuYcf/OAHrFu3btLrF0IIIYQQIhqp8aSgRYvly5frHTt2nHXboUOHmDdvnkkrmrjOzk6Sk5Pp7u7m8ssv5/HHH2fp0qVmL2tQuP5ehRBCCCFEdFNK7dRaLx/LsbLTFeHuu+8+Dh48SG9vL/fcc09IBVxCCCGEECL8+DZtlFImryR8SNAV4X7/+9+bvQQhhBBCCBFBfvT6MV4/VM8/P33+3gLibBJ0CSGEEEIIIcbE5fbwzPZTNHX2M+D2EBcjffnGQn5LQgghhBBCiDF5+1gTTZ39ADR19pm8mvAhQZcQQgghhBBiTJ4vqxn8e327BF1jJUGXEEIIIYQQ4oI6egd49UAdi6enAVDf3mvugsKIBF1R6s033+TGG28E4MUXX+Q73/nOeY91Op08+uijg9/X1tZy++23B3yNQgghhBAidLy8v44+l4f7rygCoEGCrjGToCvCuN3ucT/mpptu4uGHHz7v/cODrqlTp/Lss89OaH1CCCGEECI8vbCrhvzMRK6d78CiJL1wPCToCiMVFRXMnTuXe+65h0WLFnH77bfT3d1Nfn4+X//617n00kv5y1/+wquvvsoll1zC0qVLueOOO+js7ATglVdeYe7cuVx66aU8//zzg+d98skn+eQnPwlAfX09t956KxdffDEXX3wxW7Zs4eGHH+bEiRMsXryYL3zhC1RUVFBcXAxAb28vH/7wh1m4cCFLlixh06ZNg+e87bbbWL9+PbNnz+ahhx4K8m9LCCGEEEL4S62zh23lzdyyJI8YiyI7xSrpheMgLeMn4uWHoW6ff8+ZuxBuOH+Kn8+RI0f49a9/zdq1a/nIRz4yuANls9l45513aGpq4rbbbuP1118nKSmJ7373u/zgBz/goYce4t///d/ZuHEjs2bN4v3vf/+I5//0pz/NFVdcwQsvvIDb7aazs5PvfOc77N+/n927dwNG8Ofzs5/9DIB9+/Zx+PBhrrvuOo4ePQrA7t27KSsrw2q1MmfOHD71qU8xffr0SfyShBBCCCGEGf66uwat4dYleQA47DbqO2Sna6xkpyvMTJ8+nbVr1wJw991388477wAMBlHbtm3j4MGDrF27lsWLF/PUU09x6tQpDh8+TEFBAbNnz0Ypxd133z3i+Tdu3MgDDzwAQExMDKmpqaOu55133uGDH/wgAHPnzmXmzJmDQdfVV19NamoqNpuN+fPnc+rUqcn/AoQQQgghRFBprXlhVw3LZqYzMzMJgJwUm9R0jYPsdE3EGHakAkUpNeL3SUnG/wBaa6699lr+8Ic/nHXc7t27z3msP2itz3uf1Wod/HtMTAwul8vvzy+EEEIIIQLrQG07xxo6+datxYO3OexWdlW2mriq8CI7XWGmsrKSrVu3AvCHP/yBSy+99Kz7V69ezebNmzl+/DgA3d3dHD16lLlz51JeXs6JEycGHzuSq6++msceewwwmnK0t7eTkpJCR0fHiMdffvnlPPPMMwAcPXqUyspK5syZM/kfVAghhBBChITnd9UQH2PhxoVTB29z2G20dPXT5xp/E7doJEFXmJk3bx5PPfUUixYtoqWlZTAV0Cc7O5snn3ySD3zgAyxatIjVq1dz+PBhbDYbjz/+OO9+97u59NJLmTlz5ojn//GPf8ymTZtYuHAhy5Yt48CBA2RmZrJ27VqKi4v5whe+cNbxDz74IG63m4ULF/L+97+fJ5988qwdLiGEEEIIEb5cbg8v7qlh3dwcUhPjBm932I3Pe41S1zUmarT0sGi1fPlyvWPHjrNuO3ToEPPmzTNpRYaKigpuvPFG9u/fb+o6/CkUfq9CCCGEEGJkmw438OEnS/nFB5dx/YLcc25/7oE1LJuZbuIKzaOU2qm1Xj6WY2WnSwghhBBCCDGi58tqSEuM46o5OWfdnuPd6ZJmGmMjQVcYyc/Pj6hdLiGEEEIIEbo6egd49UAdNy6aQnzs2WGDw24DkFldYyRBlxBCCCGEEOIcL++vo8/l4dYl0865LyMxnliLokFqusZEgq5xkPo3/5LfpxBCCCFE6HphVw35mYksnZF2zn0WiyInxUp9uwRdYyFB1xjZbDaam5slUPATrTXNzc3YbDazlyKEEEIIIYapdfawrbyZW5bknXfWa47dRkOHpBeOhQxHHqNp06ZRXV1NY2Oj2UuJGDabjWnTzt2uFkIIIYQQ5vrr7hq0hluX5J33GIfdSnlTVxBXFb4k6BqjuLg4CgoKzF6GEEIIIYQQAaW15oVdNSybmc7MzKTzHuew29h2siWIKwtfkl4ohBBCCCGEGHSgtp1jDZ2j7nIB5KRYaesZoHfAHaSVhS8JuoQQQgghhBCDnt9VQ3yMhRsXTRn1uBxv2/gGaaZxQRJ0CSGEEEIIIQBwuT28uKeWdXNzSEuMH/XYwVld0kzjgiToEkIIIYQQQgDw9vEmmjr7uHXp6KmFYDTSANnpGgsJuoQQQgghhBCAMZsrLTGOq+bkXPBYR4p3p6tddrouRIIuIYQQQgghBB29A2w4UMeNi6YQH3vhMCEtMY74GIukF46BBF1CCCGEEEIIXt5fR5/Lw61LxjZHVSlFjt0q6YVjYGrQpZT6jVKqQSm1f8htX1NK1Sildnv/vGvIfV9USh1XSh1RSl0/5PZlSql93vt+orxjs5VSVqXUn7y3b1dK5Qf1BxRCCCGEECJMvLCrhvzMRJbOSBvzY3JSrJJeOAZm73Q9Cawf4fYfaq0Xe/+8BKCUmg/cCSzwPuZRpVSM9/jHgPuA2d4/vnN+FGjVWs8Cfgh8N1A/iBBCCCGEEOGq1tnDtvJmblmSh3f/YkwcdpsEXWNgatCltX4LGOsY65uBP2qt+7TW5cBxYKVSagpg11pv1Vpr4LfALUMe85T3788CV6vx/CsSQgghhBAiCvx1dw1ac8GByMM57DZJLxwDs3e6zueTSqm93vTDdO9teUDVkGOqvbflef8+/PazHqO1dgFtQGYgFy6EEEIIIUQ40Vrzwq4als1MZ2Zm0rgem2O30tHnorvfFaDVRYZQDLoeA4qAxcBp4P95bx9ph0qPcvtojzmHUuo+pdQOpdSOxsbGcS1YCCGEEEKIcHWgtp1jDZ3j3uWCM23jZbdrdCEXdGmt67XWbq21B/glsNJ7VzUwfcih04Ba7+3TRrj9rMcopWKBVM6Tzqi1flxrvVxrvTw7O9tfP44QQgghhBAh7fldNcTHWLhx0ZRxP9Zhl1ldYxFyQZe3RsvnVsDX2fBF4E5vR8ICjIYZJVrr00CHUmq1t17rQ8DfhjzmHu/fbwc2euu+hBBCCCGEiHout4cX99Ry1dxs0hLjx/14h90KQH2H7HSNJtbMJ1dK/QG4EshSSlUDXwWuVEotxkgDrAA+DqC1PqCU+jNwEHABn9Bau72negCjE2IC8LL3D8Cvgd8ppY5j7HDdGfAfSgghhBBCiDDx9vEmmjr7uG3p2GZzDZdj96UXyk7XaEwNurTWHxjh5l+Pcvy3gG+NcPsOoHiE23uBOyazRiGEEEIIISLVC7tqSEuM46o5ORN6vN0WizXWIumFFxBy6YVCCCGEEEKIwOvoHeDVg3XcuGgK8bETCwuUUt5ZXZJeOBoJuoQQQgghhIhCL++vo3fAw61LJpZa6OOwW2Wn6wIk6BJCCCGEECIKvbCrhvzMRJbOSJvUeXLsNhqlkcaoJOgSQgghhBAiytQ6e9hW3swtS/IwGoBPnCPFJjtdFyBBlxBCCCGEEFHmr7tr0JoJDUQezmG30tXvprPP5YeVRSYJuoQQQgghhIgiWmte2FXDspnpzMxMmvT5ZEDyhUnQJYQQQgghRBQ5UNvOsYZOv+xyAeSkeAckS9B1XhJ0CSGEEEIIEUWe31VDfIyFGxdN8cv5zgxIlmYa5yNBlxBCCCGEEFHC5fbw4p5arpqbTVpivF/O6bDLTteFSNAlhBBCCCFElHj7eBNNnX2Tns01VLI1lsT4GBqkbfx5SdAlRJRo6xngyy/so6Wr3+ylCCGEEMIkL+yqIS0xjqvmZvvtnEopHHZpGz8aCbqEiBJ/LKnkme2VvHmkweylCCGEEMIEnX0uXj1Yx42LpmCNjfHruXNSrFLTNQoJuoSIAh6P5vcllQBUNHWZvBohhBBCmOHlfafpHfD4NbXQx2G3Ud8hO13nI0GXEFHgneNNnGruBqDc+1UIIYQQ0eWFshryMxNZOiPN7+d22K3Ut/eitfb7uSOBBF1CRIGnt50iMyme1YUZlDd1mr0cIYQQQgRZrbOHrSebuWVJHkopv58/J8VG74CH9l6X388dCSToEiLCnW7r4Y3DDdyxfDpzc+1UNHXLVSghhBAiyvx1dw1a47eByMPleNvGN0gzjRFJ0CVEhPtjSRUerfm3lTPIz0yks89FU6d0MBRCCCGihdaaF3bVsGxmOjMzkwLyHA7fgGRpGz8iCbqEiGAut4c/llZy+exsZmQmkp9lvNCWSzMNIYQQImocqG3nWENnwHa54EzQJW3jRyZBlxAR7PVDDdS393HXqhkAFGYlA9LBUAghhIgmz++qIT7Gwo2LpgTsOXJSjPTCemkbPyIJuoSIYM9sP8WUVBvr5uYAMDXNRlyM4qQEXUIIYYrGjj6+8rf9VLdKJ1kRHC63hxf31HLV3GzSEuMD9jxJ1lhSrLGy03UeEnQJEaEqmrp4+1gTd66YQWyM8b96bIyFGRmJstMlhBAmqGrp5o6fb+G3W0/xp9Iqs5cjosTbx5to6uwLyGyu4XLsVhpkVteIYs1egBAiMP5QUkmMRXHnyuln3V6QlURFswRdQggRTEfqOvjQb7bTO+BhWnoC2042m70kESVe2FVDakIcV83NDvhz5aTYJL3wPGSnS4gI1Dvg5s87qrh2nmOwsNUnPzOJ8qYuPB5pGy+EEMGw81Qr7/vFVgD+cv8lvHvRFHZXOenpd5u8MhHpOvtcvHqwjvdcPAVrbEzAn883IFmcS4IuISLQK/vraO0e4K7VM865ryA7iT6Xhzp5URRCiIB780gDd/9qO+mJcTx7/xoucqSwujCTAbemrLLV7OWJCPfyvtP0DniCkloIRgfDhvY+mQc6Agm6hIhAT287RX5mImuLss65r8A7n0PquoQQIrD+truGjz21g8LsJP5y/xqmZyQCsHxmOjEWJSmGIuBeKKshPzORpTPSgvJ8OXYb/W4PbT0DQXm+cCJBlxAR5nBdOztOtfJvq2Zgsahz7vfN6pIOhkIIEThPbangs3/azbKZ6fzhvtVke9tpA6TY4iieamfbyRYTVygiXa2zh60nm7llSR5Knft5IBAcdmkbfz4SdAkRYZ7ZVkl8rIXbl00f8f5cuw1bnEV2uoQQIgC01vzwtaN89cUDXDPPwVMfWYndFnfOcasLM9ld5aR3QOq6RGD8dXcNWhPQgcjDyYDk85OgS4gI0tXn4oWyGt69cAoZSSPP4rBYFPmZ0sFQCCH8zePRfPXFA/z4jWPcsWwaj921FFvcyM0LVhdm0u/2sEvqukQAaK15YVcNy2amM9NbVhAMjhQJus5Hgi4hIsiLe2rp7HNx9wgNNIbKz0yS9EIhhPCjfpeHz/xpN7/deoqPX17I/92+aHBG4kiW56djUUiKoQiIA7XtHGvoDOouFxhzugAaOiS9cDgJuoSIEFprnt52irm5KSydkT7qsQXZSVS1dONye4K0OiGEiFzd/S4+9tsd/H1PLQ/fMJcvvmveBWtoUmxxFOelSjMNERDP76ohPsbCjYumBPV5bXEx2G2xstM1Agm6hIgQe6rbOFDbzl2rZ17wzb4gM4kBt6bWKS+KQggxGc7ufu761XbeOdbId9+7kPuvKBrzY6WuSwSCy+3hxT21XDU3m7TEkUsNAslht0nQNQIJuoSIEE9vO0VifAy3LJ56wWPPdDDsDPSyhBAiYtW19fK+X2zlQE07j961jPevGD21e7jVhRn0uzyUVToDs0ARld4+3kRTZ1/QZnMN57DbJL1wBBJ0CREB2roH+PueWm5ZkkfKCF2yhivIklldQggxGScbO3nvY1uodfby5EdWsL44d9znWJ6f4a3rkhRD4T8v7KohNSGOq+Zmm/L8OXYrDdIy/hyxZi9ACDF5z+6qps/l4a5VY7vKmpUcT7I1lorm7gCvTAghIs/+mjbu+U0JAH+8bzXFeakTOo/dFseCqVLXJfyns8/FqwfreO/SaVhjR+6cGWjGTlcvHo8ecV5otJKdLiHCnNaaZ7afYsmMNBZMHdsbv1KK/KxE6WAohBDjtPVEM3c+vg1bXAx/uf+SCQdcPqsLMyiTui7hJy/vO03vgIfblpqTWgjgSLEy4Na0dvebtoZQJEGXEGFu68lmTjZ2cdeqmeN6XEFWsqQXCiHEOGw4UMc9T5QwJdXGsw9cQmF28qTPubowk36Xh91VzskvUES9F8pqyM9MZOmMNNPWcGZAsqQYDiVBlxBh7pntlaQmxI27LWxBZiLVrd30u6RtvBBCXMifS6t44OmdzJ9i588fv4QpqQl+Oe/y/AyU1HUJPzjd1sPWk83csiTvgl2MA8k3q6u+QzoYDiVBlxBhrKGjlw3767h92TRscePL3S7ITsKjobJF6rqEEGI0P//XCR56bi9rZ2XxzMdWkZ7kvzbcqQlxLJhqZ7sMSRaT9NeyWrQm6AORh8tJMXa6GqRt/Fkk6BIijP1lRzUuj+bfxthAY6j8TOlgKMJPR+8AjdKKWASJ1ppvv3SI77x8mBsXTeHX96wgyer/HmSrCzLZVdkqdV1iwrTWPL+rmmUz05npfX83y+BOl6QXnkWCLiHClNuj+f32StYUZVI0gboCX9v4cgm6RBj5+O928pEnS81ehogCLreH/3puL7946yR3r57Bj+9cQnxsYD42rSrMpM/lYU8E1nV9+6VD/Otoo9nLiHgHats51tBp+i4XgDU2hvTEOBokvfAsEnQJEab+dbSBGmcPd68eXwMNn7TEeNIT4yhvlqBLhIcdFS1sOdEsu7Mi4HoH3Dz4zC7+vKOaT189m2/cXExMAFtfrxys64qsFMOqlm5+8dZJfv1OudlLiXjP76ohPsYy7vruQHHYbbLTNYwEXUKEqae3VZKdYuXa+Y4JnyM/K0k+wIqw8cim4wB09Lno6nOZvBoRqTp6B7j3iRJePVjP194zn89fe1HAmxKkJsYxf4qd7eWR1UzjjUP1AJSWt0jTpgByuT28uKeWq+Zmk5bov3rDycix26SmaxgJuoQIQ9Wt3Ww60sCdK6YTFzPx/40LMpMkvVCEhX3Vbbx5pJE5jhQA6uXNXARAU2cfdz6+jR0Vrfzo/Yu5d21B0J57dWEmO0+10ueKnLquNw43YFHQM+CWlvgB9PbxJpo6+7h1iXmzuYZzpFhlp2sYCbqECEN/KKlEAXeuHH8DjaEKspI43dZLT3/kvMmLyPSzTcex22L53LUXAVKgLfyvqqWbO36+lRONnfzyQ8u5Jci1MasKMrx1XW1Bfd5A6exzsf1kC3csm45FwebjTWYvKWK9sKuG1IQ4rpqbbfZSBjnsNho7+3B7tNlLCRkSdAkRZvpdHv5UWs26uTnkpU1uTky+t5nGqRbZ7RKh62h9B68cqOPeNfnMyjGaxkiBtvCno/Ud3P7zLTR39vH0R1dx1dycoK9hZYFR17U9QuZ1vXOskX63h1uX5lGcl8rWE5Hxc4WaPVVOXj1Yx42LpmCNHd/omEDKsVtxezTNXXKBzEeCLiHCzGsH62nq7OOuVRNroDHUYAfDRgm6ROh6dNNxEuNj+PDaAhzeVsR1bRJ0Cf/YeaqVO36+Fa3hz/dfwvL8DFPWkZYYz7xcO9sipK7r9UMN2G2xLJ+ZziVFmZRVtdLdL7WY/nKysZMHn9nJzT/bTFJ8LPeuyTd7SWc5M6tLgi4fCbqECDNPbzvFtPQELr9o8mkEvp0u6WAoQtWp5i5e3FPL3atnkp4UT7I1lsT4GEkvFH6x5XgTd/9qO2mJcTz3wBrm5tpNXc+qwoyIqOtyezSbDjdw5ZwcYmMsrC3KYsCtKa1oNXtpYa+hvZcvv7CPa3/4Fm8eaeQzV8/mXw9dxWxvvWuo8F0gk6yEM/w/4U8IETDHGzrZerKZL1w/xy/ti5OtsWSnWKWDoQhZP//XCWJjLHzsUqOhgVKKXLuNenkjF37wfxuOkGO38uz9a8hOsZq9HFYXZvLE5gr2VrexwqQdN3/YU+2kuaufq+cZaZrL89OJi1FsOd7EFX64YBiN2nsHePxfRvv9AbeHu1bN4FPrZofEv9uROOzGTpdcIDtDgi4hwsjvt1cSF6N43/LpfjundDAUoarW2cOzO6u5c8UMcrxv4GDUCtRLeqGYpD6Xm4O17Xx4bX7IfHBdNaSuK5yDrjcO1RNjUVx5kRF0JcbHsmRGOlukrmvc+lxufrf1FD/bdJzW7gHec/FU/uPaiwYzVUKV7/8p6TR7hqQXChEmegfcPLuziusX5Pr1A0JBVhLlTd1+O58Q/vL4WyfRGj5+ReFZtztkp0v4wYHadvrdHpbMSDN7KYPSEuOZm2sP+yHJbxxqYPnMdFIT4wZvW1OUyf7aNpzd/SauLHy4PZrndlaz7vv/4pv/PERxXip//+Sl/PQDS0I+4AKIi7GQlRwvO11DSNAlRJj4+55a2ntd3L168g00hsrPSqKps4+O3gG/nleIyWjs6OOPpZXcuiSPaemJZ92Xa7dR396H1tKKWExcWaUTgCUz0s1dyDCrCjLYcSp8hwlXt3ZzuK6Da+Y5zrp97awstCbsA8pA09qoh3v3T97mP/6yh/SkOH730ZX87qOrWDgt1ezljUtOigxIHkqCLiHCxDPbKynKTmJVgX9TTgqyjA+0FbLbJULIr98pp9/l4YEri865L8duo9/lwdktFwrExO2ucjIl1TZYexIqVhdm0jvgYV+N0+ylTMimww0ArJt3dtv9i6elkRAXw5YTMq/rfHZVtvL+x7fx4SdL6Rlw89MPLOHFT1zKZbPDsw4ux26VrIQhTA26lFK/UUo1KKX2j3DffyqltFIqa8htX1RKHVdKHVFKXT/k9mVKqX3e+36ilFLe261KqT95b9+ulMoPyg8mhJ/tr2ljd5WTu1bNxPvP228Ksoy5R9LBUISKtu4Bnt52inctnEJhdvI59/u6YsmbuZiMssrWkEot9PFdWAvXHaHXDzVQkJVE0bD/d+NjLawsyJAhySM43tDJx3+3g9se3cLJxk6+fvMCXvvcFbzn4qlY/NA0yyyOFJukFw5h9k7Xk8D64TcqpaYD1wKVQ26bD9wJLPA+5lGllG8K3GPAfcBs7x/fOT8KtGqtZwE/BL4bkJ9CiAB7ZnsltjgL7106ze/nnplp7HTJrC4RKp7cUkFnn4tPXDVrxPtzpSuWmKSGjl6qW3tYMj20UgsB0pPimZubwrYwHJLc1edi64lm1p1nuPSaokxONHZJcwWvurZevvj8Xq774b9451gTn7vmIv71hav40CX5xMea/RF98hx2K02dfbjc4Zkq62+m/hfVWr8FjHQp54fAQ8DQhP2bgT9qrfu01uXAcWClUmoKYNdab9VGgv9vgVuGPOYp79+fBa5W/t4mECLAOnoH+NvuGt6zaOpZRcn+YouLIS8tgQrZ6RIhoLPPxW82l3PNPAfzpow8M2mwFbF0MBQTtHuwnivN1HWcz+rCTHZUtDIQZh9W3zneRL/bM9gqfri1s4zkpWhPMWzrGeC7rxzmiu9t4tmd1Xzoknz+9dBVfOaa2SRZI6exeI7dhtbQ3CXNU8D8na5zKKVuAmq01nuG3ZUHVA35vtp7W57378NvP+sxWmsX0AZkBmDZQgTMX8tq6O53+72BxlD5WYnSNl6EhGe2naKtZ4BPrht5lwukFbGYvN1VTmItiuK80GxMsLowg54BN3ur28xeyri8caieFFvsedvdz59iJzUhji3Hw28Xzx96B9w8/tYJLv+/TTz25gluKM7ljc9fydduWkBWcmiMLfCnM7O65LUaQmxOl1IqEfgycN1Id49wmx7l9tEeM9Jz34eRosiMGTMuuFYhgkFrzdPbKinOs7MogF2L8jOT+Mfe0wE7vxBj0Tvg5pdvl3PZ7CwWT08773G2uBjSE+OkpktMWFmlk3lT7NjiYi58sAlWFhjXh7edbGbZzNBLgRyJx6PZeLiRKy7KJi5m5Gv6FoviksJMtpxoRmvt9xrlUOX2aJ7fVc0PXztKbVsvl1+UzUPXzwnZoN9fButvJRUcCL2driKgANijlKoApgG7lFK5GDtYQyfCTgNqvbdPG+F2hj5GKRULpDJyOiNa68e11su11suzs8OzS4yIPDtPtXKkvoO7A9BAY6iCrCTaegZolRQAYaI/76iiqbPvvLVcQznsNura5I1cjJ/bo9lT7QzZ1EKAjKR45jjCq65rb00bTZ1957SKH27trExqnD1UtkR+x1ytNa8frOeGH7/FF57dS1aKld9/bBW//cjKiA+4QHa6hgupoEtrvU9rnaO1ztda52METUu11nXAi8Cd3o6EBRgNM0q01qeBDqXUam+91oeAv3lP+SJwj/fvtwMbtQx2EWHk6W2nSLHGctPiqQF9ngLvoEXpYCjM0u/y8PM3T7B8ZvqYxiLk2G00yE6XmICj9R1097tDOugCI8Vw56nwqevaeKgei4IrLhr9wvUlRUZd1+YITzHcUdHCHT/fysd+u4MBt+Zn/7aUv31iLWtmZV34wREiMykei0JmdXmZ3TL+D8BWYI5Sqlop9dHzHau1PgD8GTgIvAJ8Qmvt9t79APArjOYaJ4CXvbf/GshUSh0HPg88HJAfRIgAaOnq56V9ddy2NI/E+MBmAvum20sHQ2GWv5bVUNvWyyfXzRrTrm6u3SpXT8WEDA5FDsHOhUOtLsyku9/NvprwqOt6/VADy2dmkJ4UP+pxRdlJOOzWiG2mcay+g489tYPbf76ViuZuvnlLMa9+7nLevWhK1KRT+sTGWMhMtkp6oZepNV1a6w9c4P78Yd9/C/jWCMftAIpHuL0XuGNyqxTCHH/ZUUW/28NdAWyg4TM9PZEYi5IOhsIUbo/m0TePszAv9YJXyX0cdhuNHUYr4tjz1I8IMZLdVa2kJ8YNjssIVSsH53U1s3RGaAeItc4eDp5u5+Eb5l7wWKUUa4qyeOtoIx6PDus5VMM99uYJvrfhMInxsfzndRfxkUsLAn7RNNQ5ZEDyIHmnEiIEeTya35dUsjI/g4scKQF/vvhYC9PSE6SDoTDFP/bWUtHczSeuKhrzleAcuw2PtCIWE1BW6WTx9LSQ33XITLZykSM5LIYkbzzcAMA152kVP9yaokyau/o52tARyGUFVb/Lw6ObjrN2VhZvPXQVn1w3O+oDLjAGJDfIThcgQZcQIemd402cau7mrtXB66SZn5kkQZcIOo9H8+imE8zOSea6+bljflyuFGiLCWjrGeBYQydLQnznyGd1YSY7K1pCvq7rjUP1zMhIpCg7eUzH++qaIqmua8uJJjr6XNy7Jp+MC6RYRhOpvz1Dgi4hQtAz20+RkRTP+uKxfwidrIKsJCqaupBeMyKYXj9Uz5H6Dj5x1axxpRn5WhHXyYBkMQ57q51A6A5FHm51YSZd/W72h3BdV3e/i80nmrl6Xs6Ydw/z0hLIz0xkawTVdW04UEdSfMzgAGhhcNitNHX2h/yFg2CQoEuIEFPX1svrhxq4Y/k0rLHBmyFTkJVEV7+bxk5JAxDBobXmkU3HmZGRyI2LpozrsYOtiDvk36sYu7JKJ0rBxaPMgQslZ+q6QjfFcPPxZvpdHq6eO3qr+OEuKcpi+8kWXBHwYdzt0bx6oJ4r5+aE7Ow3s/heqxvltVqCLiFCzR9LK3F7NHetDHwDjaGkg6EItrePNbG3uo0HriwadzOMrGSrtCIW47a7ysms7GTstjizlzImWclWZuckh/S8ro2H60mxxg4GiGO1dlYmHX2usOnOOJqdp1pp7upn/YLgZaeEizMDkuW1WoIuIUKIy+3hjyVVXH5RNjOC3Fmr0Bt0SQdDESyPbDrOlFQbty3NG/djYyyK7BSrpBeKMdNaU1bZyuIw2eXyWV2YyY6K0NwR8ng0bxxq4PKLsomPHd9HyksKMwHYciJ0A8qxemV/HfExFq6cM7buq9EkJ8VXfys7XRJ0CRFC3jjcQF17L3evCl4DDZ+paQnEx1g4Kc00RBCUlLdQUt7CfZcXTjiN1mG3SXqhGLNTzd20dg+ETRMNn1WFGUZdV2272Us5x/7aNho6+lg3d2xdC4fKTLYyNzcl7Od1aa3ZcKCOS2dnkRImO6jBlOPd6ZJmGhJ0CRFSntleyZRU24TewCYrxqKYnpFAhQRdIgge2XSczKR47lwx8QsMDrtN0gvFmJVVtQLh00TDZ1WBsSMUiimGbxxqQCm4aoLvWWuKsthR0UrvgNvPKwueA7Xt1Dh7uH7B+GraokVmkpUYi5K28UjQJUTIONXcxVtHG7lzxQzThr0WZCVT0dRtynOL6LG32slbRxv52GWFJMRPvOjcYbdSJ0GXGKPdlU4S42OCMvvQn7JTrMzKSWZ7KAZdh+tZOiN9wi3S187KpM/lYVdlq59XFjwbDtRhUXDNPAm6RhJjUWQnW6WmCwm6hAgZvy+pJMaieP+K6aatoSArkYrmLjweaRsvAueRjcex22K5e5Jz6BwpNpzdA2F9lVwET1mVk4unpREzjtEEoWJ1YQalFa0hVddV19bL/pp2rh7jQOSRrCzIIMai2BLG87pe2V/HyoIMMpOtZi8lZDnsVkkFR4IuIUJCn8vNX3ZUc+08B7mpNtPWUZCVTJ/Lw2m5IiUC5EhdB68erOfetQWTrn9wpEorYjE2vQNuDta2szjMUgt9VhVk0tnn4kAI1XVtPNwAMO5W8UOl2OJYNC01bOu6TjR2cqyhk+ula+GociQVHJCgS4iQ8Mr+Olq6+rlrklf+Jys/y+iYKHVdIlAeffM4SfExfHhN/qTP5Zv/IimG4kL217Th8miWhFnnQp9Vhb55XaGzI7TxcD3T0hO4yJE8qfOsKcpkT3UbHb0DflpZ8Gw4UAcgQdcFOOySXggSdAkREp7edor8zETWFpk7yb7A2zZeOhiKQKho6uLve2q5e/VM0idYAzKUzH8RY1VW6QQI252unBQbRdlJbC8PjSHJvQNu3jnexDXzHCg1uXTNtUVZuD2a0orQ+NnGY8OBehZNS2VqWoLZSwlpjhQbrd0D9LmiOxVcgi4hTHakroPSilb+bdUMLCbXGjhSbCTExchOlwiIx948QWyMhY9eVuCX8+XaZf6LGJvdVU6mpScMzgwKR6sLMyktD415XZuPN9E74PFLp92lM9OJj7WwOczqumqdPeypcsou1xgMto2P8tdqCbqEMNkz208RH2vh9mXmNdDwsVgUMzMTJegSflfr7OH5smo+sGK63z74pibEER9rkZ0ucUFlla1hN59ruFWFmXT0uTh42vy6rjcON5AUHzOY9jgZtrgYls9MZ/Px8KrrelVSC8csx3uBLNpndUnQJYSJuvpcPL+rhncvnDLhlrv+VpCVRLkEXcLPHn/rJFrDfVcU+e2cSimpFRAXVNfWS21bL4vDtJ7LZ3WBEeBsP2luGp7Wmo2HGrhsdvaEB5sPt6Yok8N1HTR3hs9OyIYD9czKSWZWzuRq2qKBw3uhTXa6hBCmeXFPLZ19rkm3zvangqwkKlu6QyKFRUSGxo4+/lBSyW1L88jzc+1Drt0mQZcY1e4wHYo8XI7dRmF2kunNNA7UtlPX3jupVvHDrZll1DNvDaFGIaNp6epne3kz62WXa0yk/tYgQZcQJtFa8/S2U8zNTWFpCKW95Gcl4fJoapw9Zi9FRIhfvXOSAbeHB66c5fdz59htUtMlRlVW6SQ+xsKCqXazlzJpqwoyKSlvwW3iLMU3DjWgFFzlh3oun0V5qSRbY9lyIjyCrtcP1ePRklo4VumJ8cTFqKif1SVBlxAm2VPdxoHadu5aPXPS3Z/8SToYCn9ydvfz9NZT3Lho6uC/LX9ypBg7XVrLQG8xsrIqJ/On2v2WCmem1YUZRl2XifO6Nh6uZ/H0NLL8OAw4NsbCqoIMtoRJXdeG/XXkpSVQnBf+gXwwWCyKnBTJSpCgSwiTPLPtFInxMdyyeKrZSzmL74OxNNMQ/vDE5gq6+t184ir/73IB5KZa6e5309nnCsj5RXhzuT3srXaGfWqhz+rCTAC2l5uzI9TQ3sue6jaumTfxgcjnc0lRJhXN3SGfZdHZ5+Lt401ct2Dy7fKjSY7dKjVdZi9AiGjU1j3A3/fWcvPiPFJscWYv5yyZSfGkWGMl6BKT1tnn4sktFVw738Gc3JSAPIdjsG18dF9BFSM7XNdB74An7Jto+DjsNgqzzKvr2ni4AcAvreKHW+ut6wr13a43jzTQ7/JIPdc45aRI0yMJuoQwwXO7qukd8HDXqtBpoOGjlCI/K0nSC8WkPb3tFG09A3wyQLtcwGD7eanrEiMpq3IChFTd7GStKsxgu0l1XW8cbiAvLYG5AbiIMseRQmZSPFtDvK5rw4F6MpPiWZ4/+Xb50cQhTY8k6BLCDM+XVXPx9DSK81LNXsqICrKSqGiWoEtMXO+Am1+9fZLLZmdxcQB3GXJTZadLnF9ZZStZyfFMS/dv10wzrS7MpKPXxaEgz+vqHXDzzrEm1s3NCUhancWiWF2UyeYTTSFbo9nncrPpcAPXzncQY5HUwvFw2G2097roHXCbvRTTSNAlRJC19w5woLadq+Zkm72U88rPSqKmtYc+V/S+OIrJ+WNJJU2d/QHd5QIjZQWgToIuMYLdVU4WT0+PqNqbVQVGXVewUwy3nmymZ8Dt11bxw60tyqK+vS9kMy22HG+ms88lXQsnwPdaHc11XRJ0CRFku061ojWsDOHUhMKsJDwaqlq6zV6KCEP9Lg+/eOskK/MzWOUt/A+UJGssKdbYqH4jFyNzdvdzsrErYppo+OSm2sjPTGRbkIckv3GonsT4mMFmHoGwpsg4d6jWdb2yv45kayxrZgX2dS0SDdbfdkTvBTIJuoQIsh0VrcRYFItD+INAvreDYXmTBF1i/J7fVc3ptl4+sS6wu1w+jlSpFRDn2u2t51oSIU00hlpdmElJeXPQ6rq01mw81MCls7KwxQWu9f7MzETy0hJCcl6Xy+3htUP1rJubExHjB4JNmh5J0CVE0JVUtFA81U5ifKzZSzmvgkxf0NVp8kpEuHG5PTz2rxMszEvl8tlZQXlOh90q6YXiHGWVTpSCRREadLX3ujhcF5y6rkOnO6ht6w1Iq/ihlFJcUpTJ1pPNeEwcAD2SHadaaenql9TCCXLYjfTCaG56JEGXEEHU53Kzp8rJihBOLQRITYwjIyledrrEuP1z32lONXfzyXWzglZH40ixSXqhOMfuKidzHCkkW0P3AtdErSo03kOClWL4xqF6AK6cG/ha5LWzMnF2D3AwyI1CLuSV/XXEx1q4MoTrsUNZakIc8bEWGqL4ApkEXUIE0f6advpcnrBoNZufmSizusS4eDyan206zkWOZK4N8BXxoRypNho6ekPuyrgwj8ej2V0VOUORh5uSmsDMzMSgNdN443ADF09PGxzREEhrirzzuk6ETl2X1ppXD9Rx+ewskiIwiA8GpVTUz+qSoEuIINpRYVyVXJ4f+jNj8rOSKJegS4zDqwfrOVrfySeumoUliO2UHSlWBtyalu7+oD2nCG3lzV209QxEzFDkkawuyKSkvCXgFxsaO/rYU+3k6gAMRB6Jw26jKDsppOq69tW0UdvWK6mFk2TM6orerAQJuoQIotKKFgqzkshKtpq9lAsqzEqirr2Xnv7wbBu/6UgDTvkQHjRaG7tcMzMTeffCKUF9binQFsOVVToBWBJBQ5GHW12UQVvPAIfrOgL6PJuONKA1AW0VP9yaoixKylvod3mC9pyj2XCgjhiLCnhNW6Rz2K00SPdCIUSgeTyaHadaQ76ey8fXwTAchyTXt/fy4SdK+dHrx8xeStR461gT+2raePDKImJjgvvW4vAOSJa6LuFTVtlKijWWWdnJZi8lYII1r+uNQ/VMSbUxf4o9oM8z1NpZmXT3u9lb7Qzac47mlf11rCrIID0p3uylhLWcKK+/laBLiCA50diJs3sgLFILAfIHOxiGX9C1vdxI43xlf53U+QTJIxuPMTXVxq1LpgX9uX07XdLBUPjsrnJy8fS0oKa5BtvUtARmZAS2rqvP5ebtY02sm5sT1AHTqwszUQo2Hzc/xfB4QwcnGrsktdAPHHYbHX0uuvpcZi/FFBJ0CREkpRWtAGGz01WQFb5BV0m58UZd197LnhC5UhrJtp9sprSilfsuLyQ+NvhvK9nJvlbEEnQJ6O53cbiuI2KbaAy1ujCDkorA1XVtO9lCd7876Gl1aYnxLJhqD4lmGhsOGJ0br1sgqYWT5Wsb39ARnbtdEnQJESSlFS1kJVuZmZlo9lLGJMkaS06KNSw7GG4/2cKSGWnExShe2V9n9nIi3iObjpOVHM+dK2eY8vzxsRaykuOjukBbnLGvug23R0d0Ew2f1YVGe/Uj9YGp69p4qB5bnIVLijIDcv7RrCnKoqzSaXpd8YYDdSyensaU1ART1xEJor3+VoIuIYKktKKFlQXpQU3RmKxw7GDY3NnHsYZOrpnnYE1RFi/vr0NrSTEMlD1VTt4+1sTHLivEFhdj2jpyUmxR+0YuzlZW5QSIiqBrVWHg6rq01rx+qIFLZ2Wb8v/2mqJM+t0edpwKziyykdQ4e9hb3SaphX6SkxLdWQkSdAkRBKfbeqhu7WH5zPBILfQpzEoKu0Yapd62/KsLM7ihOJfKlu6QG7IZSR7ZdJzUhDjuXj3T1HU47NE9/0WcUVbZyszMRDLDoEvsZOWlJTA9IyEgQdeR+g5qnD1B7Vo41Ir8DGItytS6rg3eTInrJbXQL3Ls0d30SIIuIYIg3Oq5fPKzkmjq7Ke9d8DspYzZ9vIWrLEWFualce18BxaFpBgGyOG6dl47WM+H1+aTbPLA0NzU6J7/Igxaa8oqnSyJgl0un0DN63rjUAMA64I0n2u4JGssS2aksdXEuq4NB+q4yJFMYQR3wQwmuy0WW5wlatvGS9AlRBDsqGghKT6GeVNSzF7KuPg6GIZTXVdJeQtLZ6QTH2shM9nKqoJMXpagKyB+tukESfEx3Lsm3+ylkJNio7mrjwF3aMz1EeY43dZLQ0dfRM/nGm5VYSat3QMcbfBvXdcbh+pZmJc6WIdjhkuKsthX00ZbT/Av/DV39lFa0cJ6SS30G6VUVA9IlqBLiCAorWhl6cz0oM8vmqzC7PDqYNjWM8DB0+2sKjyzo3jDwlyON3Ry3M8fSKLd/po2/rm3lrsvmUlaovmzaxx2G1pDY5R2xRIG31DkaKjn8llVYLzebTvhvzS85s4+yqqcpqUW+qwtysSjAz+LbCSvH6rHo+E6Cbr8yhHF9bfh9QlQiDDU3jvA4br2sKvnApiRkYhS4RN07TzVgtawsuDM7/q6+cYbpqQY+k+ts4ePPlWKw27jvssKzV4OALmp0V2gLQxlla3Ex1qYF8RBvmabnpHItPSEwfmE/rDpSCNaE/RW8cMtnpGGLc7CVj8GlGP1yv46pqUnsGBq9PxbCoYcu1VaxgshAmPnqVa0hhVhMhR5KFtcDFNTE8ImvXB7eQtxMYol08/8rnNTbSydkSYphn7S1jPAvU+U0N3n5okPrwiZZgU5KdHdilgYdlc5WZiXasq8ODOtLsxkux/rujYersdht5oecFhjY1iRn8Hm48Gt6+roHWDz8WauX5AbVh2Hw4GRXtgblV2Fo+tVSQgT7KhoIdaiWBymgzoLspIob+42exljsv1kCxdPSyMh/uz2xjcUT+FAbTuVYfJzhKo+l5v7f7eT8qYufvHBZczNDZ0rwGfmv0TnFVQB/S4P+2raoqqJhs+qggxauvo51tA56XP1uzy8dbSJdXMdIRFwrCnK4lhDZ1CbL2w60ki/28P6Ykkt9DeH3Up3v5vOPpfZSwk6CbqECLDSilYW5KWSGG9ud7eJys9KpLyxM+SvSnX1udhf03ZWaqGP743zlQOng72siKG15r+e3cvWk8383+2LWDMry+wlnSUzKZ5Yi5Kdrih2uK6dPpcnqppo+Kz247yu7eXNdPa5uNqkroXDrZ1l/GzBTDHccKCOrGQrS6Pw31KgnclKiL4LZBJ0CRFAfS43e6qcrJgZvi/cBVnJtPe6aO0O7bbxZZVOXB49YtA1PSOR4jy71HVNwvc2HOGvu2v5wvVzuHXJNLOXcw6LRZGTYqVOgq6oNdhEI0yzCiZjekYieWkJbC+ffGDyxqEGrLEW1obIhZUFU1Ox22LZEqR5Xb0DbjYdbuDa+Q5iLObv9EWaHLuRkt4Qha/VEnQJEUD7a9roc3lYHmbzuYYqyEoEQr+ZxvbyZiyK8/6u1y/IZVelk7q26Huhn6xntp/i0TdP8IGVM3jwyiKzl3NeOXZb1A7dFEYTjZwUK1NTzWtxbqZVhRlsO9kyqawErTVvHK5n7aysc9K0zRJjUawuzGRzkOZ1vXOsie5+t6QWBogvFTwam2lI0CVEAJ0Zihy+O12+WV2hH3S1UJyXet4hveuLpwBG2ogYuzcO1fPff93Purk5fOPmBSFR43E+ufbobUUsjCYaS2akhfS/0UBaXZg56bqu4w2dVLX0mN4qfrg1RZlUt/ZQ1RL4utwNB+pIscVyiTdlU/jXmfrb6HutlqBLiADaUdFCYXZSyHR4m4jpGYnEWFRIdzDsHXCzu8rJylF2FGflJDM7J5mX90td11jtqXLyyd+XsWBqKj/9wJKQnzPnsEt6YbRq6eqnork7Kuu5fHxBwvZJ1HW9fqgBgKvnmtsqfjhfqmOguxi63B5eP1TP1XNzoq4DZrAkW2NJio+Rmi4hhP94PJrSilZWhOF8rqHiYixMT0+gvDl0g649VU76XR5WXeDK5A3FuZSUt9DcGX0v9uNV2dzNR58qJTM5nl/fu5yk8+wghpIcu42OXhfd/dHXFSva7a4ysgqisXOhz7T0BPLSEth2cuLzujYermfBVDu5IZaiOSsnmewUK1sC3EyjpKKF1u4BrpeByAHlsNuoD2I3ylAhQZcQAXK8sZO2ngFWjNDYIdzkZyVR3hi6QVeJdyjohdI41xdPwaPh1YP1wVhW2Grt6ufeJ0oYcGue/PDKwW5ToS7XVysQhVdQo11ZpZMYi2LhtFSzl2IapRSrCjLYdrJ5QnVdrV397DzVytUmD0QeiVKKNUWZbDkxsZ9trDbsr8Maa+GKOdkBew7hHZAchVkJEnQJESClFWMLBMJBQVYSFc1dIds2vqSihbm5KaQlxo963LwpKczMTJQuhqPoHXDz77/dQbWzh1/ds5xZOclmL2nMfLUCkmIYfcoqncxxpITtaA5/WV2YSXNXP8cnUNe16UgDHk3ItIofbm1RFk2dfX6ZRTYSj0ez4UA9l1+UHfX/jgItJ8Um6YVCCP/ZUdFKdoqVGRmJZi9l0gqykujud9MYgt2GBtwedp5qZdUYdhSVUqxfkMuWE0209YR2C3wzeDyaz/1pNzsrW/nh+xazIsy6bjq8rYijsUA7mnk8mj3eJhrRbnBeV/n4UwzfONxAdoqVhXmhuVt4SZHxswWqrmtvTRt17b2sl9TCgHPYrdS394bshdxAMTXoUkr9RinVoJTaP+S2byil9iqldiulXlVKTR1y3xeVUseVUkeUUtcPuX2ZUmqf976fKG/rIqWUVSn1J+/t25VS+UH9AUVUKylvYUV+ekR00vJ1MDwZgs009te00d3vZmXB2DpNrS/OZcCteeOQpBgO981/HuLl/XV8+V3zePeiKWYvZ9wcqZJeGI1ONHbS0eeK6iYaPtMzEpiSahv3kOR+l4e3jjSybk4OlhCdTTU9I5EZGYkBq+vacKCOWIsKuc6Nkchht9Hn8tDeG131t2bvdD0JrB922/e01ou01ouBfwBfAVBKzQfuBBZ4H/OoUso3ROIx4D5gtveP75wfBVq11rOAHwLfDdhPIsQQtc4eapw9YbdTcD4FWUbQFYodDAfruQrG9oHr4mlpTEm18bKkGJ7l1++U85vN5Xx4bT4fvbTA7OVMSIo1loS4GEkvjDK+ociy02Xs5q8uzGT7OOu6dlS00NHnCvmAY01RJttONuNye/x6Xq01G/bXsbow84Jp6mLycgbrb6PrtdrUoEtr/RbQMuy29iHfJgG+V42bgT9qrfu01uXAcWClUmoKYNdab9XGK8xvgVuGPOYp79+fBa5WkbDtIELejlO++VyREXRNTUsgPsYSkrO6tpcbbfnH2uzBYlFcvyCXt4420tUXXVfZzuflfaf55j8Psn5BLv/fu+eH7e6sUmowbUVEj7KqVuy2WAq8O/LRbnVhBk2d/ZwYR/Oj1w81EB9r4dLZWQFc2eStmZVFR6+LA7XtFz54HI43dHKyqYvrZSByUDhSfKng0ZWVYPZO14iUUt9SSlUBd+Hd6QLygKohh1V7b8vz/n347Wc9RmvtAtoAmXYnAm5HRQtJ8THMzU0xeyl+EWNRzMhMDLmgy+3RlFa0jKmea6gbinPpc3l480hjgFYWPnZUtPCZP+1m6Yx0fnTnYmJCNLVorBx2m6QXRpmySieLZ6SHbFpcsA3WdY0xxVBrzRuH61lTlBnyDSR8s8g2n/BvXZevudJ180Ovc2MkitYBySEZdGmtv6y1ng48A3zSe/NIr6Z6lNtHe8w5lFL3KaV2KKV2NDbKBzExOSXlLSydmR7yw2THw9fBMJQcrmuno9fFynEGXcvzM8hKjo/6QcknGjv52G93kJeWwC8/tBxbXMyFHxTiHHabpBdGkc4+F0frO6J6PtdwMzISybWPva7rRGMXp5q7Q7JV/HDZKVbmOFLY6ue6rlcO1LF0RtpgMCACK8fX9CjKZnWF+ifC3wPv9f69Gpg+5L5pQK339mkj3H7WY5RSsUAqw9IZfbTWj2utl2utl2dny3wGMXFtPQMcqe+ImNRCHyPo6sbjCZ1uQ9u9Q0BXjbGJhk+MRXHt/Fw2HW6gd8AdiKWFvMaOPu59ooQYpXjywyvISIqMOoZo7YoVrfZWO/FoqecayqjrymDbyZYx/X/gayq0LkRbxQ93SVEmpRUt9Ln889pd1dLNgdp2GYgcRInxsaTYYqMuKyHkgi6l1Owh394EHPb+/UXgTm9HwgKMhhklWuvTQIdSarW3XutDwN+GPOYe799vBzZqeScWAbarshWtYXkEzOcaqiAriX6Xh9q2HrOXMqikvIVp6QlMTUsY92NvKM6lq9/N28cC0344lHX3u/joU6U0dvTx63tXMDOCamEGu2L1SL1eNPA10VgsO11nWV2YSVNn35g6zr5xuIF5U+zkTeB11AxrZ2XRO+AZ/G8/WRsOGKmFEnQFV05K9NXfmt0y/g/AVmCOUqpaKfVR4DtKqf1Kqb3AdcBnALTWB4A/AweBV4BPaK19lzkeAH6F0VzjBPCy9/ZfA5lKqePA54GHg/OTiWhWWt5CrEWxZHpkBV2+tvEVTd0mr8SgtaakomXcqYU+lxRlkpoQF3Uphi63h0/9voz9NW088oGlEfdhdbBWIMrSVqJVWaWTwqwk6Tg3zKox1nU5u/vZeao1ZAcij2RlQQYWBVv8NK/r1QP1zM1NIT8rci4+hQOH3UZDCM7+DCRTKya11h8Y4eZfj3L8t4BvjXD7DqB4hNt7gTsms0YhxmtHRSvFeakkxId/fcxQvrbx5U2dIdHh6nhDJy1d/aweZ2qhT1yMhWvmOXjtYB39Lg/xsSG38e93Wmu++uIB3jjcwDduKeaaCCwa9wVddW29XOSIjEY2YmRaa3ZXObn8IvNfj0JNfmYiDruVbSdbuGvVzPMe96+jjbg9OuRbxQ+VmhDHwmlpbDnRzOcnea7Gjj5KT7Xw6XWzL3yw8CuH3UZpxfiHeIezyP+UIUQQ9bnc7K52siLCUgvBqJVJiIuhPER2urZ753NNdKcLjEHJ7b2ucQ8SDVeP/esEz2yv5P4rivjg6vN/EAtnuVHaFSsaVbf20NTZJ0ORRzDWeV2vH2ogKzmei6elBW9xfrCmKJPdVc5Jj/14/VA9WhvvBSK4cuxWGtr7oqr+VoIuIfxof00b/S4PyyOsiQYYb+L5IdTBsKS8hZwUKzMzEyd8jstmZ5EUHxMVg5L/WlbD/71yhJsunspD188xezkB4+uKFW1pK9GorMoJIJ0Lz2N1YSYNHX3nHfUx4PbwryMNXDUnJ+za7a8tysLl0ZSUT26n5JX9dczISIyY8S7hxJFio9/twdk9YPZSgkaCLiH8qKTcGIq8fGZkXnktyAqNWV1aa7aXN7OqMHNSg3xtcTFcNTeH1w7W4Q6hroz+tuV4E194dg+rCzP43h2Lwu4D1njY4mJITYijrk12uiJdWWUrtjiLfGA+D9/8wm0nRw5MdlS00t7rCotW8cMtm5lOfIyFLZOY19XeO8CWE02sL84N24Hw4Swa628l6BLCj3ZUtFCUnURmstXspQREQVYSVS3duNweU9dR2dJNfXvfpFILfW4onkJTZ3/E5pYfqevg47/bSX5mEr/44HKssZFVaziSXLtN0gujQFmlk0V5aRE1D9GfCrKSyEmxnjd9+o1D9cTHWLgsBGp0xyshPoalM9PYfHziqeGbDjcw4NZcvyD8gs5I4PDN6oqitvHySiWEn3g8mh2nWiNuPtdQ+ZlJuDya6lZz28b76rlW+SHounJONtZYC69EYIphXVsv9z5RQkJ8DE9+ZCWpCXFmLykocuxW6iW9MKL1udwcrG2X+VyjGKzrKh+5rmvj4QZWF2WSZDW1p9qErSnK4uDpdlq7+if0+A0H6shOsUZcp+FwkZMSffW3EnQJ4SfHGztp6xmIyHounzMdDM1NMdx+soWMpHhm5yRP+lxJ1lguvyibV/bXhdTg58nq6B3g3idKaO8Z4IkPrwibGTz+4LDbqJf0woh2sLadfrdHgq4LWFWYQX17HxXNZzdAOtnYycmmrrBqFT/c2llG59qtE2iE1DvgZtPhRq6b74jodOtQNlh/K0GXEGK8fAW9kdi50CdUgq6SimZW5Kf7LQ//huJc6tp72VPt9Mv5zDbg9vDgM7s41tDJo3cvY8HUVLOXFFS5dhuNnX0RXacX7XyDcaVz4ehWn2de18bDDQCsC+Oga9G0NJLiYyZU1/XW0UZ6BtzStdBEvvrbaGp6JEGXEH6yo8LopjcjY+Ld9EJdRlI8KbZYUzsY1jp7qGrpYeUE53ON5Op5DuJiVESkGGqtefi5fbx9rIlv37aQKy7KNntJQeewW3F7NM1d0fNmHm3KqpxMTbUNFuOLkRVmJZGdYmX7sKDr9UP1zHGkMD2M36/iYiysLMhgywTqujYcqMduix0MSoU5HHarpBcKIcavtMKo54rkLkhKKQqykkzd6SrxYz2XT2pCHGuKsnh5f13Yzwz54evHeG5XNZ+5ejbvWz7d7OWYIsfXFatNgq5ItbuqlcWSWnhBvrqubSdbBl/b2noGKK1oDauByOezpiiLk01dnG4be53xgNvD64fquWaegzhpwmIqh90mjTSEEONT6+yhxtnD8ghOLfQxO+jaXt5CijWWeVPsfj3vDcW5VLZ0c/B0u1/PG0x/Kq3kJ28c445l0/jsNbPNXo5pZEByZGvs6KOqpUcaIIzRqoIM6tp7OeWt6/rX0UbcHh2WreKHW+Ot6xrPbldJeQttPQNcL6mFpstJsUlNlxBifHztxiO5c6FPfmYSNc4eegfcpjx/SXkzy/PTifFz8fO18x1YFGwI0xTDN4808KUX9nPZ7Cz+97aFEb3jeiHROP8lmuz2DUWWna4xGV7X9cahejKS4lkcAUOl5+XaSU+MY8uJsQddr+yvwxZn4fLZ0Zd6HWocdisNHX0R1cRqNBJ0CeEHOypaSbbGRsWQzsLsJLSGqpbuCx/sZ40dfZxo7GJVAPLwM5OtrCzI4OUwDLr217TxiWd2MceRwqN3LY36lJms5HgsCulgGKHKKluJtSiK86KrQcxEFWUnkZVsZXt5Cy63hzePNHLVnBy/X7gyg8WiuKQoky0nmsaUGu7xaF49WMeVF+WQEB/5MwtDncNuw+XRtHRPrO1/uInud2Yh/KS0ooUlM6JjSGd+pnkdDH07iv4YijySG4qncKyhk+MNnQE5fyB097v4+O92kpYYzxMfXkGKLTpmcY0mNsZCVrI1qmoFoklZpZP5U+3Y4uRD81gopVhVmMG2k83sPNVKW89ARNRz+VxSlMXptt5z2uKPZHe1k/r2Pq4vDv/UykiQk+IbkBwdF8gi/xOiEAHW1jPAkfqOqEgtBMg3sW18SXkLCXExLAzQFe7rFxg5/q/sPx2Q8wfCIxuPU+Ps4YfvXyyd3IZw2G2SXjhB2042c8rEDqWjcXs0e6udEZEaF0yrCzM53dbLE5sriItRXDY7y+wl+c3aIiPzYfPxC7eO33CgjliLYt1cCbpCga/pUbS0jZegS4hJ2nWqFa2jo54LjE5/mUnxprSN33aymWUz0wOWPpebamPpjLSwSTE80djJL98+yW1L8wK2+xeuHHYrdZJeOG5uj+bfn9rBh58spc9lTt3maI41dNDV75Z6rnG6pNB4fXjlQB2rCjIjake8ICuJKak2tl6grktrzYb9dVxSlElqQuT8/OHMEWUDkiXoEmKSSitaiLWoqLrymm9CB0Nndz9H6jsCHlysL87lQG07lWNIVTGT1pqvvXgAW2wMX7xhntnLCTkOuy1qrp7604nGTjr6XJxs7OLRTSfMXs45BociS+fCcSnKTiYrOR4golILwUif9NV1jdaQ4Wh9JxXN3TIQOYRkD6YXRsdrtd+CLqVUllLqVqXU9UopSbQWUWNHRSvFealRVZSbnxn8oGtHhbGjGOig64biKYCRhhLKXt5fx9vHmviP6y4afOMSZzjsNlq6+kNytyaU+ToDLpuZzqNvHud4Q4e5CxqmrLKV9MQ4ZmaG71BfMyilWOUdKH91BKbWrS3KorV7gMN15//3+sr+OpQyOtWK0GCNjSEjKV5qus5HKfWAUmq7UipjyG3LgEPAs8BLwBalVJL/lilEaOpzudld7WRFFMznGqowO4n69j66+11Be87t5c3Ex1gCvqM4PSORBVPtvBzCdV1dfS6+8Y+DzJti5+7VM81eTkg6k7YSHVdQ/WV3lZMUWyw/v3sZSdZYHn5uX0i1cy6rNOq5onkkwkR97LIC/uPai5gRgQHr4LyuE+ev63rlQB3LZqSTkyK1r6EkJyV6mh5NZKfr/YDWWrcMue17QDrwBEbQtQK4f/LLEyK07atuo9/liZp6Lh9fB8OKpuCl4JWUt7B4elpQOpbdUJzLrkpnyNYE/XTjcU639fKNmxdERcfMiXAMFmiH5n/DULWnyghqslOsfPld89hxqpU/lFaavSwA2nsHON7YyZIZ0XWRy1+WzEjnU1dH5tD0KakJFGYlnXdeV2VzN4dOt0tqYQgyUsGj43V6Iu/Ws4G9vm+UUlnAFcCvtdYf01q/BygF/s0/SxQidJVWtAJGKk40yc8yrpQGK8Wws8/F/tr2oDWLWB/CKYbHGzr41dsnuX3ZNJZHWbA/HoMDkqPkCqo/9PS7OVzXwcXT0gC4fdk0LinM5DsvHQ6J9J+9VW1oLUORxcguKcpk+8lmBtyec+7zvZb7OtSK0GHsdJn/+hIMEwm6MoGGId+v9X59YchtbwOS8yIiXmlFC0XZSWQmR1dNzeBOV5A6GO481Yrbo1lVGJwgY1ZOMrNykkMuxVBrzVdfPEBCfAwP3zDX7OWENF/QFaq7laFof20bbo8eTOFVSvG/ty2kz+3hf/5+wNzFYdRzKQUXR1HTIjF2a2dl0dXvZm912zn3bThQx/wpdqZnRF5qZbhz2G00dvThDqE05kCZSNDVAgwd8HAF4AG2DLlNA5I0KyKax6PZUdESla26k6yxOOzWoO10lZQ3E2NRLA1iWtENxbmUlLfQ3Bk6OyX/3Heazceb+cL1c8iKskB/vNIT44iPscisrnHY422iMTSoKchK4jNXz+alfXW8drDenIV5lVU5mZWdjD2C2p0L/1ld6K3rGjavq6Gjl52VrbLLFaIcdiseDc1dofNeGygTCboOAe9RSmUqpdIwarxKtdbtQ47JB0IvL0cIPzrW0El7r4vlM6Mv6ILgdjAsKW+hOC+VJGtsUJ4PjNbxHo3pHzR9Or3NMxZMtXPXKkkkuBClFDl2qzTSGIeyKid5aQnndMP898sKmeNI4St/209nX/Ca5wyltaassjWqRnOI8clIimf+FPs5dV2vHaxHa6SeK0QNDkiOgtfqiQRdPwamANVAFZALPOq709su/lJgjz8WKESoKq0weslEWxMNn8LsJCqCEHT1DrjZU9XG6iDvKM6fYmdGRmLIDEr+6RvHqG/v4+s3FxNjkc5tY+Gw2yS9cBz2VDlZPEK9VHyshf+9bSF17b18f8OR4C8MqGzpprV7QJpoiFGtKcpkZ2UrvQNnRkW8sr+O/MxELnIkm7gycT5n6m8j/7V63EGX1vpFjM6EB4AjwH9qrZ8ecsg1GKmFG/yyQiFCVGlFCzkpVqZnJJi9FFPkZybR3NVPW89AQJ+nrNJJv9sT9DROpRQ3FOey5URTwH/GCzlW38Gv3ynnfcunRV3TlsnItdskvXCMmjr7qG7tYbG3icZwy2am88HVM3lqa8XgLK9gGhyKLE00xCjWzsqi3+Vhh7fJVVvPAFtPNHN9ca6MGQhRvvEe0dD0aEK9hrXWj2utl3v//HDYfRu01ula68f9s0QRLVxuD1qHTyHljopWVhRkRO0LeX6Wr218YHe7tpc3oxSmdOq7vjiXAbfmjUPmpRhqrfnK3w6QGB/Df62X5hnjIemFY7fbG9SMtNPl84Xr5+BIsfHwc3tH7BAXSGWVrSTGx3CRIyWozyvCy4qCDGItanBe18bD9bg8mvVSzxWyspKtKCU7XUIEzYDbw6Xf3cQjG4+bvZQxqXH2UOPsYUUU7zoUZgWng2FJeQvzcu2kJgS/eH7xtDRy7TZTUwz/vvc0W08284X1c6OuS+ZkOew2OvtcptUhhZM91U5iLIriqannPSbFFsf/3LyAw3Ud/Ort8iCuzqg3u3hamqTWilElW2O5eHoam711XRv21+OwWwfHIIjQExdjITPJGhWzuiYcdCml3qOU+qNSao9S6viQ2+cppR5SSuX5Z4kiGhyobaeuvZdfvHUSZ3e/2cu5oB3eeq5onpM0PSMRpeBkY+CCrn6Xh12VraZ1iLRYFOuLc3nraCNdJnxw7+xz8c1/HKQ4z86/rZwR9OcPd7lRVCswWburnMxxpJAQP/rw8esX5HL9Agc/ev0op4I0MqJ3wM3B2vZRd+GE8FlTlMm+aicN7b28ebSB6xfkYpFgPaQZs7oiPyth3EGXMjwF/BW4AygCCoYc0gr8L3C3PxYookNpuRHEdPa5eGJzhbmLGYPSihaSrbHMm2I3eymmscXFkJeWENCdrn01TnoHPKwysS3/+uJc+lwe3jzSGPTn/vHrR2no6OMb0jxjQnIGawUk6BqNx6PZU+Uc8/yr/7mpmLgYC19+YX9QUsIP1Lbh8miWSOdCMQZrirLwaPjehiP0DnikVXwYcNhlp+t8HgQ+CDwBZADfH3qn1roO2Ay8e9KrE1GjpKKFGRmJXDffwROby+noNbdxwYXsqGhl6cz0qP8gXJAV2A6G273BuJmz0FbkZ5CZFB/0QclH6jr4zeYK7lwxXTq2TVA0dcWajPLmLtp7XWMOanJTbfzX+jm8c7yJF8pqArs4zjTRkJ0uMRZLZqRhjbXwl53VpCXGReUszXDjsNtkp+s8PorRDv7ftdZtGIOQhzvG2btfQpyXb8jwivwMPrVuNu29Ln679ZTZyzqvtu4BjtR3RHU9l09+ZhInm7oCdrW7pLyFWTnJptYyxVgU1y1wsOlww1ltiAPJaJ6xn2RrLA9J84wJOxN0Rf6b+WT4hiKPJ6i5a9VMls5I4xv/OEhLV2BTwssqnUxLTyAnxRbQ5xGRwRYXMzjK5eq5DuJipH1BqMux22jq7MMV5AY9wTaRf4lzgE169E9ZDUD2xJYkos2Jxk5auwdYWZDOwmmpXDUnm1+9fdKUGpqx2FnZgtbRXc/lU5CVREevKyAfulxuo+1vKFylXF88ha5+N28fawrK8724p5bt5S08tH4OGUnxQXnOSJRsjSXZGis7XRewu8pJUnwMRdljn2NksSi+fdsiOnpdfPOfBwO4OqNzoez2ivG4pCgTkIHI4cJht6I1NHWGfk3/ZEwk6HJhzOEaTR7QOYFziyhUMmzI8Keunk1r9wDPbA/N3a7SilbiYhSLpb6AggB2MDx0uoPOPpep9Vw+lxRmYrfF8koQuhh29A7wrX8eYtG0VO5cIc0zJivHbpWg6wJ2VzlZNIHOgHNyU7j/iiKe31XDOwG6IFHf3kttW6+83opxef+K6Xz2mtlccZFc/w8HjpToSAWfSNB1ELhSnWc4kVLKBqwDyiazMBE9SstbyEqOH/wAv3RGOpfOyuLxt8qDls41HjsqWijOS71gl69o4JvVFYgOhtvLjZa/obDTFR9r4Zr5Dl4/VB/w+UQ/fv0YjZ3SPMNfcqOkVmCiegfcHDrdPuYmGsN9ct0sCrKS+NIL++jp9//rtQxFFhORlWzls9dcRHyspBaGg2ipv53Iv8bfAXOBHyqlznq8UioG+AEwFXhy0qsTUaG0opUV+WcPGf7Uulk0dfbxh5JKE1d2rt4BN3uq2gZ35aLdtPQEYi0qIDtd28uN5ipTUhP8fu6JuKF4Cm09A2z1zn8JhCN1HTyxpYI7V8yY8IdgcTajQDuy38gn4+DpdgbcesI7Sba4GL51azGVLd38ZOMx/y4OKKtqJT7GwoKp0dspVohIN9hptiOyL5BNJOj6BfAq8GmgCvgAgFLqWeAUcD/wotb6GX8tUkSuwSHDw4KYVYWZrCzI4Bf/OkmfK3R2u/bVtNHv9rBcmmgAxlDD6RmJVDR1+/W8Ho+mtKIlJFILfS6bnUVifEzABiVrrfnvv+0nxRbLQ9fPCchzRKMcu5WG9r6gtDYPR74mGpPZSVpTlMUdy6bx+FsnOXS63T8L8yqrdDJ/qh1rrGQWCBGpMpPisShoiPALZOMOurTWbuBG4OtAPHARoIDbgETgGxjzu4S4oNJRWoJ/et1s6tp7+cuO6mAv67xKZSjyOfIzEznp57bxxxo6cXYPhERqoY8tLoar5ubw2sE63B7/f4D/2+5aSspb+K/1c0mX5hl+k2u30e/20Nod2mMozLK7ykmu3TaY3jNRX3rXPNIS4nj4+X1++//D5fawr7pNUguFiHCxMRayko0LZJFsQsmuWmuX1vprQA4wD7gUWAhka62/qrUOzbZzIuSUjDJkeO2sTJbMSOOxN08EvI5mrHZUtDIrJ1k6yg1RkJXMqWb/to331XOtKsj02zn94YbiXJo6+weDb39p7x3gWy8d4uLpabx/+XS/njvaRUutwETtrnL6pUlFelI8X3nPfPZUOfnd1opJnw/gSH0HPQNuaaIhRBRw2G3UR/iA5ElVGGrDEa31Fq31Ae8umBBjVlrect4hw0opPr1uNjXOHl7YFfgBnBdyZp6YpBYOVZCVSHe/mwY/5mJvL29hSqqN6RmhUc/lc9WcHKyxFr93MfzRa8do6uzjGzcvwCLNM/zK4a0VqJOg6xytXf2cau72W/3gTRdP5fKLsvnehiPUOnsmfT5fE42l0i5eiIjnsFsjvumRtHURpmnt6udYQ+eodTtXzslmYV4qP3vzuOlD8442dNDe62L5zNBJeQsF/u5gqLWmpLyFlQVnN1cJBUnWWC6/KJsNB+rw+CmF6tDpdp7aWsG/rZzBomlpfjmnOMO30xXptQITsbvaCeC3nSSlFN+6pRi3d7j3ZHe/yyqdZCXHMy09tC6+CCH8L8dui/jX6QsGXUqpjRP880YwfgARvkqHzecaiVKKT66bxanmbv6+tzZYSxtRaUUrEBotzEOJv2d1lTd10djRF7K/5xuKcznd1sse7wfWydDeD6d2WyxfkOYZAZGd4u2KFeFXUCdiT5UTpWDhtFS/nXN6RiKfv/YiXj/UMOmmM2VVrSyenh5yF1+EEP7nSLHR3NVPvys0ykkCIXYMx1w5wXNLqygxqtKKFuJjLCy6wBv+tfMczM1N4ZGNx7np4jzTZhftqGjBYbfKVddhpqYmEB9rodxPzTRKvM1VQq2ey+fquQ5iLYpX9texZJJpTy+U1VBa0cp337uQtESpEwwEa2wMGUnxkl44gt1VTi7KSSHZOpaPAmP3kbUF/G13LV998QBrZ2WRmhA37nO0dQ9wsrGL9y6d5te1CSFCky8VvLGzj7y0yPycdcGdLq21ZYJ/pL+rGFVJRSsXT0/FFjf6PxWLxdjtOtHYxcv7TwdpdecqLW9heX7opbyZzWJRzMxI9GvQlZkUT1F2kl/O52+piXGsmZXFy/vrJpU+1dYzwP++dIjF09O4Y5k0zwgkRxSkrYyX1po9fmqiMVxsjIXv3LaI5s4+vvvK4Qmdw5f6uESaaAgRFQZndUXwa7XUdAlTdPe7OFAz9iHDNxRPoSg7iUc2HvdbLc141Dh7qG3rZaW0ih9RQVYSFX4KuraHaD3XUDcU51LZ0s2h0x0TPscPXztKc1c/37ylWJpnBFg0FGiPV2VLN63dAwEbwr1wWiofWVvA77dXTqjbZ1llK0rBIgm6hIgKOSm++tvIfa2WoEuYoqzSicujWTHGup0Y727X4boOXjtUH+DVnWvH4Hwu6aI1koKsJE41d096Pk91azc1zp6QGoo8kuvmO7AoeGWCO68Ha9v57dYK7l41k+I8/9XTiJE5UmySXjjMbu9Q5EC2Y//ctReRl5bAF5/fN+4h92WVTuY4/J/6KIQITYNNjyK4bfykgi6l1DSl1Cql1OUj/fHXIkXkKSlvQSlYNnPsQcx7Fk1lZmYiP914zK8zocai1DtPbG7uufPEhBF09bs9k24TXTI4LDs067l8MpOtrCzImFCjAI/HaJ6RlhjPf14nzTOCwZFqo6mzz/QOqKFkd5WThLgYLnIkB+w5kqyxfPOWYo43dPLzN0+O+XFaa3ZXOWUoshBRJDMpnhiLkvTC4ZRS1ymlDgCngC3ApvP8EWJEpRUtzMu1Y7eNvcA6NsbCJ66cxf6adjYdaQjg6s5VWt563nli4kzb+Ml2MNx+sgW7LZY5uSn+WFZArV+Qy7GGTo43dI7rcc+X1bDjVCsP3zCX1MTxNxgQ4+ewW9Eamjr7zV5KyNhd5WRhXiqxMYFNeLlqbg7vuXgqP9t0fMz/r5Q3ddHWM8CS6ZJZIES0sFgUOSmRnQo+7ldbpdQq4B9AGvAIoIC3gF8Ch73f/x34ut9WKSLKgNtDWaVzQi3Bb12aR15aAj9543jQdrvaugc4Ut/BSkktPC9f2/jJNtMoqTDqucIhuF1fPAUYX4phW88A337pEEtnpHG7dGULGoe3VkBSDA39Lg8HattZHKSdpK/cOB9bnIUvPb9vTDW5vqHIwVqfECI05NhtstM1zJeAXmCF1voz3ts2aa3vB4qBbwDXAM/6Z4ki0uyvaaNnwD3mJhpDxcVYePCqInZXOXnneFMAVneunZW+eq7QrjMyU06KlcT4mEkFXQ3tvZQ3dYXsfK7hclNtLJmRxisHxp5i+INXj9Da3c/Xb5bmGcGUm2oEXZH8Zj4eh+va6Xd5uDhIw7izU6x8+d3zKKlo4c87qi54fFlVKynWWGZlBy71UQgRehwpVmmkMcwlwIta66GTai0A2vBV4BDwP35Yn4hAg0ORCya2c3T7smlMSbXx0zeO+3NZ51VS3kpcjAraB5RwpJQiP3NyHQy3h0k911A3FOeyv6adqpbuCx67v6aN3207xQdXS/OMYPO1Ipa28YbBJhpB3El63/LprCrI4H9fOnTBQvmySicXT0+TCxNCRJkcu5V6aaRxllSgcsj3/cDwgTqbAWmkIUZUUt5KfmbiYHvQ8bLGxvDxywspqWhh28lmP6/uXDsqWijOSyUhXkbPjaYgK2lSO10l5S0kxsdQPDV8mpWsX+BLMRx9t8vXPCM9MZ7PS/OMoMtMshJjUZJe6LW7yklWspWpqRN7DZ4IpRT/e9tCegc8fP3vB897XE+/m8N1HdJEQ4go5Eix4eweGHe303AxkaCrAUgf9n3RsGPigMgcJy0mxePR7DjVMqHUwqHuXDmDrGQrP914zE8rG1nvgJu91W0yn2sMCrKSqGrtYWCCHeJKyltYNjM94IX9/jQjM5H5U+wXHNr97K5qdlU6+eK75pGaIM0zgi0mCgq0x2O3dyhysGfhFWUn88l1s/jH3tNsPDzy6I99NW24PVqCLiGi0GDb+Ah9rZ7Ip5ujnB1kbQOuVUpdBKCUygXeC1zw07BS6jdKqQal1P4ht31PKXVYKbVXKfWCUiptyH1fVEodV0odUUpdP+T2ZUqpfd77fqK87yRKKatS6k/e27crpfIn8PMKPzre2Imze2DM87nOxxZn7HZtPt7MzlOtflrdufbVtNHv9kg91xjkZyXh9miqW8ffNr6lq58j9R2sLgyf1EKfG4pz2VXppK5t5F2Utu4BvvPyYZbPTOe2JXlBXp3wifQC7bFq6xngZGMXi6ebk+J6/xVFzM5J5r//eoCuPtc595dVGq/nks4tRPQZTAWP0BTDiQRdrwBXKKV8n0J/jLGrVaaUKsXoYJgN/GgM53oSWD/stteAYq31IowA74sASqn5wJ3AAu9jHlVK+fK9HgPuA2Z7//jO+VGgVWs9C/gh8N3x/KDC/wbnMPkhiLlr9QwykuIDutvlW+/yccwTi1YFWYkAlDeNr4U6nKnzC5cmGkPdsDAXgA3naajx/VeP4JTmGaZzpFgl6AL2VjsBWGxSO/b4WAvfvm0hNc4efvDa0XPuL6t0MjMzkcxkqwmrEwHR0wqeyEwXE/7l2+mK1KyEiQRdv8Co1xoA0FpvBu4AyjG6F54GHtBa//ZCJ9JavwW0DLvtVa217/LXNsDXV/lm4I9a6z6tdTlwHFiplJoC2LXWW7XRQ/y3wC1DHvOU9+/PAlerYOdTiLOUVrSQnWJlZmbipM+VGB/LRy8t4M0jjYMfJPxtR0ULs3OSSU+KD8j5I0lBltFprLzpwk0lhispb8Eaa2HRtPBrMDErJ4VZOckj1nXtq27j6e2n+NAl+cwPo1q1SJSbaovYN/Lx2O1tx77IpJ0uMDrB3rVqBk9sLj/ntbusqpUl09NMWZcIAGcV/Ohi+Od/mL0SEQbOBF2ReYFs3EGX1rpda71da90x5LYXtNbFWusErfU8rfXjflrfR4CXvX/PA4b2mq323pbn/fvw2896jDeQawPCL38pgpSWt7AyP8NvtQQfumQmqQlx/HSj/zsZGvVnrZJaOEbpiXHYbbET6mC4vbyZJTPSsMaGZ7OSG4pz2V7eTHPnmQ/1Ho/mv/+2n8wkK5+79iITVyfAeDNv6xmgdyC6r7jvqXZSlJ00rsH0gfDQ+rlkJVt5+Ll9uLx1oKfbeqhv72PJDMksiAhaw4ufgr42KHsa2msv/BgR1dIT44iLURF7gcwvFetKqZuUUj9SSv1YKXWbn875ZcAFPOO7aYTD9Ci3j/aYkZ7vPqXUDqXUjsbGxvEuV4xBdWs3tW29rPDjkOEUWxwfXpvPawfrOXS63W/nBTja0EFHr8uv641kSqkJdTBs7x3gYG17WLWKH+76Bbl4NLx28ExzgGd3VrO7ysmX3jVXmmeEgJwUI10tUq+gjoXW2ttEw/zXtNSEOP7npgUcPN3ObzaXA2eGIksTjQix67dwchOs/QxoN2x7zOwViRCnlCInxRax4z3GFHQppd6jlHpLKXXFCPc9AbwAfBr4FPAXpdRzk1mUUuoe4EbgLm/KIBg7WNOHHDYNqPXePm2E2896jFIqFqPd/VnpjD5a68e11su11suzs7Mns3xxHmfmc/l35+jDawpItsbyiJ93u0q99VyT7bQYTSYSdO081YpHw6owrOfyWTDVzvSMBF72phg6u/v5ziuHWZGfzq3SPCMknBmQHJlXUMeixtlDU2e/aU00hltfnMs18xz84LWjVLV0U1bZSnyshbm5koob9pxVsOHLUHA5XP01WHAr7HgCetvMXpkIcZE8q2usO103AUuB7UNvVErdCNwDdAPfBP4LOAncopT6wEQWpJRa7z3PTVrrocUhLwJ3ejsSFmA0zCjRWp8GOpRSq731Wh8C/jbkMfd4/347sHFIECeCrKS8lRRrrN/fUFMT47hnzUxe2n+a4w0dF37AGJVWtJJrtzEtXaYfjFV+VhK1bT3jSuHafrKFWItiaRinFCmluKF4CltONNHWM8D3Xz1CW88AX7+5OOhtucXIIr1WYCwGhyKHwE4XGP/ffP3mBcQoxZf/up9dlU4W5qUSHxs+YyPECLSGv38GtAdu+ilYLLDm09DfYQReQozCkWKL+pbxK4GtWuvh71YfwUjX+7DW+ita6+8BlwG9wF0XOqlS6g/AVmCOUqpaKfVR4BEgBXhNKbVbKfVzAK31AeDPwEGMDoqf0Fr7Ptk9APwKo7nGCc7Ugf0ayFRKHQc+Dzw8xp9XBEBpRQvL8tOJCUAHt49eWkhCXIxfd7t2VLSwPD9dPjSPQ0FWElpDZcvYm2mUlDezaFr4D59eX5zLgFvzo9eP8sz2Su65JJ95U+SKfahwpEjQtbvSaewkTUkxeymDpqYl8IXr5/DW0UZ2npImGhGh7Gk48QZc+z+Qnm/cNnUxFF5ppBi6IvMDtfAPhz1yO82ONejKxQhmhrsccAKD6YRa6zrgn8CSC51Ua/0BrfUUrXWc1nqa1vrXWutZWuvpWuvF3j/3Dzn+W1rrIq31HK31y0Nu3+Ft5FGktf6kbzdLa92rtb7De86VWuuTY/x5hZ+1dPVzvKEzYKl6GUnx3L16Ji/uqR13ettIztSfhW/KmxkKspIAxvzfoKffO3w6jOu5fBZPSyPXbuOJzRVkJVv57LWzzV6SGMKeEIstzhKxb+ZjsafaSfFUO3EhNoD8g5fkc7E32JImGmGurQY2fAnyL4PlHz37vrWfgc462Ptnc9YmwkKO3UZ7r4ue/shrejTWV950htVCKaVmABnAOyOk7JUjXQLFEMGYw/SxywqIi7Hw6KbJ73btqDAGdC6XJhrjkj/OoGtXZSsuj2ZVYfgHtxaL4voFDgC+/K55pneHE2dTSuGwR2/b+AG3h301bSGTWjhUjEXx/dsXcfXcHC6dlWX2csRE+dIKPa4zaYVDFV4FuQthy0/A4zFnjSLk+VLBI3FA8liDrg7OblYBsMz7tew8j4m835aYsNLyFuIDPIcpJ8XGB1bO4IWyGqrGkd42ktKKloDUn0U6uy2OrOT4MbeN317egkXBsggZPv3AlbP41q3F3Lx4qtlLESNwpNioi9KdrqP1HfQOeLg4RJpoDDfbkcKv711BaqJcrAhbu38Px1+Da74GGQXn3q8UrP0sNB2Fo68Ee3UiTDjsvk6zkXeBbKxB1z7g3Uqp5CG33YpRz/XOCMcXYAxJFgIwgpjF0wI/h+n+K4qwKMVj/xopG3bsdlS0snRmYOrPIl1+5tg7GJaUNzN/qj1idoVyU23ctWqm1AGGKEdq5LYivhBfE40lIbjTJSJAey288kWYsQZW/Pv5j5t/C6TOgM0/DtrSRHiJ5KZHYw26nsFIMfyXUurTSqlHMBpl1AGbhh7o7SB4KUbDCyHo6nOxv7adFQWBf7PPTbVxx/Jp/GVHFbXOngmdw9ndz5H6DpnPNUH5Y2wb3+dyU1bpZFUE1HOJ8OBIsVLf3kc0NrHdXekkIyme6RnSjVX4mdbw98+Cux9ufuTctMKhYmJhzSehahtUbj//cSJqRfJMxbEGXb8GNmA0x/gh8CDG4OLPDOkg6HM1RuON1/21SBHeyiqduD06aE0pHriyCK3hFxPc7dp5yqjnkiYaE1OQlURDRx9dfa5Rj9tb3UafyxPQOj8hhnLYbfQMuGnvHf3fZiTaU+3k4mmpsgsr/G/vn+DYBrjmq5BZdOHjl9wNCelGbZcQw6QmxBEfa6GxI0rTC7XWHuDdwAeBn2PM5FqltX52hMOzgB9jzMgSgpKK4NbtTEtP5LalefyhtGpCqUSlFa3ExajBblpifHwdDCuaR9/tKpHh0yLIHN4BydGWYtjRO8Cxhs6QbKIhwlxHHbz8EMy4BFZ+fGyPiU8yUhAP/xMajwZ2fSLsGE2PIrNt/Jj7xmqtPVrrZ7TWn/DO5Np9nuP+qLX+nNa6xm+rFGGttLyFeVPspASxbufBK2fhcnt4/K3xTwnYUdHCwrxUbHHhPTfKLPmZY+tguO1kM3McKWQkxQdjWULgSIncAu3R7KtpQ2tCtomGCFO+tEJXH9z8s9HTCodbeR/EWmHrTwO2PBG+HCmR2Wk2tIZ1iIjT7/JQVtUa9N2M/Kwkbl6cxzPbK2nuHPv/uL0Dxtwo2X2ZuPysRIBROxi63B52nmqV1EIRVL4C7WjrYOhrorFYdu+FP+37Cxx9Ga7+ytjSCodKzobFd8GePxq7ZUIM4bDbqI/ilvFCTMj+2jZ6B8yp2/nEVbPodbn51TvlY37M3uo2+t0eCbomITE+lly7jfKm87ftP1DbTne/W4IuEVSR3BVrNLsrneRnJpKWKLvKwk866uGlL8D0VbDq/omd45JPGDO9tv/cv2sTYS/HbqVBdrqEGJ9SE+t2ZuUk866FU/jtlgqc3f1jeoxviHOkzI0yS35WIuVNnee9f3t5MwCrJOgSQZQQH4PdFht1NV17qp2yyyX8R2v4x+fA1etNK5xgKn5mEcy7CUp/A73t/l2jCGsOu43OPhedF2jIFW4k6BIBVVrRQkFWEtneWopg+9S6WXT1u/nN5ooxHV9a0cLsnGTSpc5oUgqykqloPv9OV0m58e8ix7vzIESwOOzRNSD5dFsP9e19EnQJ/9n/HBz5J6z7/yBr9uTOtfbT0NcGu57yz9pERPANSI60C2QSdImA8Xg0pRWtps67mptr5/oFDp7YXE5778Cox7o9mp2nWlkuqYWTVpCVSEtXP23d5/7OPR5NSXkLK+X3LEyQmxqZBdrns8dbzyXdWIVfdDbAS/8J01bA6gcnf768ZZB/GWx9FFxjy0gRkS8nxZcKHlmv1RJ0iYA51tBJW8+A6fVRn1o3m45eF7/dUjHqcUfrO+jodbEyCEOcI91gB8MR2sYfruugvdfFqkIJukTw5aTYIu7q6WjKqpzExSjmT7WbvRQR7nxphf3dcPOjE08rHG7tZ6GjFvaPNIVIRKPBna4Ia6YhQZcImBJvfZTZzRKK81JZNzeHX79TPurA3h3e9S6fKcHAZBVme2d1jdDBsMRbz2X2vwsRnRx2Kw0dfXg82uylBMXuSifzp9ixxsoIDDFJB56Hw/+Aq74E2Rf577yzroacBbD5J+Dx+O+8Imz5Sg8irZmGBF0iYErLW8hJsTIjI9HspfCpdbNo7R7g6W2nzntMSUUruXYb09ITgriyyDQ9IxGLgpMjBF3by1vIS0tgWrr5/y5E9MlNteHyaJq7Ij+Vye3R7Ktpk3ouMXmdjfDP/zTSAS/5pH/PrRSs/Qw0HoLjr/n33CIspVhjSYiLibhOsxJ0iYDQWlNa0cKKggyUUmYvhyUz0rlsdha/fPskPf3uc+7XWlNaHjrrDXfW2Bjy0hPO2enS2qjnkq6FwixnagUi6818JMcaOujud0s9l5i8l/4D+juNtMKYWP+fv/g2sE+DzT/2/7lF2FFK4bBbqe+QnS4hLqi6tYfTbb0h1SzhU+tm09TZzx9KKs+5r8bZQ117r6lNPyJNfmYSFcNquk40dtHc1S+phcI0vlqBaAi69shQZOEPB16Ag3+DK78IOXMD8xwxccbcrlOboao0MM8hwkqO3RZxr9MSdImA8M27MruJxlArCzJYVZDBL946Qe/A2btdOypaAann8qeCrCTKG7vQ+kztzHap5xImy02NzK5YI9ld5cRui6UgK8nspYihBnrg5Yfh5L/MXsmFdTUZaYVTl8CaTwf2uZZ+CGxpsEV2u4Qx3iPSmh5J0CUCorSihRRbLHNyU8xeylk+ffVs6tv7+MvO6rNuL6loIcUaeusNZwVZSXT0uc6qnSkpbyE7xSofAoVpspKtKBUdO127q9q4eHqapEyHmi0/he2PwW9vMgKa/nNrX0PGS1+AvvbApRUOZU2GFR+DQ/+ApuOBfS4R8nJSrNS395114TbcSdAlAqKkvIXlM9OJsYTWm/2aokyWzkjj52+eoN91pkvSjooWluWH3nrDWX7W2R0MtdZsP9nCSqmbEyaKi7GQlWyN+KCru9/Fkbp2lkhqYWhpq4F3fghz3m3MuSr9FTy2Fiq3mb2ycx38m9Gx8Ir/Asf84Dznqo9DTDxs/Wlwnk+ELIfdSs+Am85Ruk6HGwm6hN81d/ZxorGLFSGYQqaU4lNXz6bG2cMLZcZul7O7n6P1nSGVChkJCryzunwdDKtajLo5aaIhzOawR37Qta+6DY+Wocgh5/WvgccN679t/Ln3H6A98Jv1sOHLMBAi/y67muGf/wFTFhtztIIlOQcW/xvs/gN01AfveUXIcdgjLxVcgi7hd6Xe+qhQaqIx1JUXZbNoWio/23QCl9szpJ5Lmmj407T0BGItanCny1fPtaog08xlCYEjxRZRb+Qj2VPtBKSJRkipKoV9f4Y1n4T0mcZt+ZfCA5th2b2w9RH4xeVQs9PUZQLw8kPQ44RbgpBWONyaT4G7H0p+EdznFSHF12k2kuq6JOgSflda0UJ8rIWF01LNXsqIlFJ88qpZVLZ08+KeWkpPtRAXo+SKsJ/FxliYkZE42MGwpLyFtMQ4Zuckm7wyEe0cqZHXFWu43VVOpmckkJlsNXspAoyhv6/8FyTnwqWfP/s+awq850dw93PQ1wG/uhY2fhNcJs2SO/R32P+sN61wQfCfP7MI5r3HSL3s6wj+84uQMNhptiNyXqsl6BJ+V1rRwuLpaVhjY8xeynldO9/B3NwUHtl4nO0nW1g0LQ1bXOiuN1zlZyVxstG309XCivwMLFI3J0zmSLHR3NV/Vl1npNlT1cbF09LMXobw2fdnYwfrmq8ZDSNGMusaeHArLHo/vPU9+OU6qNsf1GXS3QL/+DzkLoJLPxvc5x5q7Wegtw12/da8NQhT5Uh6oRCj6+pzcaC2PWRTC32UUnxq3WxONnWxu8rJcpnPFRAFWUmcau6m1tlDZUu31HOJkOC7gtrYGTlv5kM1dPRS4+yR1MJQ0dcJr30V8pYZAdVoEtLg1sfgzj9AZz08fiW89X1wB6mZwMv/BT0tcMtjxuwss0xbDjMvha0/A/eAeesQpkm2xpJsjY2orAQJuoRf7apsxe3RIdlEY7gbinOZ5U11WyHzuQIiPyuJngE3/9hbC0g9lwgNDu+srrq2yHkzH2p3pROQeq6Q8c4PobMO1n8HLGP82DX3XfDgNph3I2z8BvzmOmg8Gth1Hv6nsSN3+RcgtziwzzUWaz8D7TWw/zmzVyJMkmO30iA7XUKMrKS8BYuCpTPSzF7KBVksiv9aP5cZGYlhESSGI18Hwz+WVpFsjWXeFJmDJszniMAC7aH2VDuJtSiK80KzrjaqtJ4y5nItfB9MXzm+xyZlwh1Pwu2/gZaT8IvLYMsjRvdDf+tugX98DhwLz605M8vsayFnPmz+MUTQrCYxdsasrsh5nZagS/hVSXkL86faSbGZmJYwDtfOd/DWQ1eRmhAe6w03BdnetvGNXSzPTyc2Rl5yhPkGC7Qj6M18qN1VTuZOSZE61VDw2n+DJcao5Zqo4vfCg9uhaB28+mV48kYjCPOnV74I3c1Gt8LYeP+ee6KUgjWfhoaDcPx1s1cjTOCw22jokJ0uIc7R53Kzu8op867EoCl2G9ZY42VmpewmihCRkRRPXIyiLoLSVnw8Hs1eaaIRGireMQYMr/0spOZN7lwpDrjz90atVf1+eOxSo7ufP3aAjrwMe/8Il/0HTFk0+fP5U/F7wZ5n7HaJqOOwG51mdYTsdErQJfxmf00bfS5PyDfREMFjsShmZiYCSBMNETKUUuSk2CIyvfBkUycdfS6p5zKbxw2vPAyp0425U/6glDE4+MGtRqriP/8DfncLOKsmfs6eVvj7ZyFnAVz2n/5Zpz/FxsPqB6HibagOgfllIqhyUqz0uTy09wSpkUyASdAl/Kak3DtkWIIuMURBVhK2OAsL89LMXooQgxx2a0TNf/EpkyYaoaHsd1C3D679H4hP9O+5U6fBB1+AG39oDFx+bA2UPTOxXa8NX4auxtBKKxxu2T1gTYUtstsVbRy+tvER8lotQZfwm9KKFgqzkshOkWGc4oxPXjWb/3fHYuJj5eVGhI7cVFtEdi/cU+0k2RpLUbYMITdNbxu88Q2YcQksuC0wz6EULP8IPLAZchfC3x6EP9wJHXVjP8fRV2H3M3DZ52Hq4sCs0x+sKbDio3DwRWg+YfZqRBANBl0RkpUgn4KEX3g8mh0VLVLPJc6xcFoq7140xexlCHEWI70w8mq6dlc5WTQtVYaQm+mt7xlNKdZ/2wiOAimjAO75B1z/bTj5Jjy6GvY9e+Fdrx4n/P0zRnfAy78Q2DX6w6r7jblhWx8xeyUiiM40PYqM12oJuoRfHKnvoL3XJa3XhRBhwWG30dHnoqsvMmoFAHoH3Bw+3SGphWZqPgHbfg5L7oKpS4LznBYLXPIg3P8OZBTBcx+Fv9wLXc3nf8yrXzaGL9/8M4gNg+yUFAdc/AEjjbKzwezViCDJSZGdLiHOUVrRAiBNNIQQYSE3NfLaxh+obcPl0RJ0mWnDlyHWBuu+EvznzpoNH9kAV3/VGHT86Co49I9zjzv2OpQ9DZd+FvKWBn2ZE7bmU+Duh5LHzV6JCJKE+BhSbLE0RkjbeAm6hF+UlLfgsFuZnpFg9lJEtHIPgLMSKrcZ6TXbHoOm42avSoQox+AV1Mh4MwdpomG6Exvh6Mtw+X8aOzNmiIk1arTuexNScuFPd8HzHze6FIJRb/b3T0P2XLjiv8xZ40RlzYa574aSX0Jfp9mrEUHiaxsfCWLNXoAIf1prSr31XCrQ+esiOnncRipMWw20V3u/ev/4/t5ZD9pz9uNivgpXfAHWfCZ0O3MJU+R4C7QbIqQrFsCe6jamptoGfzYRRG6XMWA4vQBWP2D2aiC3GD62Ed7+Prz1fSh/C27+qTE3rOM0vP934ZFWONzaz8LhfxjdIUPh9ywCzmG3StAlhE9VSw/17X0y/FZMjMdjtCweGky1VUN77ZmgquM0aPfZj4tLNIZmpuZB0dXGV3vemdtirfD6/8DGb8L+5+Gmn8K05eb8jCLk5KYagUkkdTDcXdXKxbLLZY4dv4HGw/D+Z0InmImNh6u+BBeth78+AE+/17j90s9B3jJz1zZR01fAjDWw9Wew4mNGcw0R0RwpNraXt5i9DL+QoEtMWom3nks6F4oRDfQaH0aG7koN/r0a2k+DZ+Dsx8TawD7VCKAKLvMGU1ON+TS+oMqWduHOYO97Co68bAwR/dU1sPI+uPq/jRbEIqolW2NJio+JmPTC5s4+qlp6uHvVTLOXEn26W+DN/4WCK4z0t1CTtxTu+xe8+W3jtfiKh81e0eSs/Qz84f1w4AVY9D6zVyMCLMduo6GjF6112GdTSdAlJq20vAW7LZY5DvkgK7w8Hji1Gfb+yUhn6Ws/c58l7kwANX31ucGUfRokZviv1fKcG2DmWnjj60YB9uF/wrv/H8xZ75/zi7DlsNsiZujmnmonIPVcpnjzO0atVDBaxE9UnM0Y1BwJZl9n1KRt/jEsvCN0f+fCLxx2KwNuTWv3ABlJ4V0mIEGXmLTSihaW52fIXBgBDYdh7x9h71+MXay4JJh/k5HekjbDCKySso0Wx8Fks8O7v29cFX3xU8ZV0gW3wQ3fheSc4K5FhAyH3UZ9hKQX7q50YlFQnJdq9lKiS8MhKP0VLPswOBaYvZroYLHAmk8bA6FPbIRZV5u9IhFAQwckS9AlolpjRx8nm7q4Y/l0s5cizNJRB/ufgz1/hLq9oGKgaB1c8zWY+y6ITzJ7hWdMXwkffxs2/8gYYHpiI1z3TVhyt1wtjUIOu5Wdla1mL8Mvdle3cZEjhSSrvK0Hjdaw4UtgTYarvmz2aqLLwjtg4zeM3S4JuiJaTopRI9nQ0ce8KSYvZpLk1VlMyg7ffK6CdJNXIoKqr9NI09v7Rzj5ptE1cOoSWP8dKH5vaO8excbDFQ/B/FuM1skvfhL2/Rlu/BFkFpm9OhFERivivrCvFdBas6fKyQ3FuWYvJboc3WBcuFn/HUjKNHs10SU2HlY/CK/9N9SWBW8QtQi6oTtd4U7mdIlJKalowRprYWFemtlLEYHmdsHx1+H5++D7F8EL9xlzsC79PHyixJgLs/qB0A64hsq+CO59CW78IdTuhsfWwNs/MOZ9iajgsNvod3lwdof3f/OK5m7aegakniuYXP3GLlfWRUYXPRF8y+4Fqx02/8TslYgAyvbtdEVA0CU7XWJSSitaWDw9jfhYid8jktZGyuCeP8H+Z41ZWNZUWHg7XHyn0Qgj2PVZ/mSxwPKPwEU3wMtfgDf+x9te/sfh21JZjNngFdSOXtLDuFZgd5WRIint4oOo5BfQcgLuelbalpvFZjdev7f8BFq+AhkFZq9IBIAtLoa0xLiI6DQbxp+WhNk6egc4WNsu87kikbMK3v5/8Ohq+MXlRte/aSvgfb+D/zwKN/0EZq4J74BrKPsUeP/Txp+uRqO9/CtfMtIoRcRy2I0rqOH+Zr6nqo3E+Bgukg6ywdHZCP/6P6OL3uxrzV5NdFt1v1FHvPVnZq9EBJAjxRYR6YWy0yUmbFelE4+W+VwRo8cJh140drVOvWPcNn01vPsHsOBWo417pJv3Hii4HF7/Gmz7GRz6u5F+OPsas1cmAmBwpyvMOxiWVTlZmJdKjHSQDY5N34SBbrj+f81eibBPgYvfD2VPw5UPQ1KW2SsSAZBjt1LfEd4Xx0B2usQklJa3YFGwdKY00Qhbrn44/BL8+R6jTuvFT0HHaaMT16d3w0c3wIqPRkfA5WNLNQKtD79szLZ55r3w3Megq8nslQk/yxnc6QrfoKvP5eZQbbvUcwXL6b2w8ylj0HrWbLNXI8BoH+/qgZJfmr0SESAOu01qukR0K6loYcHUVJKlRXF40RqqS43Bxfufh54WSMw0ipIXvR/ylkr7dDDSJ+9/x0izfPsHRhOR6/8XLv6A/H4ihDU2hvTEuLAekHzodAf9bo8EXcGgNbzyReMi1BUPmb0a4ZM9B+a8y0iDX/vp0BpTIvwiJ8VKY0cf/3979x0fVZX+cfxz0ikJPaH3GkCqCFjpCKjg2rCvrt11Xcuuurrqqquuq/4sa+9YALuAFUQsoBQhoUsv0gkhtISU8/vjDBpCElJm5s5Mvu/Xi9eEmzv3PhMuk3nuec5zCgpsWK8Jq5EuqZCcvHwWbMhUaWE4Kch3CcSTPeDlIa4co/UpcP5EuHk5jPgPNO2lhKKwmHgYcAdc/R3UawcfXQPjRkPGGq8jEz9JSUpgy+7wLVtZsF5NNIJm6Seu9HrAP6CaKjxCyvF/cTcQ57/ldSTBd3A/TL3XdeGNUClJCeQVWDL2H/Q6lEpR0iUVsnDjbg7mFWh9rnCy+EOY9i9IagJn/A9uWQFnvwrth6n71tEkd4LLvoAR/4WN8+CZfm5Rzvw8ryOTSkpJSmBbGI90pW3cTXJiPI1qJXgdSmTLzYYv74TkztDzEq+jkaKa94Vmx8Gsp6re+/JPz8L3j8FLg1yDlwh8/SkRUAoOSrqkgmb7FkXurZGu8PHzG1C7OVwyCXpc6NrtStlFRUGfK+C6n6DNAPjqn/DigIi+u1gVpCTFh/Uv8gUbMunerHZYL+4cFmY9DZnrYfiDEK2S+pB0/F/cv9GSj7yOJHj2Z8D3T0CbgZA6GqY/AK8MhR0rvI7Mr5J9TY+2hXmnWSVdUiFz1mTQukEN6teM9zoUKYtda2HNDOh+YeS0efdKrSZw3ttw9utu3bIXB7o74Af3ex2ZVEDDpAS278khL7/A61DKLXP/Qdbs2KfSwkDL2uzmdXYcBa1P9joaKUn7U10Z+A9PuPl3VcEP/wc5WTD0ATjrZTjrVchYDc+dAD8+BwXh975WnN86zYbxDTLwOOkyxrxijNlmjFlUaNvZxpjFxpgCY0zvIvvfboxZaYxZbowZVmh7L2PMQt/3njS+W37GmHhjzATf9p+MMS2D9uIiWH6BZe66XRyn9bnCx/y3AAPdz/c6kshgDHQe7Ua9elwAM59ya5qt+trryKSckpMSKLCwc1/4zRVI27gbgB5KugJr2r1QkAtD7/c6EilNVJRrpLElHVZ/43U0gZe1CX56HrqdBympbluXM+HaH6HVyfD53+GN0926m2GuQc3IWFPR61verwHDi2xbBJwJfFt4ozEmFTgP6Ox7zjPGmGjft58FrgTa+f4cOublwC5rbVvgceBh/7+Eqmf5lj3syc5TE41wUZAPC9525Qe1m3kdTWSpVgdOfwounQJRMTBujGu7HyF3F6uCcL6DumB9JsZA16a1vA4lcm2cB2nvQL/roG4rr6ORoznmXKiZ4ka7It2Mh93v91NuP3x7YkM4fwKc9iRsmg/P9nc3XsN49C8uJop6NeLCutMseJx0WWu/BTKKbFtqrV1ezO5nAOOttTnW2jXASqCPMaYRkGStnWWttcAbwOhCz3nd9/V7wCCjwvdKm+Obz6WkK0ysng5ZG908LgmMlifANTPh2Cvc3Llf53odkZRRQ1/StSUMF0hO25hJ2wY1SUxQI5yAsNaNFtRMgRNv9joaKYuYeOh7jfu9tznN62gCZ8dK+Hkc9L4M6rQ48vvGQK9L4JofoGFX+PhaGH8B7N0e/Fj9JDkC1uryeqSrPJoAhcdIN/q2NfF9XXT7Yc+x1uYBu4F6xR3cGHOlMWauMWbu9u3he1EGw+y1GTSqlUDTOtW8DkXK4udxUK0udBzpdSSRLTYBBt0F0XGw+COvo5Ey+q0r1p7wKlux1rJgQ6bmcwXSwnfdmoaD/gnxiV5HI2XV648Qlwg/POl1JIEz/X6ISYCTbil9vzot4ZLJbs7XyqnwzHGw5JOghOhvyYnxbAuz9+miwinpKm6EypayvbTnHLnR2hestb2ttb0bNGhQwRAjn7WWOWsyOLZlXXXLCgf7dsKyKa7kIkZNTwIuoRa0GeS6Z6nEMCzUqxlPdJQJuzuoGzIOkLHvoBZFDpSD++Cru6FRd+imubBhpVpt6H0pLP4Atv/idTT+t2m+WwKm33VQM/no+0dFQf/r4aoZUKspTLwIPrgKDmQGPFR/CvdOsxBeSddGoPCElKbAJt/2psVsP+w5xpgYoBZFyhmlfNZn7GfbnhyOVRON8LBwopsA3vMiryOpOjqPgaxf3R1yCXnRUYYGNePDrrxwwcZMAP8nXXk58MkNsOh9/x433PzwBOzZBKc+rI6v4aj/DW60a8pNYT2XqVjT/uWqV/pfX77nJXeCP02Dk//uRnGf7R9WzZ9SfJ1m8wvC998znN5JPgHO83UkbIVrmDHbWrsZ2GOM6eubr3Ux8HGh5xxaxfAs4GvfvC+poNlrXM7aR/O5Qp+1rrSwcQ9I6ex1NFVHh+GuxLAqrRUT5lKS4sOuvHDB+kziY6Lo0NCPZW8F+fDBFfDz6/DZbW5B4Kooc4NLurr8wS26K+GnZjIM/ies/c4lGJFi9QyXKJ14s6usKK/oWBhwB/zpK4ir4Zo/TbnFjeyGuN86ze4Nr/fqwrxuGf8OMAvoYIzZaIy53BgzxhizEegHTDHGfAFgrV0MTASWAJ8D11lr832HugZ4CddcYxXwmW/7y0A9Y8xK4CbgtiC9tIg1Z20GtarF0i65ptehyNFs+hm2LYYeGuUKqoRa0Hawm9elEsOwEI4TtNM2ZtK1SS1io/30a9xamHIzLPnYJRv7trmR8qroq38CBgbf63UkUhm9/giNe8IXd8CBXV5HU3nWuuULkprAsX+q3LGa9IKrvoW+18KcF+G5E2FDaFdnNKwRTd+oJUR9cTss/9zrcCrE6+6FY621jay1sdbaptbal621H/q+jrfWplhrhxXa/wFrbRtrbQdr7WeFts+11nbxfe/6Q6NZ1tpsa+3Z1tq21to+1trVXrzOSDJn7S6ObVmHqCjN5wp589+EmGrQ9SyvI6l6Uke70qRILjHM3g1T7wm7eQHFaZiUwJYwSrpy8wtY9Otu/zbRmP5vmPcqHH8j/OFlaHiMW3+uqt04WDfLzQU6/i9aYiPcRUXDqMdh/06Ydp/X0VTessnw6zzXIj42ofLHi60Gwx+ESyZB/kF4ZagrXcwLoTULD+6HpZPhw2sYMPl4xsfdT52lb8L2pV5HViHhVF4oHtu2J5s1O/apVXw4OLgfFr4HqWdUrARBKqfDqRAd7yY7R6r5b8L3j8M3D3kdSaWlJMWTuT+X7Nz8o+8cApZt3kNOXoH/5nP99Dx8+x+3rMTge1y76f43wI5fYMUX/jlHOCgocC3ik5q4pEvCX+Pu0OdKmPuKW3MtXBXku8SxfnvoNta/x251klvypNv58N2j8OJA2LLIv+coj3073bpi75wP/2kNEy6A5Z+S23oIVx28kfcGfQsn/NW7+CpBSZeU2dy1bnheTTTCwNJPICdLa3N5JSEJ2g5ypVqROlKQNt49znnRrRkTxpJ9a3VtD5N5XX5torHwPfjsb9BhJIx6wiVcAJ1HQ61mbrSrqljwllvbafC9EFfd62jEXwb8w621NvlGyM/zOpqKSRsPO5bDwLsgOsb/x09IgtH/g/Pegb1b4MUB7qZaQZBuRO1aC7OegVdHwn/bunXFNqdBz4vh4k/g1pXEnvUCX9o+/Lo/OjgxBYCSLimz2WsySIiNoktjjZyEvJ/HQZ1WbtFe8UbnMb4Sw9leR+J/25bClnQ3mTsmwTcHJnz9tkBymJQYLlifSb0acZVfK3HFVPjwKmhxPJz18uEf5qJj3SKz634I7xGCssrOcqVVzY5TSXakSUiCUx9y71lzXvQ6mvLLzYZvHnTz0zqdFthzdRwB1/4I7Ye58vFXR8DOVf4/j7WwOR2mPwjPngBPdIMvbndz7068Ba6cAX9dBCP+A61PhuhYYqKjqFcjnu17wuN9ujhKuqTM5qzNoEezOsTF6LIJaTtXwbrv3SiX1lLzTvvhvhLDj7yOxP/SxoOJhuOucWUey6fAmu+8jqrCUnxJV7isAZO2MZPuzWpXbq3EjXPdej0NOsHYd9z8jqJ6XgzxtWBmBC8ye8h3j7rmIcMf1PtmJEod7dZQ/PoByNp01N1DytxXYPeG30t/A61GfThnHIx5wd1ge+4EmPNy5Vvv5+e53xOf3Qb/dww8fyLMeBjia8LQ++HPP8O1M2HgP1xZaDGv1a3VFR4VCcXRp2cpkz3ZuSzdnKXSwnCw4C0wUdBdC3p6KiHJdTGMtIWSCwpcC+a2g6FmA7dAZ1JT+PIfYfs6U5LcwuHh8Ms8KzuXVdv3Vq6JxrZl8NZZruTqwvdLnvcZnwjHXubKlTPWVPx8oS5jNfz4jJvT0qSX19FIIBgDI//rGkZ8frvX0ZRddhZ8919oPcCN+ASLMdDtXLh2lhv9nXITvPmH8ieshRph8N+28Pool0SmpMLpT8EtK+Cyz6H/n6Fem6MeLiUpIWxujhVHSZeUybx1uyiwWp8r5OXnwYK33QfipMZeRyOdx8CezZFVYrj2O7f48zHnuL/HVoPBd7v6+/QJ3sZWQbWqxRIfExUWv8zTN+zG2krM58rcAG+e6daSu+hDSEwpff8+V7lRzR+fqdj5wsGXd7mfx+C7vY5EAqluazjpFncjbMVUr6Mpm1n/c90XB3lUwl2riXufGPFfWD8LnukL6e+WPupVbCOMKdBuKJzzBvxtNZw/wY2k12xQrnA00iVVwpy1GURHGXo0r+11KFKaVdPch3ytzRUaOgyPvC6G6RMgLhE6jvx9W5ez3HyDaf8Ki0U2izLGhM0d1DRfE41uTWuX/8n7drrFUHP2uhGuuq2O/pykRnDMua5b5f6M8p8z1K3+xrXiPvEmSGzodTQSaMf/Beq1hU9vhtwDXkdTur3bYdbTrgtxk57exWEM9LkCrv4e6neAD/4E717i3k8OKbYRxgLoeRFc/DHcugrOfMG9lviKr/OanJjAzn055OaHZ1WFki4pkzlrdtGlcRI14gPQNUf8Z/44qF7fzScS78UnQrshkdPF8OB+91pSzzh8DlBUFAz7t2scMvNp7+KrBHcHNfSTrvnrM2ldvwa1qseW74k5e11J4e4NcP54aNi17M/tfz3k7nfzOiJJQT58cSfUbg59r/M6GgmGmHgY+ZhLEr571OtoSvfdoy4xHHiX15E49dq4UsBBd8OyT92o15d3FmmEkeEaLF35Dfx1MYx4BFqf4hrz+EFKUgLWwo694TnapaRLjionL58FGzO1Pleo27sdln8G3c6DmDivo5FDUke70ccNP3kdSeUt/xQO7nW1/kW16AedTocf/g+yNgc9tMpyI12h/YvcWsuCDZnlLy3My4EJF7oS0LNehRb9y/f85E6uNGj2866TWqRInwhbF7oPkf5YbFbCQ+uToes58P3/wfZfvI6meLvWwdyXoccFUL+d19H8LirajQpfOR1qJrubbIc1wpgFA++Exj0C0vQjnObfFkdJlxxV+sbdHMwrUBONUJc+HgryVFoYaiKpxDB9gmua0aKEpQiG3Av5uTD9/uDG5QeHygttZTt0BdCm3dns2JtTviYaBfnw4dWwerqbuN5xRMVO3v/PsG87pL1TseeHmtxsmP4ANOoOnc/0OhoJtmEPQGx11yAiFP/Pf/MQYODk27yOpHgNu8JV38HtG8rVCKOykhPdzZFtYVCVUBwlXXJUs9e4On6NdIUwa93aXE2PheSOXkcjhUVKieHebbByGhxztisnLE7d1nDcVW4S9eb04MZXSSlJ8ew/mM/enNBdPDVtQyZQjiYa1rqFjxd/AEP+5e6aV1TLE12CMuvp8L6OD5n9giu1HPKvkq9niVw1k2HwP11joIXveh3N4bYucTc3jrvSNbIIVVFR7vdbEP020hUmC9kXpXcaOao5azNom1yTujVUshayNs51q9VrlCs0dR4De7fAhh+9jqTiFr0PNh+OOa/0/U66BarVdi3kQ/EOcgnCYa2uBRsyiYuOomOjMn7QmfEwzHkJ+t/gGghUhjHubvbOlfDLZ5U7ltcO7HLzZdoOCW4bbgktvf7olgj44g53TYSKr+93ycwJN3kdScipVzOeKKORLolQ+QWWeWt3aZQr1M1/w5VKdB7jdSRSnPbDICYhvBdKThsPjbodfSS1Wh045XZY8y388kVwYvOD35Ou0L2DumB9JqmNk4iPiT76zrNfhG8ehO4XuNEcf0gdDbWaw8yn/HM8r3z3GGTvdovNStUVFQ2jHnct2afd53U0zobZrr368TdAdX3uKio6yvDixb35Q8+mXodSIUq6pFTLtmSxJyePPq3qeB2KlCRnLyz6wCVcCUleRyPFiU/0LZQcpiWG25e79r9HG+U6pPdlri3zV3e5OV5hINRHuvLyC1j46+6ylRYu+gA+vRU6jIDTnvTfhPboGOh3rVuvZ8Mc/xwz2DI3wE/PQ7ex0LCL19GI1xp1c2vRzX0FNs7zNhZrYeq9UCMZjrvG21hC2KBOKbSsX8PrMCpESZeUao7mc4W+JR+5jnIqLQxt4VximDbeLZDb9ayy7R8dC0Pugx2/wLzXAhqavxyaK7AlRJOuX7bu5UBu/tGTrlVfwwdXQvO+cNYrLlHypx4XQUJtmPmkf48bLNP/7R4H3OFtHBI6Btzh1mibfCPkezinc9U0WPc9nPy3Sq1lJaFLSZeUas7aXTSulUDTOtW9DkVKMv9NN6rQvK/XkUhp2g/3lRiGWRfDggI30bzNADf5vKw6nOqaL0z/NxzIDFh4/lI9LobEhBi2hWh54aFFkUtNujbOg/EXQoMOMHb84Wup+Ut8TTj2clg6CXau8v/xA2nLQl+DgqugdjOvo5FQkZAEwx+ELekw50VvYigocKNctVtAz0u8iUECTkmXlMhay+y1GWoVH8p2rHClPj0uDMiaGOJH8TULdTHM9zqaslv3g+vyVtbSwkOMcW2ZDzUtCAOH2saHogXrM6ldPZYW9Uq4Abb9F7f4cY36cOH7rplJoPS50o1m/vhM4M4RCFPvgYRabp0hkcJSR7sS8K8fgKxNwT//kg9d0jfwTq2zGcGUdEmJ1u3cz/Y9OSotDGXzx7myr27nex2JlEXqaNi7FdaHUYlh+niIqwkdR5b/uY26Qffz4afnIGON/2Pzs4ZJCSFbXrhgQybdmtbGFHdzZfdGGDcGomLgog9dqVQgJTaEY851SwPs2xnYc/nL6hmwciqceLNr9iJSmDEw4hEoyIXPbw/uufNzXcfClC7QpYwl3BKWlHRJiWavdfO5+mikKzTl58KCd1xnvMQUr6ORsgi3EsPcA7DkE+h0OsRVsMR44J0uGZh6j19DC4TkpPiQLC/cm5PHL9v2FL8o8v4MGHcm5GTBhe8FZYFSwLWPzzvgXTlWeRQUwFf/hFrN3CidSHHqtoYTb3HzpFdMDd5554+DjNUw8C6tGRfh9K8rJZqzJoPa1WNp20ATOkPSiq9g3zY10Agn8TWh3VBY+kl4lBgu/8x9mO92bsWPkdTYrRO15CNY/5PfQguElKQEtu3JpqAgtNYXW7hxN9ZCj6JJV85eeOts2LUWxr7jRhaDpUEHdxNh9gsuOQ9liz9w3TcH3gmxCV5HI6Hs+BugXjv49ObgXNcH98M3D0Ozvu4GqkQ0JV1SojlrM+jdoi5RUZorFJLmj3OtZdsN8ToSKY/Oo30lhrO8juTo0idAYmPXEKMyjr8BajZ0i5CG8ILJDZMSyM23ZOw/6HUohznUROOwka68gzDxYtj0s+tS2PKE4AfW/89ujaMFbwf/3GWVdxC+vg9SukLXc7yORkJdTDyMfNTdyPjuscCfb/bzrqvt4Hs0L7sKUNIlxdq2J5u1O/drfa5QtWeLW3i2+1g3oV3CR7thEFMt9BdK3rfDzYE55my3iGhlxNWAQXfBr3Nh0fv+iS8ADrWND7VmGgvWZ9K8bnXq1vBNsC8ogI+ucS2mT3sCOo3yJrAWx0PjnjDrf6E7cjv3FfcBesg9Kt2Ssml9skvQv3/cNagJlAO73DnaDYMW/QJ3HgkZegeSYs1ZswvQ+lwhK+0dsPkqLQxH4dLFcNH7UJBX/q6FJek2Fhp2dXO7QrQcLdm3QHKozetasCHz91bx1sLnt8Gi99zd8Z4XexeYMW60K2MVLP/UuzhKkr0bZjwMrU6GNoO8jkbCybAHILY6TLkpcKPzPzwB2Vkw6J+BOb6EHCVdUqw5azOoFhtNlya1vA5FirLWrc3VrC/Ub+d1NFIRnce4+XihXGKYNt4lSSmp/jleVDQMfcC1n//xWf8c088a+pKuUOpguGV3Nluysn8vLfz2v64kqd/1cPyNXobmdDrdrS008ymvIznSD0/AgQwYcq9Kt6R8aibD4Lth7XdunUJ/y9oMPz4HXc+Ghl38f3wJSUq6pFiz12TQo3ltYqN1iYSc9T/CzpXQU6NcYav9oRLDEO1iuGOFmyvkr1GuQ1qfDO1PdXMl9m7377H9oEFi6JUXLtiQCfgWRZ7zMky/340aDrkvNBKJ6BiXAG74KbQapWRtglnPuBbcjXt4HY2Eo15/hCa93FzUA7v8e+xv/+Pa0w+4w7/HlZCmT9RyhKzsXJZuyVJpYaiaP86tm5Q62utIpKLiakD7oa4deyiWGKaNBxMFXQOwZszQ+1yr8W/+7f9jV1JsdBT1a8axNYTKC9M2ZhITZei6ezpMudnN/zj9qdCan9TjArf21cwnvY7kd9886MpjB93ldSQSrqKiYNTjrlnMtPv8d9ydq2De6y6pq9vKf8eVkBdC79oSKuat24W1Wp8rJOXscaMjXc50c4MkfB0qMVw30+tIDldQAOkTofUpgVlkt3476H0ZzHsNti31//ErKSUpIbRGutZncm791cR9fBU0Ow7Ofi30mufE1YBj/wTLpsCOlV5HA9uWuRLsPldAnZZeRyPhrFE36HOVa8iycZ5/jjn9Adcl8aRb/XM8CRtKuuQIP63OIDrK0KN5ba9DkaIWfQC5+9VAIxK0GxqaJYbrZ8Hu9f4vLSzs5NsgLhG+DL1RiFBKuvILLPkb5/HPvfdDvbZw/viKL1IdaH2uhOg4mPW015HAtHtdNcCJt3gdiUSCAXe4G1CTb4T8vModa3O6a1LU91pITPFLeBI+lHTJYay1fL5oM31b16V6XIzX4UhR88dB/Q7Q9FivI5HKiqvh5naF2kLJ6eMhtkZg25DXqAcn3worv4KV0wJ3ngpISYoPjfJCa9mUNpVnzYPkxdeFCz9wJXyhqmYydDvPdVb1cr7eulmuk+IJN7rrTKSyEpJg+EOwJR3mvFi5Y037l/t/fPwN/olNwoqSLjnMol+zWLtzP6d3a+x1KFLUtmWwcY5roBEKE+il8jqPhn3bYd0PXkfi5GbD4o+h02kuKQykPle60q8v7wyppDMlKYGd+3LIzS/wJoD8XFj4Hrw4kGYfn0Ue0ewYMx6SGnkTT3n0ux7ysiv/wbSirIWv7nILeh93jTcxSGRKPQPaDoavH3BNWipi7ffuRtMJN0GCOkNXRUq65DCT0jcRG20Y1jkAczmkcuaPg6iYwJZ9SXC1G+rWggmVhZJ/+RxydkO3cwN/rph4GHwvbFviru0QkZKUgLWwfU+QR7sOZLoW5090h/cvx2bv5smEq7mo+nM0a9s1uLFUVIP20GEEzH4RDu4P/vmXfuJuTA24PXTLMCU8GQMjHnEdBz+/vfzPtxam3utuCPS5wv/xSVhQ0iW/KSiwTEnfzEntGlC7epzX4UhheQddR7n2w6FmA6+jEX+Jq+ESr1ApMUyfAImN3GKywZB6hltv7uv7XZOYEJCSFOS28Rlr4LO/w2Op8NU/XTezseN569j3eSzzJG4a2Z2oqDAa2e7/Z7c21oK3gnve/Fz3obZBR+h2fnDPLVVD3dZunuCSj2DF1PI9d/lnsHE2nPJ3iK0WkPAk9Cnpkt/M37CLXzMPcJpKC0PPL5/D/h3Q82KvIxF/6zwmNEoM9+2EFV+6NvFR0cE5pzEw7N/u9X//f8E551Gk+BZIDmjSZa2bezThQniyB8x5yZV0XvUtXDqZ3c0H89jUlRzXqm74VR007wdNesOs/wX3RsLPr0PGKhh8j1s7TCQQjr8B6rWDT2+G3ANle05BvpvLVa8tdL8wsPFJSFPSJb+ZlLaZ+JgoBqeqo07ImT/OjUC0GeR1JOJvv5UYetzFcPEHbl2jYJevNu0FXc92Xe8yNwT33MX4PekKQHlhoflavDrczfE48Sa4cRGc+bxrTw38b/pKdu0/yF2jUjHhNn/TGDfatWsNLJscnHPm7IVvHobm/V01gEigxMTDyEdh11q3yHtZpE+E7Uth4J26IVDFKekSwLUmnpy+mYEdk6kZrzeFkJK1CVZOhe7n6w07EsVVd10Ml3xS+XbElZE2HlK6QMMuwT/3oLvd47R/Bf/cRdStHkdstPHvSNdv87W6wfuXQ06W++D218Uw6J+HNclYu2Mfr/6whrN6NqVLkzCdbN/pNKjTCn540o3qBdqsp92ad0PvU5MhCbzWJ8Mx58L3j8OOFaXvm5cD0/8NjbpDpzOCEp6ELiVdAsBPq3eyY2+OSgtD0YK3wRZA9wu8jkQCpfMYVz7qVYnhjpXw61w45hxvzl+7mVu3ZuFE+NVPC5BWUFSUITkxgS3+SLoyVheZr9Uaxk6A6+a4xYSL6RD54GdLiY2O4tZhHSp/fq9ERUO/69w1tf7HwJ5r7zaX3KWeAU17B/ZcIocMvd/dMJtyU+k3Fua+6tY9HHw3ROkjd1WnK0AA17WwRlw0Azokex2KFFZQAPPfhBYnQL02XkcjgdJ2iLclhukTAOPK/Lxywl+hRgP44h/BGR0pRXJSPNsqWl54aL7W+AvgyZ4w52VIPR2u+g4unQwdhpf44Wvmqh18sXgr157ShmRfmWPY6n4BVKsLM58M7HlmPAz5Ob+PlooEQ81kd82t+RYWvlv8Pjl74NtHoNVJ0HpAcOOTkKSkS8jNL+CzRVsYkppCtbggTaCXsln3g5sb0fMiryORQIqr7uaiLJ0U/BJDa13S1fpkSPJwpDshCQbcAetnuZ+Dh1ISE8pfXvjbfK0Bbr7Wuh9887UWwpjnoNExpT+9wHL/5KU0qV2NP53YuhLRh4i46q419vJPj16CVVE7VrqRhF6X6qaUBF+vP7qmMV/cAQd2Hfn9Wc+4CoZB96jsVQAlXQJ8v3IHmftzVVoYiua/CfFJ0Ol0ryORQOs82ldi+H1wz7v+R8hcFxrrv/W4GBp0cqV4eUFeJ6uQhrXKUV54xHytPTDyMfjrkiPma5XmvXkbWLI5i7+f2pGE2Ai5+XXsFRCTADOfCszxp93r2m+f/PfAHF+kNFFRMOox2L8Tpt13+Pf27XDXfafTXLMgEZR0CTApbRNJCTGc2E7rP4WU7N2w5GPo8gct9FkVtB0CsTWCv1By+gRX2tjptOCetzjRMTDsfje6O/tFz8JITopnT3Ye+w+WMuqYsRo+/dvv87XqtSk0X+vycv2f3ZuTxyNf/ELP5rU57ZiyJWlhoWYD6DbWNWnZu82/x94wx61v1//PrtRLxAuNusFxV8PcV2Bjofmo3z0Guftg4F3exSYhR0lXFZedm8+Xi7cyvEtD4mI8vBx2rXVr1WSs8S6GULPwPcg7oNLCquJQF8OlQeximJfj5pF1HAXxNYNzzqNpO9gtjfDtf2B/hichpCS6+VRHzOuyFtbN/H2+1txXfp+vdcmkUudrleaZ6SvZsTcnPFvEH02/6yH/IMx+wX/HtNYlujWS3fFFvDTgDkhsCJNvdO/dmRtgzouu43CDMG6II36npKuK+2b5dvbm5HlTWrhtGcx4BJ470ZXmTLkZxo327INWyJk/DpI7Q+OeXkciwdJ5jCtVCVaJ4S9fQHYmdDs3OOcrq6H3uzK9GQ97cvqGtVzS9VuJ4cH9bq2dFwfAq6f65mvdDH9dVKb5WqXZkLGfl75fw+jujenRvI4/wg8t9dtCx5HuptrBff455i+fw/qZcMptoXOzQKqu+EQY/hBsSXfJ1oyHAAMn3+Z1ZBJitOhPFTcpfRP1asTRr3W9wJ/MWti8wE2SXzoJdvzitjftA0Pugzot4f0/wcSL4cIPICYu8DGFqi2LYNN8GPagJuBWJe0OlRh+CK1PCfz50idAzRRoFYRzlUdKKvS8xH1QP/YK98E9mKdPiieafApWTIUFX7tFfg/uhXrt3HytbmP9VvL78OfLiDLwt+Ed/XK8kNT/z+5nOP8tOO7Kyh0rPw+m3gP12kLPi/0SnkilpZ7hSsSn3ecqVPpe65bCEClESVcVti8nj2lLt3J2r2bERAdo0LMgHzb89HuitXsDmGhoeTz0udLdAS3cMS33KfjwSvjsVhj1f1U34Zj/JkTFugUYpeqIreZK1JZOghGPBnYx7P0ZbqTruKtCc9HtAXe4Vsxf/RPGvh2cc1oLG+fSbMEEfoyfQINZWZBQC7qc6drptzjBr2vtzF2bweT0zdwwqB2Na1fz23FDTvO+7ubarKeh92WVu97S3obty+CccRAd678YRSrDGBjxCDzT1904O+EmryOSEBSCv2klWKYu3Up2boH/SwvzDsLab90Hx2VTYN92iI6DNgNdOUj7U6FGCSNr3c6F7UvdSu/Jqe4DYVWTlwPp411CWtLPSSJX5zGw6H1Y+x20CeDaLos/gILc0E3saya7luvT/gVrvoNWJwbuXNt/cQszL3wXdq0lLjqen+nO7jZjOGfsZRAT7/dTFhRY7pu8hJSkeK4+OQJaxB9N/z/DxItg2SR3jVfEwf0w/d8ugQuFxi8ihdVtBee9BSZKv7ulWEq6qrDJ6ZtpmJRA7xZ+mEdwcD+smuYSreWfQ85ud7en/VD3y7HdUFf3XBYD/wnbl8Pnt7kSkraDKh9fOFk2xa35oQYaVVPbwRBX05UYBjLpSpvg2rM37Bq4c1RW32vdOkxf3AFXzvDrKBNZm1xyu/Bd2JzmPii1OglO+hum0ygeeno+naOTOCcACRfARwt+JW3jbh49uxvV46rAr+KOI6Fua/jhSUgdXbEqhh+fgT2b4axXq24VhIS2toO9jkBCWBV4p5fi7D6Qy4zl27m4Xwuioir4yyt7tytPWvoJrJjq6pgTakOnUS7Raj0AYhPKf9yoKDjzBXh5GLz7R7hiGtRvV7EYw9H8NyGpqVawr6piq/2+UPLIxwJT+rdzFWycDYPvCe0Pr7HVYNDd8MGf3Ohv9/Mrd7wDme79Kn0irP0esNC4h5s72eVM14HMJzkx/sjuhX6y/2Ae//l8Occ0rcWYHk0Cco6QExXtOg1Oucl1gGx5fPmev2+nWw+twwho0S8wMYqIBJCSrirqy8VbOJhfwKjylhbu3Q7LP3UfCFd/48qTajaEHhe4RKvF8f6ps49PhLHvuG5h75wHf5oK1SKws1dRmRtg1ddw0q3uQ4pUTZ1Hw6L3XJlum4H+P376RMBA13P8f2x/6/IH+OlZV2aYegbE1Sjf83OzYcUX7jWv+NK1L6/b2i2o2/XsEpt0NKyVwPz1mZWPvxjPz1jNlqxsnjq/R8VveoWj7ufD9Adg5pPlT7q+fcQ1Mxl0d2BiExEJMCVdVdSk9M00q1uNbk1rHX3n3Rth6WSXaK2fCbYAareAvldDp9OhSW//lv0cUqcFnPsWvH4avHspXPB+aE7496cFbwPWJbFSdf1WYviR/5Mua13XwlYnQq0wGGWJioJh/4ZXhsHMp+GUvx/9OQX5sOZbt9bd0k8gJ8ut6dT7cjjmbLcMw1FG+FKSEtialY211q9rZ23efYDnv13FyGMacWzLun47bliIreYaKH3zoCshL+saRhlrXCfLHhdCcgR3eRSRiBbhn2ClODv35vDDyh1cdVLrkj9M7FjpPqwsnQSbfnbbklPdCEyn0yClS3DKklr0g1GPwyfXu3kdI/4T+HN6paAAFrwJrU527fOl6jqsxPBR/3Zp2zgHdq1x/5fDRfO+bpTrh/9zbcKTGh25j7VumYWF77m5Wnu3QFyiW7y461nQ8qRy3bRJTownJ6+ArAN51Kruv5//fz5fToGF2yK5RXxpjv2Ta5Q08yk44+myPefr+yEqBk65I7CxiYgEkJKuKuizRVvIL7BHdi3MznIlTfNed+tpATTp5eZ9dDwt6Gvl/KbnRa5F8Kyn3V3O3pd5E0egrf0WMte7RiIincf4Sgy/8+9oV9p4iKnmkpFwMvgeWP6Z+wA++n+/b9+5yjXDWPgu7FzpOqW2G+pKB9sPcwlsBRReINlfSdeCDZl8OP9Xrj2lDc3q+medr7BToz50v8At/j7wLkhMKX3/TfPd/4MTbyk+2RYRCRNKuqqgSWmbaJtck44NE93d4V9/hp9fg4XvQ+4+SO7sJpanng61mnodrjPkX64c5dNbXUfDVid5HZH//TzOrQnUaZTXkUgoOKyLoZ+SrryDrlV8x5Fl7yYaKuq2dqVps/7nml7s+MXN09r0M2Cg5QnQ/wb3vuWH+Z8pSS7p2pqVTYeGlf9ZWetaxNevGc+1Azy6gRUq+l0Hc1+B2c/DoFJuMlnr1mmrXg+O/0vw4hMRCYAArYhbNsaYV4wx24wxiwptq2uM+coYs8L3WKfQ9243xqw0xiw3xgwrtL2XMWah73tPGl/NnDEm3hgzwbf9J2NMy6C+wBC0NSub2Wsz+ENqImbOS/DcifDSQFeS02UMXD4VrvkB+l0bOgkXuKYSZ70MddvAxIshY7XXEfnXgV2ulKzrORW+My8RJjYBOpzq5lPm5/rnmCu+dNdat/P8c7xgO+lWl1C9eaZbUqIgF4bcB39dDJdOhl6X+K3hTkri70mXP0xO38y8dbu4dVh7asZX8fud9dq4m0tzXoacvSXvt3Kam5t30t8gISl48YmIBICnSRfwGjC8yLbbgGnW2nbANN/fMcakAucBnX3PecYYc6i927PAlUA7359Dx7wc2GWtbQs8DjwcsFcSDqxlzref8UjMc1w191T49BY3L2vkY3Dzcjjjf9Ds2NBtIZ1QC84f775++zzXsj5SpL8L+Tlam0sO13kMHMhwHzz9IX28aygRrssRVKsNf3gRTrkdrv0Jrv4ejr8hIA1BkpPc+lz+SLqyc/N56LNlpDZK4qxezSp9vIjQ/wbIznRLZBSnIB+m3u3mt0ZqSbmIVCmeJl3W2m+BjCKbzwBe9339OjC60Pbx1toca+0aYCXQxxjTCEiy1s6y1lrgjSLPOXSs94BBxp9tqMLF/gz48Vl4pi+j5l7KiOg5RHU7D678Bq7+Do69PHzuItZtDee8ARmr4L3L3S/mSDB/nFuktlE3ryORUNJmkGsGsfjDyh/rwC63rl7Xs8K7C2jbwXDKbQHvYpcQG03t6rFs9cNaXS9/v4ZfMw9w56hORFelFvGladYHmvWFH/8H+XlHfj99Imxd5OZ9xcQFPz4RET/zeqSrOCnW2s0Avsdk3/YmwIZC+230bWvi+7ro9sOeY63NA3YD9Yo7qTHmSmPMXGPM3O3bt/vppXjIWrf45/tXwKMd4fPbyImqxt9zr+CtE76C055wi4KGo1YnwYhHYOVXrt4/3G1Ogy3p0ONiryORUHOoxHCZH0oMF3/o1qg6JgzW5goRKYkJlR7p2paVzf+mr2Roagr929T3U2QR4vgbXPOgpR8fvj03263n1ag7dD7Tk9BERPwtFJOukhR3e9CWsr205xy50doXrLW9rbW9GzRoUMEQQ8C+Ha4V79PHwmsj4ZfPXYvlq7/nlU4vMyF/AMN7tvE6ysrrfZlvUv3TJZenhIufx0F0vBuBECmq82g3SrVmRuWOkzYB6ndwH2SlTFJqVT7p+u+Xy8nNL+COEZ38FFUEaX+qa4z0w5PuRuEhs1+A3Rtg6H2BWQNSRMQDofhuttVXMojvcZtv+0agcDF8U2CTb3vTYrYf9hxjTAxQiyPLGcNfQQGs/gbe/aMb1fryTqheF0Y/6+ZqjfwvNOzKpLRN9GheO3JaFQ97EFqfApNuhHWzvI6mYnKzYeFEN6m8ehVbKFXK5rcSw48qfoyMNbDhR+h2bujO2QxBKYnxlSovXPTrbt6dt5FL+7ekZf0afowsQkRFQb/r3RIla7932w7sgu8ehbZDIrNLrYhUWaGYdH0CXOL7+hLg40Lbz/N1JGyFa5gx21eCuMcY09c3X+viIs85dKyzgK99874iw56t8N1j8FRPeOMMWPW1W3jy2h/h8i+h+/kQ5xKsVdv3smRzFqcd0/goBw0j0TFw9mtQuzlMuBB2rfM6ovJbNtk1BOmhBhpSgtgE6DiiciWG6RPdY1eVFpZHSlIC2/fmkF9Q/l8bh1rE16kex/UD2wUgugjR7TyoXh9mPun+/t1j7j1x8D2ehiUi4m9et4x/B5gFdDDGbDTGXA48BAwxxqwAhvj+jrV2MTARWAJ8DlxnrT3UReEa4CVcc41VwGe+7S8D9YwxK4Gb8HVCDGsFBbByqksyHk+FafdCUmM480U3qnXqQ5B8ZBnL5LTNrlHhMRG2uGS1OnD+BNc6+p2xkLPH64jK5+c3XNLY6mSvI5FQljq64iWG1kL6BGh5ItRW57zySKmVQH6BZefe8o92fbF4Kz+tyeCvQ9pTq5p/FleOSLHV4Lir3HIGK76Cn56HbmOhYRevIxMR8StPW1hZa8eW8K1BJez/APBAMdvnAke8Q1trs4GzKxNjyMjaBPPfgvlvuInH1evBcVdDz0ugQftSn2qt5ZO0XzmuVd3fFvyMKPXbuRGvN8+CD66Ec98Kj3kAu9a6D9Gn3BEe8Yp32gyE+CTXDKPt4PI999d5rtvnCX8NTGwRLCXxUNv4HJLL8d6Zk5fPvz9dSvuUmow9VonuUfW+3I1wjb/A/X3AHd7GIyISAPqkF8oK8l2L53fGwuOdYfr9UKcVnPUK3LQUhj1w1IQLYNmWPazavo9RkVRaWFSbgTD8QVj+KXx9n9fRlM2CtwHjykBFSlOZhZLTxkNMAqSeEZjYItihm1Tlbabx+sy1rM/Yz50jU4mJ1q/Zo6pRD3pc6NYqPO4qjciKSEQK48VaqoBN8+Htc9xipsf/xc37qVf+zoOT0jYRHWU4tUvDAAQZQvpcCduWwPePQYOOrmlAqCrIdyOXbQboA4aUTecxrkxw9QxoV8bRrryDsOh96DAifNbiCyENa7mka0s5kq4de3N4atpKBnRowEntw7gTbrCdeDPYfPcoIhKBlHSFsia94IL3XIe+6IrNCbDWMil9E8e3rU+9mvH+jS/UGAMj/gs7V8Enf3YLKTc71uuoird6OmRtdC2RRcqicIlhWZOulVPhQIZrViDlVq9GHFHGrbVVVo9/9Qv7c/P5x8jUAEYWgZIawajHvY5CRCRgVPcQyoyBdkMqnHABpG3czYaMA5wWaQ00ShIdC+e84X6Bjz8fdm88+nOCyVrYOBe+ecg1Aek40uuIJFzExLsRq2WT3QhWWaSPd53h2gwMbGwRKiY6ivo1y942ftmWLN6ZvZ6L+ragbXLNAEcnIiLhRElXhJuUtom46CiGdo7w0sLCqteFseMh94CbD3dwn9cRQXYWzHkJnjsRXhoEW5fAoLvdB2mRsuo8BrIzy9bF8EAmLP8cuvyhUjduqrqGtRLKVF5oreX+yUtJTIjlL4PUIl5ERA6npCuCFRRYpqRv5uQODapey+LkTq7hyJaF8OHVrtW+FzbNh09ucItWT7kZDDDyMbh5GfT+ozcxSfhqM8BXYvjR0fdd8pFrTBDKcxvDQHJiQpkaaXy9bBvfr9zBXwa1o06NuCBEJiIi4URzuiLY3HW72JKVzR3djly3q0poP9TNmfryTpjxMAy4PTjnzdkLi96Dua/C5gUQU82NNvS+DJr0dGWjIhURE+9KUpdNgrzHIaaUD/dpE6BeO2jcM3jxRaCUpHh+Xr+r1H1y8wt4YMpSWjeowUX9WgQpMhERCSdKuiLYpLRNJMRGMahjsteheKff9bBtGcx4CBp0gC5nBu5cWxa6RCt9IhzcA8mpcOojcMw5UK124M4rVUvqaEh7x5UYthtS/D671sH6mTDwTiX5ldQwKYGMfQfJycsnPia62H3GzVrH6h37ePmS3sSqRbyIiBRDSVeEyssv4NOFmxnUKYUa8VX4n9kYGPUY7FwJH10DdVq60SZ/ObgfFn/gkq1f57r1kDqPgV5/hGZ99IFX/K/NAIiv5etiWELStXCie+x6TvDiilCH1uralpVDs7rVj/j+rn0HeWLaCk5sV5+BVfkGl4iIlEq35CLUrNU72bnvIKdF8oLIZRUTD+e+6dY7G38+ZG2u/DG3LoFPb3VztT6+DnKyYNiDbtHqMc9B8+OUcElgxMRDx1K6GFrrSgtbHA91VOpWWclJrtnNtj3Fz+t6YtoK9mTncufIVIz+z4uISAmUdEWoSWmbqBkfwykdtDgnADUbwNh3XBfB8ee7zobllXsA0sbDy8Pg2X4w7zU3b+zST+G62dDvWtc5USTQOo+B7N2w+psjv7fpZ9i5Ao5RAw1/+G2B5N1Hto1fuW0P435cx9g+zenQMDHYoYmISBipwnVnketgXgGfL9rC0M4pJMQWPwehSmrYBf7wIoy/AD6+Hv7wUtlGo7b/AvNehQVvu3bdddvAkPug+wVQo17AwxY5QutCJYbthx7+vbQJEB0PqWd4E1uESUl0SVdxHQwfmLKU6rHR3DSkfbDDEhGRMKOkKwJ9t2I7Wdl5nNZNpYVH6DgSBt0F0/4FyR3hpFuL3y8vB5ZOcnO11n0PUbHQaZSbq9XqJJUOirdi4nxdDKe4EsNDXQzzc2HR+9DhVDVv8ZPa1WOJi4lia5Hywhm/bGf68u3cMaIj9WpqvT0RESmdkq4INCltE7Wrx3JC2/pehxKaTrjJdTT8+n5o0BE6nfb793au+n1Ua/9O13hj8D3Q/UJXoigSKjqPgbS3YfV0aD/MbVs5DfbvUGmhHxljSEmKZ+vu35OuvPwC7p+8hBb1qnNJ/5beBSciImFDSVeEOXAwn6+WbOX07o3VurgkxsDpT0HGKvjgSrh0smuxPe9VWPMtmGjXqKDXH10ZV5R+jhKCWp8CCbXcQsmHkq708VCtLrQd7GVkESclMYGtWb/P6XpnzgZWbNvLcxf2LLGNvIiISGFKuiLM9OXb2HcwX10LjyY2Ac57G14c6P4A1Gru1jXqcREkNvQ2PpGjiYmDjqNg6WRXDpuXDcs+hZ4Xl75ospRbSlICS7dkAbD7QC6Pfbmc41rVZVhnvU+IiEjZKOmKMJPSNlG/ZjzHtVaDh6NKbAjnT4SfnoVOZ0DbQRClu9YSRlJHw4K3XBfDvVshPwe6ned1VBEnJSmBb5ZvA+Dpr1eQeSCXu0apRbyIiJSdkq4Isic7l6+XbWNsn+ZER+nDQJk07AJn/M/rKEQq5rcSww9h90bXWbNJL6+jijgpSfHsO5jPol9389rMtZzdqyldmtTyOiwREQkjSroiyNSlW8nJK+C0bo28DkVEguFQieHijyB3Hwz4hzprBkBKkmsbf8u7acRGR3HL0A4eRyQiIuFGHQIiyOS0zTSpXY0ezep4HYqIBEvnMS7hAjjmHG9jiVCHkq5lW/Zw3YC2JPv+LiIiUlZKuiJE5v6DfLtiO6OOaUSUSgtFqo5WJ0NCbWjezy1xIH6XkuTW4WpSuxqXn9DK42hERCQcqbwwQnyxeAu5+ZZR6looUrXExMGFH0B1jXAHSpM61Ti2ZR2uPaUtCbFqtiMiIuWnpCtCTErbTMt61enSJMnrUEQk2JqqeUYgxcdE8+7V/b0OQ0REwpjKCyPA9j05zFy1g9O6NVYLYxERERGREKOkKwJ8tmgzBRZO66bSQhERERGRUKOkKwJMSttEh5RE2qckeh2KiIiIiIgUoaQrzG3efYA5a3dpbS4RERERkRClpCvMTUnfDKCuhSIiIiIiIUpJV5iblLaJrk1q0bJ+Da9DERERERGRYijpCmPrdu4jbeNulRaKiIiIiIQwJV1hbLKvtHCkSgtFREREREKWkq4wNiltE71b1KFJ7WpehyIiIiIiIiVQ0hWmVmzdw7Ite7Q2l4iIiIhIiFPSFaYmpW8mysCpXRt6HYqIiIiIiJRCSVcYstYyOW0T/drUIzkxwetwRERERESkFEq6wtDiTVms3rFPa3OJiIiIiIQBJV1haFL6JmKiDMM7q7RQRERERCTUKekKM660cDMntqtPnRpxXocjIiIiIiJHoaQrzPy8PpNfMw+oa6GIiIiISJhQ0hVmJqVtIi4miiGpKV6HIiIiIiIiZaCkK4zkF1g+XbiZgR2SSUyI9TocEREREREpAyVdYWT2mgy27clRaaGIiIiISBhR0hVGJqVvonpcNAM7JnsdioiIiIiIlJGSrjCRm1/AZws3M7hTCtXior0OR0REREREykhJV5j4YeUOdu3PVWmhiIiIiEiYUdIVJialbSYxIYaT2tf3OhQRERERESkHJV1hIDs3ny8Xb2F454bEx6i0UEREREQknCjpCgPf/rKdPTl5Ki0UEREREQlDSrrCwKT0zdStEUf/NvW8DkVERERERMpJSVeI238wj6lLtnJql4bEROufS0REREQk3OhTfIibtnQbB3LzVVooIiIiIhKmlHSFuElpm0hJiufYlnW9DkVERERERCogZJMuY8xfjDGLjDGLjTE3+rbVNcZ8ZYxZ4XusU2j/240xK40xy40xwwpt72WMWej73pPGGOPBy6mQrOxcvlm+nZFdGxMdFTZhi4iIiIhIISGZdBljugBXAH2AbsAoY0w74DZgmrW2HTDN93eMManAeUBnYDjwjDHmUG/1Z4ErgXa+P8OD+FIqZcvubDo0TOS0bo28DkVERERERCooJJMuoBPwo7V2v7U2D5gBjAHOAF737fM6MNr39RnAeGttjrV2DbAS6GOMaQQkWWtnWWst8Eah54S89imJTPrzCfRoXufoO4uIiIiISEgK1aRrEXCSMaaeMaY6MAJoBqRYazcD+B6Tffs3ATYUev5G37Ymvq+LbhcREREREQmKGK8DKI61dqkx5mHgK2AvkAbklfKU4iY82VK2H3kAY67ElSHSvHnzcsUrIiIiIiJSklAd6cJa+7K1tqe19iQgA1gBbPWVDOJ73ObbfSNuJOyQpsAm3/amxWwv7nwvWGt7W2t7N2jQwL8vRkREREREqqyQTbqMMcm+x+bAmcA7wCfAJb5dLgE+9n39CXCeMSbeGNMK1zBjtq8EcY8xpq+va+HFhZ4jIiIiIiIScCFZXujzvjGmHpALXGet3WWMeQiYaIy5HFgPnA1grV1sjJkILMGVIV5nrc33Heca4DWgGvCZ74+IiIiIiEhQGNfUTwrr3bu3nTt3rtdhiIiIiIhIiDLGzLPW9i7LviFbXigiIiIiIhIJlHSJiIiIiIgEkJIuERERERGRAFLSJSIiIiIiEkBKukRERERERAJISZeIiIiIiEgAKekSEREREREJICVdIiIiIiIiAaSkS0REREREJICUdImIiIiIiASQki4REREREZEAUtIlIiIiIiISQMZa63UMIccYsx1Y53UchdQHdngdhEQMXU/iL7qWxJ90PYk/6XoSfyrpemphrW1QlgMo6QoDxpi51treXschkUHXk/iLriXxJ11P4k+6nsSf/HE9qbxQREREREQkgJR0iYiIiIiIBJCSrvDwgtcBSETR9ST+omtJ/EnXk/iTrifxp0pfT5rTJSIiIiIiEkAa6RIREREREQkgJV0eM8YkGGNmG2PSjDGLjTH3+rbXNcZ8ZYxZ4XusU+g5txtjVhpjlhtjhnkXvYSa8l5PxpiWxpgDxpgFvj/PefsKJJSUcj2d7ft7gTGmd5Hn6P1JilXe60nvT1KaUq6nR4wxy4wx6caYD40xtQs9R+9PUqzyXk8VeX9SeaHHjDEGqGGt3WuMiQW+B/4CnAlkWGsfMsbcBtSx1v7dGJMKvAP0ARoDU4H21tp8j16ChJAKXE8tgcnW2i7eRS2hqpTraTdQADwP3GKtnevbX+9PUqIKXE8t0fuTlKCU6ykJ+Npam2eMeRhAn5/kaCpwPbWknO9PGunymHX2+v4a6/tjgTOA133bXwdG+74+Axhvrc2x1q4BVuLeQEQqcj2JlKik68lau9Rau7yYp+j9SUpUgetJpESlXE9fWmvzfNt/BJr6vtb7k5SoAtdTuSnpCgHGmGhjzAJgG/CVtfYnIMVauxnA95js270JsKHQ0zf6tokA5b6eAFoZY+YbY2YYY04MfsQSykq4nkqi9ycpVTmvJ9D7k5SiDNfTZcBnvq/1/iSlKuf1BOV8f1LSFQKstfnW2u647LmPMaa0oUpT3CECEpiEpXJeT5uB5tbaHsBNwNvGmKQghClhQu9P4k96fxJ/Ku16Msb8A8gD3jq0qbhDBDxICRvlvJ7K/f6kpCuEWGszgW+A4cBWY0wjAN/jNt9uG4FmhZ7WFNgUvCglXJTlevKVWez0fT0PWAW09yJeCW1FrqeS6P1JyqQs15Pen6Ssil5PxphLgFHABfb35gV6f5IyKcv1VJH3JyVdHjPGNCjUCaUaMBhYBnwCXOLb7RLgY9/XnwDnGWPijTGtgHbA7KAGLSGrvNeTb/9o39etcdfT6iCHLSGqlOupJHp/khKV93rS+5OUpqTryRgzHPg7cLq1dn+hp+j9SUpU3uupIu9PMQGKXcquEfC67x8uCphorZ1sjJkFTDTGXA6sB84GsNYuNsZMBJbghjmvU+cdKaRc1xNwEvAvY0wekA9cba3N8CJwCUklXU9jgKeABsAUY8wCa+0wvT/JUZTrekLvT1K6kq6nlUA88JVrSMeP1tqr9f4kR1Gu64kKvD+pZbyIiIiIiEgAqbxQREREREQkgJR0iYiIiIiIBJCSLhERERERkQBS0iUiIiIiIhJASrpEREREREQCSEmXiIiIiIhIACnpEhGRoDDGRBtjrjDGzDDGZBhjco0x24wx6caYl4wxp3sdo4iISCBonS4REQk434KTk4HhQCYwBdgI1AXaAP2An621J3gVo4iISKDEeB2AiIhUCWNxCVcacLK1dnfhbxpjqgPHeRGYiIhIoKm8UEREgqG/7/G1ogkXgLV2v7V2etHtxpixxpjpxphdxphsY8xSY8ydxpj44k5ijDnPGDPPGHPAV7o4zhjT2BjzjTHGFtn3UmOMNcZcWsKxrDHmm2K2xxhjrjXG/GiMyTLG7DfGzDfGXG+MiSqyb0vfcV7zfT3eGLPD91rmGmNGlfQDM8aca4yZ5ivFzDbGrDXGvGOM6V3Zn5OIiASXRrpERCQYdvoe25f1CcaYl4HLcGWIH+DKEvsC9wGDjDFDrLV5hfb/K/CYb783fI/DgJnAEYleRRhjYoFJvuMuB94GsoEBwFO40bqLinlqC2A2sBoYhyurPBf42BgzuHDCaYwxwKvAJcAO32vfDjT1nWc5MLfQ/uX6OYmISPAp6RIRkWD4APg7cLUxJhH4EJhnrV1X3M6+0afLfPtdYK09UOh79wB3A9cBT/i2tQQeAnYBPa21a33bbwfeBc700+v4By7hehq40Vqb7ztPNPACcJkx5j1r7cdFnncKcI+19t5Cr+Nt4HPgVqDwKN8VuIRrDjCk8Mig7zzJhf5+KeX4OYmIiDfUSENERILCGHMO7sN/w0KbM4BvgVestZMK7Tsf6AI0sNZmFjlONLAVWG2t7ePb9g/gfuBf1tq7i+zfGlgBRFlrTaHtl+JGlP5orX2tmHgtMMNae4rv71HANiAXaFZ09MgYU9v3et6z1p7j29YSWAOsA9ocStIKPWcdUMNaW7/QtoW+197TWju/aFxFnl+un5OIiHhDI10iIhIU1tqJxpgPcSVyJwA9fI+jgdHGmDeAS4FqQDdcad2NrtruCDlAp0J/7+l7nFHMeVcbYzbgSvwqoz1QD5fA3VlCXAeKxHXIgqIJl88GXOdGAIwxNXBJ1NYyJFzVKf/PSUREPKCkS0REgsZamwt86ftzaDTmD8ArwMW4Mrk5gAEa4MrjyqKW73FrCd/fQuWTrnq+x3aUHlfNYrZllrBvHoc3tarte/y1DPHUofw/JxER8YC6F4qIiGestfnW2onA475NA/m96cV8a60p7U+hQx16TkoJp2pYzLYC3+MRNyB9pYJFHTrHh0eJq1VJr7cMMn2PTcqwb0V+TiIi4gElXSIiEgr2+B6NtXYvsBjobIypW8bn/+x7PLnoN3xzupoV85xdvsfivndEW3ZgGb7OgL4uhn5nrd0HLAJSjDE9jrJvRX5OIiLiASVdIiIScL51pIYUXcfK972GuI594JpqgGv9Hge8UtyokzGmjjGmZ6FNb+EaXPzZ17zi0H5RwCMU//tuLm6063zf/KhDz6kL/Kfozr7GGU8BjYAnjTHViomrkTEmtZhzlceTvsfnjTG1Cn/DGBNljGlUaFN5f04iIuIBzekSEZFgOA74C7DFGPM9rqMfQCtgJK55xsfAewDW2leMMb2Aa4FVxpgvgPW49a1aASfhOg9e7dt/rTHmNuBRYL4xZgKu/G4Ybp5UOnBM4YCstZuNMW/h1tVaYIyZAiQBI3DJX3EjTffhmldcDZxmjPkaN/8qGTfX63hcW/klFf1BAS/hGoxcDKwwxnyMW6erMa788hXgnor8nERExBtqGS8iIgFnjGkGnA4MBlJxo0UJuEWT5+MWGX7bWltQ5HmjcAlDH1zylIFLKr4E3rTWLiuy/1jculepuJLFL4C/+Y5/ctH5TcaYeFyr+bG4xGk98DJudCyXQi3jCz3HABfiOi32wDXO2I5LJD8FxllrN/j2benb/rq19tJifi7fFBeX73sXAFcC3YF4YDNuoedHrbU/F9m3XD8nEREJLiVdIiIS8UpLbkRERAJNc7pEREREREQCSEmXiIiIiIhIACnpEhERERERCSDN6RIREREREQkgjXSJiIiIiIgEkJIuERERERGRAFLSJSIiIiIiEkBKukRERERERAJISZeIiIiIiEgAKekSEREREREJoP8HMgOg5EYNGjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(325)\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(df[300:325]['Sales'], label='original')\n",
    "plt.plot(x[300:325], y_hat, label='prediction')\n",
    "plt.legend()\n",
    "plt.xlabel('Sequence', fontsize=20)\n",
    "plt.ylabel('Sales', fontsize=20)\n",
    "plt.title('RNN prediction', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "051887d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3270 - mae: 0.4837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3270481526851654, 0.4836752414703369]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819448e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
