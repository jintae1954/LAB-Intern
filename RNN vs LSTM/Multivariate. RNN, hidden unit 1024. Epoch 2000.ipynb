{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044e22b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjintae\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jintae/RNN%20seq%201024./runs/3cszfnio\" target=\"_blank\">youthful-dew-1</a></strong> to <a href=\"https://wandb.ai/jintae/RNN%20seq%201024.\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jintae/RNN%20seq%201024./runs/3cszfnio?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x209b7f03c40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"RNN seq 1024.\", name=\"epoch 2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650bae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE  Sales\n",
      "0     0   3459\n",
      "1     1   3458\n",
      "2     2   4002\n",
      "3     3   4564\n",
      "4     4   4221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/PARK/Desktop/Alcohol_Sales.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e18e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4f8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6063052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01930485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 3459],\n",
       "       [   1, 3458],\n",
       "       [   2, 4002],\n",
       "       [   3, 4564],\n",
       "       [   4, 4221]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad83b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17aef2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data.mean()\n",
    "data_std = data.std()\n",
    "\n",
    "data = (data - data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fe0032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9194862 , -0.12914209],\n",
       "       [-0.91925771, -0.12937058],\n",
       "       [-0.91902922, -0.00507246],\n",
       "       [-0.91880073,  0.12333846],\n",
       "       [-0.91857224,  0.04496667]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ac24ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_label = []\n",
    "\n",
    "data_len = 325\n",
    "time_step = 100\n",
    "out_dim = 25\n",
    "\n",
    "for i in range(176):\n",
    "    _input = data[i:i+time_step]\n",
    "    _label = data[i+time_step:i+time_step+out_dim]\n",
    "    \n",
    "    train_input.append(_input)\n",
    "    train_label.append(_label)\n",
    "    \n",
    "\n",
    "train_input = np.array(train_input)\n",
    "train_label = np.array(train_label)\n",
    "train_label = np.delete(train_label, 0, axis=2)\n",
    "\n",
    "\n",
    "test_input = np.array(data[data_len-out_dim-time_step:data_len-out_dim])\n",
    "test_label =np.array(data[300:325])\n",
    "test_label = np.delete(test_label, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41975dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b762c3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 25, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127c63a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6647472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d83c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "shuffled_indices = np.random.permutation(np.arange(train_input.shape[0]))\n",
    "train_input = train_input[shuffled_indices, :, :]\n",
    "train_label = train_label[shuffled_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a183926e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1024)              1051648   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                25625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,077,273\n",
      "Trainable params: 1,077,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9290 - mae: 0.7971INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 665ms/step - loss: 0.9290 - mae: 0.7971 - val_loss: 0.3351 - val_mae: 0.4661\n",
      "Epoch 2/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.3555 - mae: 0.4802INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 542ms/step - loss: 0.3465 - mae: 0.4736 - val_loss: 0.2631 - val_mae: 0.4195\n",
      "Epoch 3/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.2784 - mae: 0.4294 - val_loss: 0.2653 - val_mae: 0.4154\n",
      "Epoch 4/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2615 - mae: 0.4105INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 544ms/step - loss: 0.2615 - mae: 0.4105 - val_loss: 0.2525 - val_mae: 0.4107\n",
      "Epoch 5/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2474 - mae: 0.4041INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 552ms/step - loss: 0.2474 - mae: 0.4041 - val_loss: 0.2252 - val_mae: 0.3936\n",
      "Epoch 6/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2309 - mae: 0.3917INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 573ms/step - loss: 0.2309 - mae: 0.3917 - val_loss: 0.1968 - val_mae: 0.3658\n",
      "Epoch 7/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2035 - mae: 0.3701INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 509ms/step - loss: 0.2035 - mae: 0.3701 - val_loss: 0.1876 - val_mae: 0.3602\n",
      "Epoch 8/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.1962 - mae: 0.3642INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 595ms/step - loss: 0.1983 - mae: 0.3671 - val_loss: 0.1868 - val_mae: 0.3577\n",
      "Epoch 9/2000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.1858 - mae: 0.3565 - val_loss: 0.1912 - val_mae: 0.3651\n",
      "Epoch 10/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.1928 - mae: 0.3639INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 515ms/step - loss: 0.1936 - mae: 0.3650 - val_loss: 0.1865 - val_mae: 0.3562\n",
      "Epoch 11/2000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1917 - mae: 0.3586 - val_loss: 0.1902 - val_mae: 0.3638\n",
      "Epoch 12/2000\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.1945 - mae: 0.3623 - val_loss: 0.2198 - val_mae: 0.3822\n",
      "Epoch 13/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1941 - mae: 0.3615INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 576ms/step - loss: 0.1941 - mae: 0.3615 - val_loss: 0.1780 - val_mae: 0.3518\n",
      "Epoch 14/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1793 - mae: 0.3503INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 533ms/step - loss: 0.1793 - mae: 0.3503 - val_loss: 0.1779 - val_mae: 0.3489\n",
      "Epoch 15/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1897 - mae: 0.3584INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 530ms/step - loss: 0.1897 - mae: 0.3584 - val_loss: 0.1747 - val_mae: 0.3467\n",
      "Epoch 16/2000\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.2032 - mae: 0.3717 - val_loss: 0.1757 - val_mae: 0.3443\n",
      "Epoch 17/2000\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.1850 - mae: 0.3516 - val_loss: 0.2243 - val_mae: 0.3906\n",
      "Epoch 18/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.2166 - mae: 0.3811 - val_loss: 0.2389 - val_mae: 0.4048\n",
      "Epoch 19/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2019 - mae: 0.3679 - val_loss: 0.1780 - val_mae: 0.3499\n",
      "Epoch 20/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1772 - mae: 0.3466 - val_loss: 0.1783 - val_mae: 0.3475\n",
      "Epoch 21/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1809 - mae: 0.3489INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 537ms/step - loss: 0.1809 - mae: 0.3489 - val_loss: 0.1658 - val_mae: 0.3387\n",
      "Epoch 22/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1837 - mae: 0.3492 - val_loss: 0.1863 - val_mae: 0.3572\n",
      "Epoch 23/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.1906 - mae: 0.3532 - val_loss: 0.2684 - val_mae: 0.4240\n",
      "Epoch 24/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2424 - mae: 0.3996 - val_loss: 0.1793 - val_mae: 0.3478\n",
      "Epoch 25/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2131 - mae: 0.3761 - val_loss: 0.2823 - val_mae: 0.4386\n",
      "Epoch 26/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.2142 - mae: 0.3739 - val_loss: 0.1675 - val_mae: 0.3393\n",
      "Epoch 27/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1839 - mae: 0.3539 - val_loss: 0.2008 - val_mae: 0.3688\n",
      "Epoch 28/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2055 - mae: 0.3738 - val_loss: 0.2092 - val_mae: 0.3732\n",
      "Epoch 29/2000\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.2044 - mae: 0.3692 - val_loss: 0.1879 - val_mae: 0.3585\n",
      "Epoch 30/2000\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.1858 - mae: 0.3514 - val_loss: 0.1773 - val_mae: 0.3481\n",
      "Epoch 31/2000\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.1788 - mae: 0.3491 - val_loss: 0.1709 - val_mae: 0.3407\n",
      "Epoch 32/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.1792 - mae: 0.3480 - val_loss: 0.1696 - val_mae: 0.3413\n",
      "Epoch 33/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1797 - mae: 0.3450 - val_loss: 0.2507 - val_mae: 0.4092\n",
      "Epoch 34/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.2229 - mae: 0.3851 - val_loss: 0.2312 - val_mae: 0.3943\n",
      "Epoch 35/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1884 - mae: 0.3541INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 511ms/step - loss: 0.1884 - mae: 0.3541 - val_loss: 0.1651 - val_mae: 0.3354\n",
      "Epoch 36/2000\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.1719 - mae: 0.3389 - val_loss: 0.1687 - val_mae: 0.3389\n",
      "Epoch 37/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1677 - mae: 0.3325 - val_loss: 0.2629 - val_mae: 0.4201\n",
      "Epoch 38/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2186 - mae: 0.3816 - val_loss: 0.3485 - val_mae: 0.4910\n",
      "Epoch 39/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.3078 - mae: 0.4576 - val_loss: 0.2870 - val_mae: 0.4387\n",
      "Epoch 40/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.2672 - mae: 0.4219 - val_loss: 0.3751 - val_mae: 0.5047\n",
      "Epoch 41/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2859 - mae: 0.4324 - val_loss: 0.2981 - val_mae: 0.4459\n",
      "Epoch 42/2000\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.2600 - mae: 0.4126 - val_loss: 0.2320 - val_mae: 0.3939\n",
      "Epoch 43/2000\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.2168 - mae: 0.3823 - val_loss: 0.1995 - val_mae: 0.3664\n",
      "Epoch 44/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.1968 - mae: 0.3649 - val_loss: 0.1821 - val_mae: 0.3507\n",
      "Epoch 45/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1894 - mae: 0.3583 - val_loss: 0.1913 - val_mae: 0.3616\n",
      "Epoch 46/2000\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.1868 - mae: 0.3562 - val_loss: 0.1754 - val_mae: 0.3460\n",
      "Epoch 47/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.1756 - mae: 0.3466 - val_loss: 0.1800 - val_mae: 0.3511\n",
      "Epoch 48/2000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.1749 - mae: 0.3472 - val_loss: 0.1716 - val_mae: 0.3427\n",
      "Epoch 49/2000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.1776 - mae: 0.3473 - val_loss: 0.1652 - val_mae: 0.3348\n",
      "Epoch 50/2000\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.1758 - mae: 0.3423 - val_loss: 0.1714 - val_mae: 0.3407\n",
      "Epoch 51/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1687 - mae: 0.3378INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 491ms/step - loss: 0.1687 - mae: 0.3378 - val_loss: 0.1596 - val_mae: 0.3305\n",
      "Epoch 52/2000\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.1808 - mae: 0.3492 - val_loss: 0.2054 - val_mae: 0.3714\n",
      "Epoch 53/2000\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.1746 - mae: 0.3424 - val_loss: 0.1727 - val_mae: 0.3394\n",
      "Epoch 54/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1647 - mae: 0.3322INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 569ms/step - loss: 0.1647 - mae: 0.3322 - val_loss: 0.1475 - val_mae: 0.3144\n",
      "Epoch 55/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.1580 - mae: 0.3264 - val_loss: 0.1568 - val_mae: 0.3253\n",
      "Epoch 56/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.1657 - mae: 0.3336 - val_loss: 0.2448 - val_mae: 0.4035\n",
      "Epoch 57/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.2343 - mae: 0.3923 - val_loss: 0.2912 - val_mae: 0.4489\n",
      "Epoch 58/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2715 - mae: 0.4208 - val_loss: 0.3570 - val_mae: 0.4943\n",
      "Epoch 59/2000\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.2482 - mae: 0.4062 - val_loss: 0.1948 - val_mae: 0.3615\n",
      "Epoch 60/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.2065 - mae: 0.3710 - val_loss: 0.1867 - val_mae: 0.3566\n",
      "Epoch 61/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2142 - mae: 0.3744 - val_loss: 0.1940 - val_mae: 0.3634\n",
      "Epoch 62/2000\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.1931 - mae: 0.3578 - val_loss: 0.1892 - val_mae: 0.3591\n",
      "Epoch 63/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1992 - mae: 0.3668 - val_loss: 0.1863 - val_mae: 0.3549\n",
      "Epoch 64/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1795 - mae: 0.3498 - val_loss: 0.1669 - val_mae: 0.3399\n",
      "Epoch 65/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1727 - mae: 0.3416 - val_loss: 0.1611 - val_mae: 0.3321\n",
      "Epoch 66/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1638 - mae: 0.3319 - val_loss: 0.1590 - val_mae: 0.3301\n",
      "Epoch 67/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1626 - mae: 0.3332 - val_loss: 0.1598 - val_mae: 0.3333\n",
      "Epoch 68/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1701 - mae: 0.3381 - val_loss: 0.1571 - val_mae: 0.3250\n",
      "Epoch 69/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1673 - mae: 0.3354 - val_loss: 0.1538 - val_mae: 0.3250\n",
      "Epoch 70/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1505 - mae: 0.3189INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 499ms/step - loss: 0.1505 - mae: 0.3189 - val_loss: 0.1385 - val_mae: 0.3080\n",
      "Epoch 71/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1424 - mae: 0.3087 - val_loss: 0.1512 - val_mae: 0.3158\n",
      "Epoch 72/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.1438 - mae: 0.3104 - val_loss: 0.1447 - val_mae: 0.3128\n",
      "Epoch 73/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1411 - mae: 0.3053INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 524ms/step - loss: 0.1411 - mae: 0.3053 - val_loss: 0.1095 - val_mae: 0.2731\n",
      "Epoch 74/2000\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.1709 - mae: 0.3394 - val_loss: 0.1140 - val_mae: 0.2753\n",
      "Epoch 75/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1194 - mae: 0.2815 - val_loss: 0.2608 - val_mae: 0.4245\n",
      "Epoch 76/2000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.1870 - mae: 0.3519 - val_loss: 0.1922 - val_mae: 0.3620\n",
      "Epoch 77/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.2022 - mae: 0.3688 - val_loss: 0.2313 - val_mae: 0.3980\n",
      "Epoch 78/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.2229 - mae: 0.3774 - val_loss: 0.3433 - val_mae: 0.4900\n",
      "Epoch 79/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2463 - mae: 0.4022 - val_loss: 0.1836 - val_mae: 0.3529\n",
      "Epoch 80/2000\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.2063 - mae: 0.3731 - val_loss: 0.1667 - val_mae: 0.3345\n",
      "Epoch 81/2000\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.1732 - mae: 0.3414 - val_loss: 0.1763 - val_mae: 0.3487\n",
      "Epoch 82/2000\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.1757 - mae: 0.3441 - val_loss: 0.1749 - val_mae: 0.3420\n",
      "Epoch 83/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1848 - mae: 0.3536 - val_loss: 0.1731 - val_mae: 0.3434\n",
      "Epoch 84/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.1743 - mae: 0.3379 - val_loss: 0.1897 - val_mae: 0.3556\n",
      "Epoch 85/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1735 - mae: 0.3383 - val_loss: 0.1627 - val_mae: 0.3302\n",
      "Epoch 86/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.1549 - mae: 0.3220 - val_loss: 0.1634 - val_mae: 0.3295\n",
      "Epoch 87/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1511 - mae: 0.3144 - val_loss: 0.1449 - val_mae: 0.3139\n",
      "Epoch 88/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1550 - mae: 0.3225 - val_loss: 0.2216 - val_mae: 0.3903\n",
      "Epoch 89/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1674 - mae: 0.3327 - val_loss: 0.1741 - val_mae: 0.3414\n",
      "Epoch 90/2000\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.1401 - mae: 0.3047 - val_loss: 0.1126 - val_mae: 0.2729\n",
      "Epoch 91/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1469 - mae: 0.3076 - val_loss: 0.1571 - val_mae: 0.3245\n",
      "Epoch 92/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1375 - mae: 0.3007INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 822ms/step - loss: 0.1375 - mae: 0.3007 - val_loss: 0.1065 - val_mae: 0.2684\n",
      "Epoch 93/2000\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.1145 - mae: 0.2708 - val_loss: 0.1716 - val_mae: 0.3449\n",
      "Epoch 94/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.1271 - mae: 0.2889 - val_loss: 0.2204 - val_mae: 0.3898\n",
      "Epoch 95/2000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.1737 - mae: 0.3454 - val_loss: 0.1941 - val_mae: 0.3637\n",
      "Epoch 96/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.1558 - mae: 0.3241 - val_loss: 0.1832 - val_mae: 0.3428\n",
      "Epoch 97/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1801 - mae: 0.3456 - val_loss: 0.2059 - val_mae: 0.3705\n",
      "Epoch 98/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1816 - mae: 0.3415 - val_loss: 0.1620 - val_mae: 0.3299\n",
      "Epoch 99/2000\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.1765 - mae: 0.3409 - val_loss: 0.1301 - val_mae: 0.2922\n",
      "Epoch 100/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1613 - mae: 0.3224 - val_loss: 0.1249 - val_mae: 0.2872\n",
      "Epoch 101/2000\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.1488 - mae: 0.3152 - val_loss: 0.2113 - val_mae: 0.3787\n",
      "Epoch 102/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.1817 - mae: 0.3473 - val_loss: 0.1773 - val_mae: 0.3418\n",
      "Epoch 103/2000\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.1745 - mae: 0.3378 - val_loss: 0.2472 - val_mae: 0.4050\n",
      "Epoch 104/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2105 - mae: 0.3751 - val_loss: 0.1412 - val_mae: 0.3086\n",
      "Epoch 105/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1457 - mae: 0.3088 - val_loss: 0.1361 - val_mae: 0.2964\n",
      "Epoch 106/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.1322 - mae: 0.2958 - val_loss: 0.1317 - val_mae: 0.3006\n",
      "Epoch 107/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.1239 - mae: 0.2866 - val_loss: 0.1499 - val_mae: 0.3125\n",
      "Epoch 108/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1377 - mae: 0.2936 - val_loss: 0.1117 - val_mae: 0.2708\n",
      "Epoch 109/2000\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0926 - mae: 0.2463 - val_loss: 0.1128 - val_mae: 0.2804\n",
      "Epoch 110/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.1057 - mae: 0.2623 - val_loss: 0.1096 - val_mae: 0.2721\n",
      "Epoch 111/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1079 - mae: 0.2646INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 521ms/step - loss: 0.1079 - mae: 0.2646 - val_loss: 0.0802 - val_mae: 0.2265\n",
      "Epoch 112/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0848 - mae: 0.2317INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 513ms/step - loss: 0.0847 - mae: 0.2318 - val_loss: 0.0752 - val_mae: 0.2090\n",
      "Epoch 113/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.1281 - mae: 0.2905INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 521ms/step - loss: 0.1294 - mae: 0.2919 - val_loss: 0.0688 - val_mae: 0.2053\n",
      "Epoch 114/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0906 - mae: 0.2374 - val_loss: 0.2353 - val_mae: 0.4112\n",
      "Epoch 115/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.1322 - mae: 0.2905 - val_loss: 0.0866 - val_mae: 0.2352\n",
      "Epoch 116/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0922 - mae: 0.2409 - val_loss: 0.1139 - val_mae: 0.2770\n",
      "Epoch 117/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0960 - mae: 0.2514 - val_loss: 0.1795 - val_mae: 0.3521\n",
      "Epoch 118/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.1643 - mae: 0.3294 - val_loss: 0.1581 - val_mae: 0.3318\n",
      "Epoch 119/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.1436 - mae: 0.3061 - val_loss: 0.0869 - val_mae: 0.2392\n",
      "Epoch 120/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1266 - mae: 0.2896 - val_loss: 0.1114 - val_mae: 0.2709\n",
      "Epoch 121/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1159 - mae: 0.2761 - val_loss: 0.0880 - val_mae: 0.2372\n",
      "Epoch 122/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0981 - mae: 0.2487 - val_loss: 0.0948 - val_mae: 0.2484\n",
      "Epoch 123/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1177 - mae: 0.2751 - val_loss: 0.2067 - val_mae: 0.3797\n",
      "Epoch 124/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1092 - mae: 0.2641 - val_loss: 0.0840 - val_mae: 0.2298\n",
      "Epoch 125/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0874 - mae: 0.2342INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 515ms/step - loss: 0.0874 - mae: 0.2342 - val_loss: 0.0670 - val_mae: 0.2021\n",
      "Epoch 126/2000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0676 - mae: 0.2026 - val_loss: 0.0777 - val_mae: 0.2144\n",
      "Epoch 127/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1078 - mae: 0.2666 - val_loss: 0.0830 - val_mae: 0.2261\n",
      "Epoch 128/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0853 - mae: 0.2323 - val_loss: 0.0704 - val_mae: 0.2045\n",
      "Epoch 129/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0721 - mae: 0.2109INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 486ms/step - loss: 0.0737 - mae: 0.2135 - val_loss: 0.0670 - val_mae: 0.2061\n",
      "Epoch 130/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0650 - mae: 0.2001INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 530ms/step - loss: 0.0647 - mae: 0.1991 - val_loss: 0.0657 - val_mae: 0.1955\n",
      "Epoch 131/2000\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0599 - mae: 0.1905 - val_loss: 0.0658 - val_mae: 0.1966\n",
      "Epoch 132/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0755 - mae: 0.2168 - val_loss: 0.0805 - val_mae: 0.2209\n",
      "Epoch 133/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0656 - mae: 0.1995INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 541ms/step - loss: 0.0656 - mae: 0.1995 - val_loss: 0.0600 - val_mae: 0.1929\n",
      "Epoch 134/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0623 - mae: 0.1949 - val_loss: 0.0606 - val_mae: 0.1900\n",
      "Epoch 135/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0683 - mae: 0.2036 - val_loss: 0.0617 - val_mae: 0.1937\n",
      "Epoch 136/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0591 - mae: 0.1901 - val_loss: 0.0622 - val_mae: 0.1957\n",
      "Epoch 137/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0605 - mae: 0.1923 - val_loss: 0.0603 - val_mae: 0.1916\n",
      "Epoch 138/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0611 - mae: 0.1929 - val_loss: 0.0711 - val_mae: 0.2079\n",
      "Epoch 139/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0608 - mae: 0.1925INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 488ms/step - loss: 0.0608 - mae: 0.1925 - val_loss: 0.0556 - val_mae: 0.1807\n",
      "Epoch 140/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0586 - mae: 0.1882 - val_loss: 0.0673 - val_mae: 0.2120\n",
      "Epoch 141/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0624 - mae: 0.1961 - val_loss: 0.0763 - val_mae: 0.2219\n",
      "Epoch 142/2000\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0650 - mae: 0.2020 - val_loss: 0.0601 - val_mae: 0.1910\n",
      "Epoch 143/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0552 - mae: 0.1840INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 529ms/step - loss: 0.0545 - mae: 0.1823 - val_loss: 0.0548 - val_mae: 0.1762\n",
      "Epoch 144/2000\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0579 - mae: 0.1885 - val_loss: 0.0582 - val_mae: 0.1856\n",
      "Epoch 145/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0505 - mae: 0.1720 - val_loss: 0.0567 - val_mae: 0.1873\n",
      "Epoch 146/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0658 - mae: 0.2033INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 527ms/step - loss: 0.0658 - mae: 0.2033 - val_loss: 0.0530 - val_mae: 0.1791\n",
      "Epoch 147/2000\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0600 - mae: 0.1931 - val_loss: 0.0638 - val_mae: 0.1948\n",
      "Epoch 148/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0619 - mae: 0.1963 - val_loss: 0.0619 - val_mae: 0.1882\n",
      "Epoch 149/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0615 - mae: 0.1930 - val_loss: 0.0640 - val_mae: 0.1973\n",
      "Epoch 150/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0574 - mae: 0.1874 - val_loss: 0.0539 - val_mae: 0.1815\n",
      "Epoch 151/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0518 - mae: 0.1749 - val_loss: 0.0535 - val_mae: 0.1813\n",
      "Epoch 152/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0490 - mae: 0.1706 - val_loss: 0.0665 - val_mae: 0.2090\n",
      "Epoch 153/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1060 - mae: 0.2664 - val_loss: 0.1081 - val_mae: 0.2694\n",
      "Epoch 154/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0837 - mae: 0.2293 - val_loss: 0.0579 - val_mae: 0.1883\n",
      "Epoch 155/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0710 - mae: 0.2111 - val_loss: 0.0655 - val_mae: 0.1998\n",
      "Epoch 156/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0623 - mae: 0.1954 - val_loss: 0.1064 - val_mae: 0.2681\n",
      "Epoch 157/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0817 - mae: 0.2311 - val_loss: 0.0855 - val_mae: 0.2445\n",
      "Epoch 158/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0991 - mae: 0.2574 - val_loss: 0.1416 - val_mae: 0.3162\n",
      "Epoch 159/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1070 - mae: 0.2676 - val_loss: 0.1367 - val_mae: 0.3105\n",
      "Epoch 160/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1143 - mae: 0.2805 - val_loss: 0.0766 - val_mae: 0.2202\n",
      "Epoch 161/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0828 - mae: 0.2287 - val_loss: 0.0791 - val_mae: 0.2235\n",
      "Epoch 162/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0741 - mae: 0.2177 - val_loss: 0.0568 - val_mae: 0.1890\n",
      "Epoch 163/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0689 - mae: 0.2105 - val_loss: 0.0609 - val_mae: 0.1876\n",
      "Epoch 164/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0751 - mae: 0.2187 - val_loss: 0.0737 - val_mae: 0.2164\n",
      "Epoch 165/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0628 - mae: 0.1973 - val_loss: 0.0596 - val_mae: 0.1955\n",
      "Epoch 166/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0564 - mae: 0.1892 - val_loss: 0.0557 - val_mae: 0.1863\n",
      "Epoch 167/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0488 - mae: 0.1733INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 521ms/step - loss: 0.0488 - mae: 0.1733 - val_loss: 0.0475 - val_mae: 0.1722\n",
      "Epoch 168/2000\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0448 - mae: 0.1644 - val_loss: 0.0663 - val_mae: 0.2077\n",
      "Epoch 169/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0656 - mae: 0.2076 - val_loss: 0.0996 - val_mae: 0.2697\n",
      "Epoch 170/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0677 - mae: 0.2093 - val_loss: 0.0556 - val_mae: 0.1815\n",
      "Epoch 171/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0583 - mae: 0.1891 - val_loss: 0.0541 - val_mae: 0.1804\n",
      "Epoch 172/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0562 - mae: 0.1875INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 506ms/step - loss: 0.0562 - mae: 0.1875 - val_loss: 0.0465 - val_mae: 0.1698\n",
      "Epoch 173/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0570 - mae: 0.1893 - val_loss: 0.0570 - val_mae: 0.1889\n",
      "Epoch 174/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0579 - mae: 0.1909 - val_loss: 0.0675 - val_mae: 0.2112\n",
      "Epoch 175/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0502 - mae: 0.1754 - val_loss: 0.0469 - val_mae: 0.1699\n",
      "Epoch 176/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0455 - mae: 0.1643INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 529ms/step - loss: 0.0455 - mae: 0.1643 - val_loss: 0.0411 - val_mae: 0.1571\n",
      "Epoch 177/2000\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0419 - mae: 0.1579 - val_loss: 0.0765 - val_mae: 0.2304\n",
      "Epoch 178/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0536 - mae: 0.1833 - val_loss: 0.0920 - val_mae: 0.2514\n",
      "Epoch 179/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0730 - mae: 0.2202 - val_loss: 0.0510 - val_mae: 0.1825\n",
      "Epoch 180/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0544 - mae: 0.1846 - val_loss: 0.0721 - val_mae: 0.2173\n",
      "Epoch 181/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0496 - mae: 0.1760 - val_loss: 0.0709 - val_mae: 0.2130\n",
      "Epoch 182/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0646 - mae: 0.2032 - val_loss: 0.0648 - val_mae: 0.2120\n",
      "Epoch 183/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0531 - mae: 0.1842 - val_loss: 0.0430 - val_mae: 0.1628\n",
      "Epoch 184/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0425 - mae: 0.1636 - val_loss: 0.0428 - val_mae: 0.1648\n",
      "Epoch 185/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0431 - mae: 0.1647 - val_loss: 0.0420 - val_mae: 0.1590\n",
      "Epoch 186/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0435 - mae: 0.1643 - val_loss: 0.0730 - val_mae: 0.2232\n",
      "Epoch 187/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0510 - mae: 0.1802 - val_loss: 0.0574 - val_mae: 0.1879\n",
      "Epoch 188/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0475 - mae: 0.1713 - val_loss: 0.0815 - val_mae: 0.2375\n",
      "Epoch 189/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0536 - mae: 0.1834 - val_loss: 0.0454 - val_mae: 0.1663\n",
      "Epoch 190/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0416 - mae: 0.1596 - val_loss: 0.0414 - val_mae: 0.1558\n",
      "Epoch 191/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0534 - mae: 0.1870INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 497ms/step - loss: 0.0534 - mae: 0.1870 - val_loss: 0.0400 - val_mae: 0.1546\n",
      "Epoch 192/2000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0616 - mae: 0.2003 - val_loss: 0.0453 - val_mae: 0.1688\n",
      "Epoch 193/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0483 - mae: 0.1741INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 498ms/step - loss: 0.0483 - mae: 0.1741 - val_loss: 0.0391 - val_mae: 0.1597\n",
      "Epoch 194/2000\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0456 - mae: 0.1672 - val_loss: 0.0605 - val_mae: 0.1964\n",
      "Epoch 195/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0474 - mae: 0.1718INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 520ms/step - loss: 0.0471 - mae: 0.1713 - val_loss: 0.0379 - val_mae: 0.1543\n",
      "Epoch 196/2000\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0356 - mae: 0.1495 - val_loss: 0.0477 - val_mae: 0.1709\n",
      "Epoch 197/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0473 - mae: 0.1739INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 491ms/step - loss: 0.0473 - mae: 0.1739 - val_loss: 0.0344 - val_mae: 0.1482\n",
      "Epoch 198/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0416 - mae: 0.1628 - val_loss: 0.0441 - val_mae: 0.1691\n",
      "Epoch 199/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0425 - mae: 0.1629INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 496ms/step - loss: 0.0425 - mae: 0.1629 - val_loss: 0.0342 - val_mae: 0.1442\n",
      "Epoch 200/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0313 - mae: 0.1385INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 556ms/step - loss: 0.0313 - mae: 0.1385 - val_loss: 0.0313 - val_mae: 0.1405\n",
      "Epoch 201/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0274 - mae: 0.1299 - val_loss: 0.0318 - val_mae: 0.1442\n",
      "Epoch 202/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0266 - mae: 0.1294INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 505ms/step - loss: 0.0269 - mae: 0.1301 - val_loss: 0.0307 - val_mae: 0.1412\n",
      "Epoch 203/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0266 - mae: 0.1301 - val_loss: 0.0313 - val_mae: 0.1407\n",
      "Epoch 204/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0296 - mae: 0.1366 - val_loss: 0.0316 - val_mae: 0.1437\n",
      "Epoch 205/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0273 - mae: 0.1301INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 500ms/step - loss: 0.0273 - mae: 0.1301 - val_loss: 0.0268 - val_mae: 0.1323\n",
      "Epoch 206/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0239 - mae: 0.1233INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 552ms/step - loss: 0.0239 - mae: 0.1233 - val_loss: 0.0259 - val_mae: 0.1287\n",
      "Epoch 207/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0276 - mae: 0.1338 - val_loss: 0.1236 - val_mae: 0.3158\n",
      "Epoch 208/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0593 - mae: 0.1991 - val_loss: 0.0858 - val_mae: 0.2474\n",
      "Epoch 209/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0522 - mae: 0.1870 - val_loss: 0.0460 - val_mae: 0.1763\n",
      "Epoch 210/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0446 - mae: 0.1727 - val_loss: 0.0310 - val_mae: 0.1429\n",
      "Epoch 211/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0360 - mae: 0.1522 - val_loss: 0.0291 - val_mae: 0.1360\n",
      "Epoch 212/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0288 - mae: 0.1325 - val_loss: 0.0262 - val_mae: 0.1267\n",
      "Epoch 213/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0232 - mae: 0.1198 - val_loss: 0.0288 - val_mae: 0.1363\n",
      "Epoch 214/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0231 - mae: 0.1213INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 494ms/step - loss: 0.0228 - mae: 0.1203 - val_loss: 0.0240 - val_mae: 0.1266\n",
      "Epoch 215/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0197 - mae: 0.1120INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 544ms/step - loss: 0.0197 - mae: 0.1120 - val_loss: 0.0235 - val_mae: 0.1235\n",
      "Epoch 216/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0218 - mae: 0.1170INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 558ms/step - loss: 0.0218 - mae: 0.1170 - val_loss: 0.0233 - val_mae: 0.1232\n",
      "Epoch 217/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0192 - mae: 0.1109 - val_loss: 0.0303 - val_mae: 0.1413\n",
      "Epoch 218/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0269 - mae: 0.1312 - val_loss: 0.0267 - val_mae: 0.1336\n",
      "Epoch 219/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0232 - mae: 0.1228INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 484ms/step - loss: 0.0232 - mae: 0.1228 - val_loss: 0.0222 - val_mae: 0.1195\n",
      "Epoch 220/2000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0202 - mae: 0.1125 - val_loss: 0.0362 - val_mae: 0.1565\n",
      "Epoch 221/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0235 - mae: 0.1228INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 528ms/step - loss: 0.0235 - mae: 0.1228 - val_loss: 0.0206 - val_mae: 0.1125\n",
      "Epoch 222/2000\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0217 - mae: 0.1171 - val_loss: 0.0272 - val_mae: 0.1320\n",
      "Epoch 223/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0309 - mae: 0.1425 - val_loss: 0.0502 - val_mae: 0.1831\n",
      "Epoch 224/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0351 - mae: 0.1514 - val_loss: 0.0265 - val_mae: 0.1335\n",
      "Epoch 225/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0216 - mae: 0.1179 - val_loss: 0.0574 - val_mae: 0.1987\n",
      "Epoch 226/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0309 - mae: 0.1434INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 502ms/step - loss: 0.0309 - mae: 0.1434 - val_loss: 0.0199 - val_mae: 0.1131\n",
      "Epoch 227/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0188 - mae: 0.1096 - val_loss: 0.0234 - val_mae: 0.1254\n",
      "Epoch 228/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0175 - mae: 0.1046INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 501ms/step - loss: 0.0175 - mae: 0.1046 - val_loss: 0.0197 - val_mae: 0.1109\n",
      "Epoch 229/2000\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0155 - mae: 0.0984 - val_loss: 0.0312 - val_mae: 0.1457\n",
      "Epoch 230/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0185 - mae: 0.1082INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 519ms/step - loss: 0.0185 - mae: 0.1082 - val_loss: 0.0167 - val_mae: 0.1022\n",
      "Epoch 231/2000\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0159 - mae: 0.0993 - val_loss: 0.0270 - val_mae: 0.1331\n",
      "Epoch 232/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0313 - mae: 0.1450 - val_loss: 0.0182 - val_mae: 0.1075\n",
      "Epoch 233/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0223 - mae: 0.1201 - val_loss: 0.0220 - val_mae: 0.1176\n",
      "Epoch 234/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0215 - mae: 0.1178 - val_loss: 0.0192 - val_mae: 0.1101\n",
      "Epoch 235/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0173 - mae: 0.1048INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 529ms/step - loss: 0.0173 - mae: 0.1048 - val_loss: 0.0167 - val_mae: 0.1015\n",
      "Epoch 236/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0131 - mae: 0.0913 - val_loss: 0.0189 - val_mae: 0.1102\n",
      "Epoch 237/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0149 - mae: 0.0979INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 504ms/step - loss: 0.0149 - mae: 0.0979 - val_loss: 0.0145 - val_mae: 0.0955\n",
      "Epoch 238/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0162 - mae: 0.1012INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 548ms/step - loss: 0.0162 - mae: 0.1012 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 239/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0127 - mae: 0.0893INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 519ms/step - loss: 0.0127 - mae: 0.0893 - val_loss: 0.0132 - val_mae: 0.0918\n",
      "Epoch 240/2000\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0130 - mae: 0.0910 - val_loss: 0.0155 - val_mae: 0.0991\n",
      "Epoch 241/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0141 - mae: 0.0943 - val_loss: 0.0147 - val_mae: 0.0954\n",
      "Epoch 242/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0124 - mae: 0.0896 - val_loss: 0.0249 - val_mae: 0.1301\n",
      "Epoch 243/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0169 - mae: 0.1050 - val_loss: 0.0193 - val_mae: 0.1125\n",
      "Epoch 244/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0201 - mae: 0.1132 - val_loss: 0.0173 - val_mae: 0.1057\n",
      "Epoch 245/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0260 - mae: 0.1309 - val_loss: 0.0273 - val_mae: 0.1327\n",
      "Epoch 246/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0273 - mae: 0.1334 - val_loss: 0.0179 - val_mae: 0.1066\n",
      "Epoch 247/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0247 - mae: 0.1274 - val_loss: 0.0473 - val_mae: 0.1882\n",
      "Epoch 248/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0321 - mae: 0.1481 - val_loss: 0.0173 - val_mae: 0.1047\n",
      "Epoch 249/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0167 - mae: 0.1035 - val_loss: 0.0153 - val_mae: 0.0979\n",
      "Epoch 250/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0173 - mae: 0.1046 - val_loss: 0.0230 - val_mae: 0.1237\n",
      "Epoch 251/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0145 - mae: 0.0964 - val_loss: 0.0146 - val_mae: 0.0956\n",
      "Epoch 252/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0111 - mae: 0.0839 - val_loss: 0.0146 - val_mae: 0.0950\n",
      "Epoch 253/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0110 - mae: 0.0832 - val_loss: 0.0148 - val_mae: 0.0949\n",
      "Epoch 254/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0110 - mae: 0.0840 - val_loss: 0.0146 - val_mae: 0.0942\n",
      "Epoch 255/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0154 - mae: 0.0999 - val_loss: 0.0157 - val_mae: 0.1007\n",
      "Epoch 256/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0118 - mae: 0.0867 - val_loss: 0.0193 - val_mae: 0.1123\n",
      "Epoch 257/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0186 - mae: 0.1105INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 489ms/step - loss: 0.0186 - mae: 0.1105 - val_loss: 0.0123 - val_mae: 0.0886\n",
      "Epoch 258/2000\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0108 - mae: 0.0831 - val_loss: 0.0202 - val_mae: 0.1147\n",
      "Epoch 259/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0160 - mae: 0.1017 - val_loss: 0.0138 - val_mae: 0.0923\n",
      "Epoch 260/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0125 - mae: 0.0895 - val_loss: 0.0140 - val_mae: 0.0933\n",
      "Epoch 261/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0148 - mae: 0.0964 - val_loss: 0.0221 - val_mae: 0.1220\n",
      "Epoch 262/2000\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.0196 - mae: 0.1135 - val_loss: 0.0294 - val_mae: 0.1442\n",
      "Epoch 263/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0203 - mae: 0.1168 - val_loss: 0.0374 - val_mae: 0.1638\n",
      "Epoch 264/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0366 - mae: 0.1606 - val_loss: 0.0153 - val_mae: 0.0989\n",
      "Epoch 265/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0177 - mae: 0.1076 - val_loss: 0.0161 - val_mae: 0.1017\n",
      "Epoch 266/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0120 - mae: 0.0866 - val_loss: 0.0206 - val_mae: 0.1159\n",
      "Epoch 267/2000\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0170 - mae: 0.1044 - val_loss: 0.0131 - val_mae: 0.0899\n",
      "Epoch 268/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0106 - mae: 0.0826 - val_loss: 0.0161 - val_mae: 0.1026\n",
      "Epoch 269/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0203 - mae: 0.1162 - val_loss: 0.0689 - val_mae: 0.2349\n",
      "Epoch 270/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0381 - mae: 0.1649 - val_loss: 0.0630 - val_mae: 0.2215\n",
      "Epoch 271/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0418 - mae: 0.1672 - val_loss: 0.0226 - val_mae: 0.1208\n",
      "Epoch 272/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0383 - mae: 0.1583 - val_loss: 0.0491 - val_mae: 0.1867\n",
      "Epoch 273/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0340 - mae: 0.1515 - val_loss: 0.0312 - val_mae: 0.1455\n",
      "Epoch 274/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0244 - mae: 0.1254 - val_loss: 0.0385 - val_mae: 0.1613\n",
      "Epoch 275/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0265 - mae: 0.1306 - val_loss: 0.0237 - val_mae: 0.1237\n",
      "Epoch 276/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0169 - mae: 0.1025 - val_loss: 0.0140 - val_mae: 0.0943\n",
      "Epoch 277/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0148 - mae: 0.0970 - val_loss: 0.0143 - val_mae: 0.0960\n",
      "Epoch 278/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0115 - mae: 0.0851 - val_loss: 0.0133 - val_mae: 0.0917\n",
      "Epoch 279/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0105 - mae: 0.0814 - val_loss: 0.0140 - val_mae: 0.0952\n",
      "Epoch 280/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0118 - mae: 0.0871 - val_loss: 0.0342 - val_mae: 0.1589\n",
      "Epoch 281/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0268 - mae: 0.1355 - val_loss: 0.0238 - val_mae: 0.1265\n",
      "Epoch 282/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0196 - mae: 0.1144 - val_loss: 0.0434 - val_mae: 0.1794\n",
      "Epoch 283/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0220 - mae: 0.1192 - val_loss: 0.0388 - val_mae: 0.1644\n",
      "Epoch 284/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0200 - mae: 0.1147INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 523ms/step - loss: 0.0200 - mae: 0.1147 - val_loss: 0.0112 - val_mae: 0.0840\n",
      "Epoch 285/2000\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0091 - mae: 0.0757 - val_loss: 0.0153 - val_mae: 0.0988\n",
      "Epoch 286/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0120 - mae: 0.0865 - val_loss: 0.0127 - val_mae: 0.0912\n",
      "Epoch 287/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0124 - mae: 0.0895 - val_loss: 0.0121 - val_mae: 0.0879\n",
      "Epoch 288/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0141 - mae: 0.0968INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 503ms/step - loss: 0.0141 - mae: 0.0968 - val_loss: 0.0108 - val_mae: 0.0823\n",
      "Epoch 289/2000\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0095 - mae: 0.0771 - val_loss: 0.0115 - val_mae: 0.0850\n",
      "Epoch 290/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0087 - mae: 0.0728INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 543ms/step - loss: 0.0087 - mae: 0.0728 - val_loss: 0.0093 - val_mae: 0.0759\n",
      "Epoch 291/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0097 - mae: 0.0782 - val_loss: 0.0098 - val_mae: 0.0780\n",
      "Epoch 292/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0112 - mae: 0.0842 - val_loss: 0.0204 - val_mae: 0.1164\n",
      "Epoch 293/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0135 - mae: 0.0938 - val_loss: 0.0130 - val_mae: 0.0906\n",
      "Epoch 294/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0106 - mae: 0.0826 - val_loss: 0.0106 - val_mae: 0.0814\n",
      "Epoch 295/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0101 - mae: 0.0791 - val_loss: 0.0096 - val_mae: 0.0784\n",
      "Epoch 296/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0120 - mae: 0.0860 - val_loss: 0.0160 - val_mae: 0.1036\n",
      "Epoch 297/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0096 - mae: 0.0782 - val_loss: 0.0121 - val_mae: 0.0885\n",
      "Epoch 298/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0101 - mae: 0.0803 - val_loss: 0.0101 - val_mae: 0.0805\n",
      "Epoch 299/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0116 - mae: 0.0862 - val_loss: 0.0148 - val_mae: 0.0974\n",
      "Epoch 300/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0169 - mae: 0.1044 - val_loss: 0.0373 - val_mae: 0.1647\n",
      "Epoch 301/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0183 - mae: 0.1086 - val_loss: 0.0238 - val_mae: 0.1282\n",
      "Epoch 302/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0195 - mae: 0.1141 - val_loss: 0.0176 - val_mae: 0.1087\n",
      "Epoch 303/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0132 - mae: 0.0910 - val_loss: 0.0245 - val_mae: 0.1284\n",
      "Epoch 304/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0153 - mae: 0.0991 - val_loss: 0.0130 - val_mae: 0.0919\n",
      "Epoch 305/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0111 - mae: 0.0846 - val_loss: 0.0128 - val_mae: 0.0901\n",
      "Epoch 306/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0123 - mae: 0.0879 - val_loss: 0.0358 - val_mae: 0.1647\n",
      "Epoch 307/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0171 - mae: 0.1054 - val_loss: 0.0174 - val_mae: 0.1050\n",
      "Epoch 308/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0124 - mae: 0.0890 - val_loss: 0.0125 - val_mae: 0.0887\n",
      "Epoch 309/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0100 - mae: 0.0794 - val_loss: 0.0097 - val_mae: 0.0787\n",
      "Epoch 310/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0077 - mae: 0.0695 - val_loss: 0.0124 - val_mae: 0.0880\n",
      "Epoch 311/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0096 - mae: 0.0790INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 504ms/step - loss: 0.0096 - mae: 0.0790 - val_loss: 0.0084 - val_mae: 0.0723\n",
      "Epoch 312/2000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0094 - mae: 0.0764 - val_loss: 0.0217 - val_mae: 0.1228\n",
      "Epoch 313/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0142 - mae: 0.0975 - val_loss: 0.0105 - val_mae: 0.0804\n",
      "Epoch 314/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0088 - mae: 0.0742 - val_loss: 0.0116 - val_mae: 0.0866\n",
      "Epoch 315/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0113 - mae: 0.0847 - val_loss: 0.0108 - val_mae: 0.0830\n",
      "Epoch 316/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0108 - mae: 0.0829 - val_loss: 0.0288 - val_mae: 0.1442\n",
      "Epoch 317/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0197 - mae: 0.1157 - val_loss: 0.0147 - val_mae: 0.0952\n",
      "Epoch 318/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0123 - mae: 0.0887 - val_loss: 0.0104 - val_mae: 0.0807\n",
      "Epoch 319/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0089 - mae: 0.0737 - val_loss: 0.0213 - val_mae: 0.1209\n",
      "Epoch 320/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0194 - mae: 0.1151 - val_loss: 0.0103 - val_mae: 0.0809\n",
      "Epoch 321/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0139 - mae: 0.0934 - val_loss: 0.0199 - val_mae: 0.1130\n",
      "Epoch 322/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0120 - mae: 0.0879 - val_loss: 0.0186 - val_mae: 0.1139\n",
      "Epoch 323/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0145 - mae: 0.0975 - val_loss: 0.0156 - val_mae: 0.0992\n",
      "Epoch 324/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0129 - mae: 0.0918 - val_loss: 0.0249 - val_mae: 0.1313\n",
      "Epoch 325/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0200 - mae: 0.1175 - val_loss: 0.0113 - val_mae: 0.0865\n",
      "Epoch 326/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0098 - mae: 0.0791 - val_loss: 0.0124 - val_mae: 0.0895\n",
      "Epoch 327/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0120 - mae: 0.0875 - val_loss: 0.0124 - val_mae: 0.0872\n",
      "Epoch 328/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0117 - mae: 0.0848 - val_loss: 0.0232 - val_mae: 0.1285\n",
      "Epoch 329/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0143 - mae: 0.0970 - val_loss: 0.0111 - val_mae: 0.0838\n",
      "Epoch 330/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0195 - mae: 0.1126 - val_loss: 0.0366 - val_mae: 0.1705\n",
      "Epoch 331/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0264 - mae: 0.1364 - val_loss: 0.0543 - val_mae: 0.2027\n",
      "Epoch 332/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0433 - mae: 0.1741 - val_loss: 0.0582 - val_mae: 0.2058\n",
      "Epoch 333/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0497 - mae: 0.1860 - val_loss: 0.0275 - val_mae: 0.1318\n",
      "Epoch 334/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0494 - mae: 0.1807 - val_loss: 0.0904 - val_mae: 0.2344\n",
      "Epoch 335/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0842 - mae: 0.2315 - val_loss: 0.0757 - val_mae: 0.2167\n",
      "Epoch 336/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0731 - mae: 0.2148 - val_loss: 0.0734 - val_mae: 0.2149\n",
      "Epoch 337/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0697 - mae: 0.2095 - val_loss: 0.2030 - val_mae: 0.3864\n",
      "Epoch 338/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1668 - mae: 0.3376 - val_loss: 0.0881 - val_mae: 0.2386\n",
      "Epoch 339/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0972 - mae: 0.2480 - val_loss: 0.0783 - val_mae: 0.2260\n",
      "Epoch 340/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0746 - mae: 0.2171 - val_loss: 0.1078 - val_mae: 0.2749\n",
      "Epoch 341/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0780 - mae: 0.2195 - val_loss: 0.0703 - val_mae: 0.2085\n",
      "Epoch 342/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0733 - mae: 0.2161 - val_loss: 0.0660 - val_mae: 0.2000\n",
      "Epoch 343/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0623 - mae: 0.1946 - val_loss: 0.0664 - val_mae: 0.1980\n",
      "Epoch 344/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0826 - mae: 0.2293 - val_loss: 0.0477 - val_mae: 0.1726\n",
      "Epoch 345/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0505 - mae: 0.1771 - val_loss: 0.0492 - val_mae: 0.1763\n",
      "Epoch 346/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0450 - mae: 0.1668 - val_loss: 0.0438 - val_mae: 0.1676\n",
      "Epoch 347/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0366 - mae: 0.1508 - val_loss: 0.0599 - val_mae: 0.1906\n",
      "Epoch 348/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0429 - mae: 0.1635 - val_loss: 0.0319 - val_mae: 0.1398\n",
      "Epoch 349/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0302 - mae: 0.1358 - val_loss: 0.0419 - val_mae: 0.1641\n",
      "Epoch 350/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0328 - mae: 0.1429 - val_loss: 0.0260 - val_mae: 0.1294\n",
      "Epoch 351/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0233 - mae: 0.1199 - val_loss: 0.0249 - val_mae: 0.1257\n",
      "Epoch 352/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0230 - mae: 0.1197 - val_loss: 0.0204 - val_mae: 0.1126\n",
      "Epoch 353/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0292 - mae: 0.1360 - val_loss: 0.0614 - val_mae: 0.2140\n",
      "Epoch 354/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0336 - mae: 0.1491 - val_loss: 0.0209 - val_mae: 0.1140\n",
      "Epoch 355/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0201 - mae: 0.1131 - val_loss: 0.0235 - val_mae: 0.1246\n",
      "Epoch 356/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0195 - mae: 0.1111 - val_loss: 0.0377 - val_mae: 0.1604\n",
      "Epoch 357/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0240 - mae: 0.1244 - val_loss: 0.0204 - val_mae: 0.1153\n",
      "Epoch 358/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0186 - mae: 0.1083 - val_loss: 0.0174 - val_mae: 0.1033\n",
      "Epoch 359/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0168 - mae: 0.1037 - val_loss: 0.0292 - val_mae: 0.1390\n",
      "Epoch 360/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0178 - mae: 0.1065 - val_loss: 0.0252 - val_mae: 0.1294\n",
      "Epoch 361/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0212 - mae: 0.1175 - val_loss: 0.0146 - val_mae: 0.0955\n",
      "Epoch 362/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0165 - mae: 0.1047 - val_loss: 0.0156 - val_mae: 0.0987\n",
      "Epoch 363/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0147 - mae: 0.0965 - val_loss: 0.0179 - val_mae: 0.1064\n",
      "Epoch 364/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0160 - mae: 0.1015 - val_loss: 0.0456 - val_mae: 0.1859\n",
      "Epoch 365/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0231 - mae: 0.1229 - val_loss: 0.0204 - val_mae: 0.1141\n",
      "Epoch 366/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0181 - mae: 0.1077 - val_loss: 0.0241 - val_mae: 0.1229\n",
      "Epoch 367/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0152 - mae: 0.0975 - val_loss: 0.0157 - val_mae: 0.1007\n",
      "Epoch 368/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0138 - mae: 0.0940 - val_loss: 0.0323 - val_mae: 0.1520\n",
      "Epoch 369/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0194 - mae: 0.1123 - val_loss: 0.0156 - val_mae: 0.0988\n",
      "Epoch 370/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0139 - mae: 0.0952 - val_loss: 0.0156 - val_mae: 0.0990\n",
      "Epoch 371/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0173 - mae: 0.1051 - val_loss: 0.0168 - val_mae: 0.1054\n",
      "Epoch 372/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0136 - mae: 0.0934 - val_loss: 0.0147 - val_mae: 0.0962\n",
      "Epoch 373/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0111 - mae: 0.0834 - val_loss: 0.0135 - val_mae: 0.0923\n",
      "Epoch 374/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0142 - mae: 0.0949 - val_loss: 0.0298 - val_mae: 0.1434\n",
      "Epoch 375/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0157 - mae: 0.0998 - val_loss: 0.0172 - val_mae: 0.1061\n",
      "Epoch 376/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0114 - mae: 0.0851 - val_loss: 0.0129 - val_mae: 0.0911\n",
      "Epoch 377/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0107 - mae: 0.0826 - val_loss: 0.0271 - val_mae: 0.1375\n",
      "Epoch 378/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0172 - mae: 0.1075 - val_loss: 0.0129 - val_mae: 0.0913\n",
      "Epoch 379/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0097 - mae: 0.0785 - val_loss: 0.0128 - val_mae: 0.0899\n",
      "Epoch 380/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0088 - mae: 0.0738 - val_loss: 0.0137 - val_mae: 0.0926\n",
      "Epoch 381/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0098 - mae: 0.0790 - val_loss: 0.0134 - val_mae: 0.0909\n",
      "Epoch 382/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0143 - mae: 0.0961 - val_loss: 0.0294 - val_mae: 0.1436\n",
      "Epoch 383/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0236 - mae: 0.1273 - val_loss: 0.0408 - val_mae: 0.1713\n",
      "Epoch 384/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0313 - mae: 0.1467 - val_loss: 0.0325 - val_mae: 0.1473\n",
      "Epoch 385/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0263 - mae: 0.1307 - val_loss: 0.0645 - val_mae: 0.2297\n",
      "Epoch 386/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0394 - mae: 0.1648 - val_loss: 0.0302 - val_mae: 0.1455\n",
      "Epoch 387/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0158 - mae: 0.1003 - val_loss: 0.0258 - val_mae: 0.1347\n",
      "Epoch 388/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0221 - mae: 0.1224 - val_loss: 0.0121 - val_mae: 0.0883\n",
      "Epoch 389/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0121 - mae: 0.0874 - val_loss: 0.0136 - val_mae: 0.0908\n",
      "Epoch 390/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0200 - mae: 0.1152 - val_loss: 0.0375 - val_mae: 0.1673\n",
      "Epoch 391/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0266 - mae: 0.1339 - val_loss: 0.0369 - val_mae: 0.1639\n",
      "Epoch 392/2000\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0260 - mae: 0.1352 - val_loss: 0.0361 - val_mae: 0.1615\n",
      "Epoch 393/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0221 - mae: 0.1211 - val_loss: 0.0268 - val_mae: 0.1352\n",
      "Epoch 394/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0212 - mae: 0.1203 - val_loss: 0.0136 - val_mae: 0.0920\n",
      "Epoch 395/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0159 - mae: 0.1005 - val_loss: 0.0153 - val_mae: 0.1003\n",
      "Epoch 396/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0142 - mae: 0.0956 - val_loss: 0.0480 - val_mae: 0.1898\n",
      "Epoch 397/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0344 - mae: 0.1557 - val_loss: 0.0506 - val_mae: 0.2006\n",
      "Epoch 398/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0351 - mae: 0.1596 - val_loss: 0.0377 - val_mae: 0.1629\n",
      "Epoch 399/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0218 - mae: 0.1206 - val_loss: 0.0370 - val_mae: 0.1678\n",
      "Epoch 400/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0191 - mae: 0.1128 - val_loss: 0.0135 - val_mae: 0.0934\n",
      "Epoch 401/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0097 - mae: 0.0789 - val_loss: 0.0198 - val_mae: 0.1124\n",
      "Epoch 402/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0139 - mae: 0.0951 - val_loss: 0.0291 - val_mae: 0.1462\n",
      "Epoch 403/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0210 - mae: 0.1209 - val_loss: 0.0211 - val_mae: 0.1189\n",
      "Epoch 404/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0163 - mae: 0.1023 - val_loss: 0.0138 - val_mae: 0.0923\n",
      "Epoch 405/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0095 - mae: 0.0774 - val_loss: 0.0130 - val_mae: 0.0903\n",
      "Epoch 406/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0101 - mae: 0.0796 - val_loss: 0.0166 - val_mae: 0.1015\n",
      "Epoch 407/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0108 - mae: 0.0817 - val_loss: 0.0202 - val_mae: 0.1184\n",
      "Epoch 408/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0173 - mae: 0.1085 - val_loss: 0.0128 - val_mae: 0.0928\n",
      "Epoch 409/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0124 - mae: 0.0894 - val_loss: 0.0104 - val_mae: 0.0799\n",
      "Epoch 410/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0109 - mae: 0.0836 - val_loss: 0.0165 - val_mae: 0.1047\n",
      "Epoch 411/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0110 - mae: 0.0851 - val_loss: 0.0219 - val_mae: 0.1228\n",
      "Epoch 412/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0164 - mae: 0.1040 - val_loss: 0.0222 - val_mae: 0.1246\n",
      "Epoch 413/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0148 - mae: 0.0995 - val_loss: 0.0250 - val_mae: 0.1339\n",
      "Epoch 414/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0129 - mae: 0.0924 - val_loss: 0.0286 - val_mae: 0.1440\n",
      "Epoch 415/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0220 - mae: 0.1248 - val_loss: 0.0111 - val_mae: 0.0830\n",
      "Epoch 416/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0108 - mae: 0.0835 - val_loss: 0.0105 - val_mae: 0.0820\n",
      "Epoch 417/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0076 - mae: 0.0692 - val_loss: 0.0183 - val_mae: 0.1111\n",
      "Epoch 418/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0133 - mae: 0.0935 - val_loss: 0.0104 - val_mae: 0.0810\n",
      "Epoch 419/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0090 - mae: 0.0753 - val_loss: 0.0119 - val_mae: 0.0867\n",
      "Epoch 420/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0070 - mae: 0.0672 - val_loss: 0.0103 - val_mae: 0.0808\n",
      "Epoch 421/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0073 - mae: 0.0674 - val_loss: 0.0109 - val_mae: 0.0836\n",
      "Epoch 422/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0063 - mae: 0.0628 - val_loss: 0.0109 - val_mae: 0.0841\n",
      "Epoch 423/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0066 - mae: 0.0644 - val_loss: 0.0097 - val_mae: 0.0785\n",
      "Epoch 424/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0062 - mae: 0.0618 - val_loss: 0.0118 - val_mae: 0.0881\n",
      "Epoch 425/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0090 - mae: 0.0769 - val_loss: 0.0147 - val_mae: 0.0984\n",
      "Epoch 426/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0096 - mae: 0.0776 - val_loss: 0.0105 - val_mae: 0.0818\n",
      "Epoch 427/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0083 - mae: 0.0726 - val_loss: 0.0100 - val_mae: 0.0787\n",
      "Epoch 428/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0072 - mae: 0.0663 - val_loss: 0.0126 - val_mae: 0.0894\n",
      "Epoch 429/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0141 - mae: 0.0947 - val_loss: 0.0288 - val_mae: 0.1435\n",
      "Epoch 430/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0173 - mae: 0.1093 - val_loss: 0.0257 - val_mae: 0.1306\n",
      "Epoch 431/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0142 - mae: 0.0964 - val_loss: 0.0192 - val_mae: 0.1135\n",
      "Epoch 432/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0161 - mae: 0.1034 - val_loss: 0.0172 - val_mae: 0.1076\n",
      "Epoch 433/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0147 - mae: 0.0975 - val_loss: 0.0127 - val_mae: 0.0893\n",
      "Epoch 434/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0109 - mae: 0.0829 - val_loss: 0.0117 - val_mae: 0.0861\n",
      "Epoch 435/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0097 - mae: 0.0783 - val_loss: 0.0150 - val_mae: 0.1002\n",
      "Epoch 436/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0113 - mae: 0.0860 - val_loss: 0.0091 - val_mae: 0.0759\n",
      "Epoch 437/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0070 - mae: 0.0658 - val_loss: 0.0087 - val_mae: 0.0729\n",
      "Epoch 438/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0079 - mae: 0.0700 - val_loss: 0.0113 - val_mae: 0.0853\n",
      "Epoch 439/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0068 - mae: 0.0651 - val_loss: 0.0119 - val_mae: 0.0882\n",
      "Epoch 440/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0068 - mae: 0.0658 - val_loss: 0.0096 - val_mae: 0.0760\n",
      "Epoch 441/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0093 - mae: 0.0777 - val_loss: 0.0181 - val_mae: 0.1116\n",
      "Epoch 442/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0112 - mae: 0.0858 - val_loss: 0.0103 - val_mae: 0.0815\n",
      "Epoch 443/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0075 - mae: 0.0688 - val_loss: 0.0092 - val_mae: 0.0761\n",
      "Epoch 444/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0067 - mae: 0.0646 - val_loss: 0.0105 - val_mae: 0.0796\n",
      "Epoch 445/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0076 - mae: 0.0692 - val_loss: 0.0100 - val_mae: 0.0795\n",
      "Epoch 446/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0091 - mae: 0.0763 - val_loss: 0.0104 - val_mae: 0.0816\n",
      "Epoch 447/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0066 - mae: 0.0639 - val_loss: 0.0106 - val_mae: 0.0811\n",
      "Epoch 448/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0091 - mae: 0.0766 - val_loss: 0.0157 - val_mae: 0.1013\n",
      "Epoch 449/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0097 - mae: 0.0790 - val_loss: 0.0112 - val_mae: 0.0842\n",
      "Epoch 450/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0098 - mae: 0.0792 - val_loss: 0.0271 - val_mae: 0.1385\n",
      "Epoch 451/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0184 - mae: 0.1121 - val_loss: 0.0107 - val_mae: 0.0828\n",
      "Epoch 452/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0097 - mae: 0.0788 - val_loss: 0.0132 - val_mae: 0.0911\n",
      "Epoch 453/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0120 - mae: 0.0883 - val_loss: 0.0085 - val_mae: 0.0725\n",
      "Epoch 454/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0108 - mae: 0.0849 - val_loss: 0.0124 - val_mae: 0.0897\n",
      "Epoch 455/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0088 - mae: 0.0750 - val_loss: 0.0178 - val_mae: 0.1104\n",
      "Epoch 456/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0163 - mae: 0.1063 - val_loss: 0.0255 - val_mae: 0.1360\n",
      "Epoch 457/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0152 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1324\n",
      "Epoch 458/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0128 - mae: 0.0905 - val_loss: 0.0126 - val_mae: 0.0891\n",
      "Epoch 459/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0078 - mae: 0.0696 - val_loss: 0.0102 - val_mae: 0.0792\n",
      "Epoch 460/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0080 - mae: 0.0710 - val_loss: 0.0097 - val_mae: 0.0778\n",
      "Epoch 461/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0064 - mae: 0.0634 - val_loss: 0.0097 - val_mae: 0.0780\n",
      "Epoch 462/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0067 - mae: 0.0653 - val_loss: 0.0091 - val_mae: 0.0749\n",
      "Epoch 463/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0066 - mae: 0.0640 - val_loss: 0.0147 - val_mae: 0.0989\n",
      "Epoch 464/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0090 - mae: 0.0770 - val_loss: 0.0111 - val_mae: 0.0846\n",
      "Epoch 465/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0066 - mae: 0.0647 - val_loss: 0.0088 - val_mae: 0.0749\n",
      "Epoch 466/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0060 - mae: 0.0611 - val_loss: 0.0127 - val_mae: 0.0928\n",
      "Epoch 467/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0094 - mae: 0.0784INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 518ms/step - loss: 0.0094 - mae: 0.0784 - val_loss: 0.0082 - val_mae: 0.0718\n",
      "Epoch 468/2000\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0097 - mae: 0.0788 - val_loss: 0.0196 - val_mae: 0.1178\n",
      "Epoch 469/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0157 - mae: 0.1048 - val_loss: 0.0086 - val_mae: 0.0728\n",
      "Epoch 470/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0135 - mae: 0.0947 - val_loss: 0.0117 - val_mae: 0.0867\n",
      "Epoch 471/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0115 - mae: 0.0855 - val_loss: 0.0100 - val_mae: 0.0790\n",
      "Epoch 472/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0077 - mae: 0.0697 - val_loss: 0.0084 - val_mae: 0.0706\n",
      "Epoch 473/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0068 - mae: 0.0654 - val_loss: 0.0101 - val_mae: 0.0789\n",
      "Epoch 474/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0103 - mae: 0.0823 - val_loss: 0.0111 - val_mae: 0.0836\n",
      "Epoch 475/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0079 - mae: 0.0708 - val_loss: 0.0111 - val_mae: 0.0833\n",
      "Epoch 476/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0064 - mae: 0.0633 - val_loss: 0.0130 - val_mae: 0.0903\n",
      "Epoch 477/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0106 - mae: 0.0831 - val_loss: 0.0127 - val_mae: 0.0905\n",
      "Epoch 478/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0069 - mae: 0.0661 - val_loss: 0.0182 - val_mae: 0.1079\n",
      "Epoch 479/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0099 - mae: 0.0793 - val_loss: 0.0471 - val_mae: 0.1920\n",
      "Epoch 480/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0411 - mae: 0.1758 - val_loss: 0.0249 - val_mae: 0.1289\n",
      "Epoch 481/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0265 - mae: 0.1338 - val_loss: 0.0274 - val_mae: 0.1373\n",
      "Epoch 482/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0150 - mae: 0.0980 - val_loss: 0.0113 - val_mae: 0.0845\n",
      "Epoch 483/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0083 - mae: 0.0718 - val_loss: 0.0098 - val_mae: 0.0778\n",
      "Epoch 484/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0076 - mae: 0.0688 - val_loss: 0.0099 - val_mae: 0.0787\n",
      "Epoch 485/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0068 - mae: 0.0651 - val_loss: 0.0088 - val_mae: 0.0731\n",
      "Epoch 486/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0063 - mae: 0.0621INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 501ms/step - loss: 0.0063 - mae: 0.0621 - val_loss: 0.0076 - val_mae: 0.0669\n",
      "Epoch 487/2000\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0061 - mae: 0.0617 - val_loss: 0.0104 - val_mae: 0.0809\n",
      "Epoch 488/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0062 - mae: 0.0624 - val_loss: 0.0079 - val_mae: 0.0696\n",
      "Epoch 489/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0053 - mae: 0.0578 - val_loss: 0.0092 - val_mae: 0.0724\n",
      "Epoch 490/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0057 - mae: 0.0598 - val_loss: 0.0105 - val_mae: 0.0801\n",
      "Epoch 491/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0073 - mae: 0.0675 - val_loss: 0.0223 - val_mae: 0.1253\n",
      "Epoch 492/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0149 - mae: 0.1008 - val_loss: 0.0114 - val_mae: 0.0826\n",
      "Epoch 493/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0133 - mae: 0.0910 - val_loss: 0.0341 - val_mae: 0.1612\n",
      "Epoch 494/2000\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0233 - mae: 0.1272 - val_loss: 0.0306 - val_mae: 0.1480\n",
      "Epoch 495/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0204 - mae: 0.1178 - val_loss: 0.0101 - val_mae: 0.0779\n",
      "Epoch 496/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0127 - mae: 0.0912 - val_loss: 0.0337 - val_mae: 0.1603\n",
      "Epoch 497/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0183 - mae: 0.1125 - val_loss: 0.0095 - val_mae: 0.0787\n",
      "Epoch 498/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0131 - mae: 0.0930 - val_loss: 0.0231 - val_mae: 0.1259\n",
      "Epoch 499/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0205 - mae: 0.1167 - val_loss: 0.0166 - val_mae: 0.1042\n",
      "Epoch 500/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0119 - mae: 0.0892 - val_loss: 0.0108 - val_mae: 0.0813\n",
      "Epoch 501/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0079 - mae: 0.0694 - val_loss: 0.0311 - val_mae: 0.1534\n",
      "Epoch 502/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0183 - mae: 0.1114 - val_loss: 0.0286 - val_mae: 0.1411\n",
      "Epoch 503/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0232 - mae: 0.1265 - val_loss: 0.0348 - val_mae: 0.1596\n",
      "Epoch 504/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0270 - mae: 0.1402 - val_loss: 0.0123 - val_mae: 0.0895\n",
      "Epoch 505/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0237 - mae: 0.1264 - val_loss: 0.0255 - val_mae: 0.1254\n",
      "Epoch 506/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0364 - mae: 0.1566 - val_loss: 0.0614 - val_mae: 0.2214\n",
      "Epoch 507/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0406 - mae: 0.1700 - val_loss: 0.0854 - val_mae: 0.2632\n",
      "Epoch 508/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0562 - mae: 0.2027 - val_loss: 0.0804 - val_mae: 0.2536\n",
      "Epoch 509/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0483 - mae: 0.1837 - val_loss: 0.0294 - val_mae: 0.1418\n",
      "Epoch 510/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0399 - mae: 0.1588 - val_loss: 0.1196 - val_mae: 0.2974\n",
      "Epoch 511/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0944 - mae: 0.2511 - val_loss: 0.0874 - val_mae: 0.2435\n",
      "Epoch 512/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0834 - mae: 0.2324 - val_loss: 0.0697 - val_mae: 0.2140\n",
      "Epoch 513/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0472 - mae: 0.1751 - val_loss: 0.0596 - val_mae: 0.1985\n",
      "Epoch 514/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0382 - mae: 0.1570 - val_loss: 0.0291 - val_mae: 0.1350\n",
      "Epoch 515/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0255 - mae: 0.1266 - val_loss: 0.0200 - val_mae: 0.1127\n",
      "Epoch 516/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0219 - mae: 0.1182 - val_loss: 0.0242 - val_mae: 0.1254\n",
      "Epoch 517/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0225 - mae: 0.1216 - val_loss: 0.0219 - val_mae: 0.1200\n",
      "Epoch 518/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0159 - mae: 0.1020 - val_loss: 0.0303 - val_mae: 0.1446\n",
      "Epoch 519/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0217 - mae: 0.1204 - val_loss: 0.0116 - val_mae: 0.0847\n",
      "Epoch 520/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0152 - mae: 0.0981 - val_loss: 0.0237 - val_mae: 0.1268\n",
      "Epoch 521/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0183 - mae: 0.1100 - val_loss: 0.0518 - val_mae: 0.1956\n",
      "Epoch 522/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0303 - mae: 0.1435 - val_loss: 0.0446 - val_mae: 0.1847\n",
      "Epoch 523/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0198 - mae: 0.1130 - val_loss: 0.0513 - val_mae: 0.1976\n",
      "Epoch 524/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0355 - mae: 0.1562 - val_loss: 0.0444 - val_mae: 0.1798\n",
      "Epoch 525/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0257 - mae: 0.1300 - val_loss: 0.0148 - val_mae: 0.0970\n",
      "Epoch 526/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0121 - mae: 0.0885 - val_loss: 0.0140 - val_mae: 0.0948\n",
      "Epoch 527/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0110 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0830\n",
      "Epoch 528/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0097 - mae: 0.0782 - val_loss: 0.0172 - val_mae: 0.1074\n",
      "Epoch 529/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0097 - mae: 0.0789 - val_loss: 0.0205 - val_mae: 0.1187\n",
      "Epoch 530/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0136 - mae: 0.0938 - val_loss: 0.0102 - val_mae: 0.0801\n",
      "Epoch 531/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0097 - mae: 0.0793 - val_loss: 0.0110 - val_mae: 0.0833\n",
      "Epoch 532/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0075 - mae: 0.0687 - val_loss: 0.0095 - val_mae: 0.0777\n",
      "Epoch 533/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0060 - mae: 0.0619 - val_loss: 0.0097 - val_mae: 0.0783\n",
      "Epoch 534/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0074 - mae: 0.0697 - val_loss: 0.0091 - val_mae: 0.0762\n",
      "Epoch 535/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0063 - mae: 0.0626 - val_loss: 0.0116 - val_mae: 0.0861\n",
      "Epoch 536/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0096 - mae: 0.0776 - val_loss: 0.0217 - val_mae: 0.1208\n",
      "Epoch 537/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0127 - mae: 0.0918 - val_loss: 0.0109 - val_mae: 0.0840\n",
      "Epoch 538/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0074 - mae: 0.0689 - val_loss: 0.0109 - val_mae: 0.0823\n",
      "Epoch 539/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0089 - val_mae: 0.0749\n",
      "Epoch 540/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0057 - mae: 0.0594 - val_loss: 0.0087 - val_mae: 0.0734\n",
      "Epoch 541/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0070 - mae: 0.0673 - val_loss: 0.0160 - val_mae: 0.1055\n",
      "Epoch 542/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0137 - mae: 0.0954 - val_loss: 0.0104 - val_mae: 0.0801\n",
      "Epoch 543/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0063 - mae: 0.0628 - val_loss: 0.0210 - val_mae: 0.1216\n",
      "Epoch 544/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0122 - mae: 0.0896 - val_loss: 0.0118 - val_mae: 0.0858\n",
      "Epoch 545/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0116 - mae: 0.0878 - val_loss: 0.0088 - val_mae: 0.0740\n",
      "Epoch 546/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0081 - mae: 0.0727 - val_loss: 0.0143 - val_mae: 0.0956\n",
      "Epoch 547/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0121 - mae: 0.0889 - val_loss: 0.0116 - val_mae: 0.0862\n",
      "Epoch 548/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0100 - mae: 0.0812 - val_loss: 0.0076 - val_mae: 0.0691\n",
      "Epoch 549/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0084 - mae: 0.0738 - val_loss: 0.0076 - val_mae: 0.0682\n",
      "Epoch 550/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0063 - mae: 0.0623INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 517ms/step - loss: 0.0063 - mae: 0.0623 - val_loss: 0.0071 - val_mae: 0.0657\n",
      "Epoch 551/2000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0059 - mae: 0.0610 - val_loss: 0.0084 - val_mae: 0.0727\n",
      "Epoch 552/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0052 - mae: 0.0572 - val_loss: 0.0087 - val_mae: 0.0735\n",
      "Epoch 553/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0058 - mae: 0.0609 - val_loss: 0.0081 - val_mae: 0.0704\n",
      "Epoch 554/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0052 - mae: 0.0571 - val_loss: 0.0101 - val_mae: 0.0804\n",
      "Epoch 555/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0102 - val_mae: 0.0791\n",
      "Epoch 556/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0065 - mae: 0.0650 - val_loss: 0.0076 - val_mae: 0.0681\n",
      "Epoch 557/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0053 - mae: 0.0582 - val_loss: 0.0094 - val_mae: 0.0765\n",
      "Epoch 558/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0048 - mae: 0.0549 - val_loss: 0.0084 - val_mae: 0.0732\n",
      "Epoch 559/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0108 - val_mae: 0.0835\n",
      "Epoch 560/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0062 - mae: 0.0639 - val_loss: 0.0075 - val_mae: 0.0673\n",
      "Epoch 561/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0099 - mae: 0.0809 - val_loss: 0.0148 - val_mae: 0.0987\n",
      "Epoch 562/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0096 - mae: 0.0803 - val_loss: 0.0092 - val_mae: 0.0760\n",
      "Epoch 563/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0062 - mae: 0.0627 - val_loss: 0.0077 - val_mae: 0.0693\n",
      "Epoch 564/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0065 - mae: 0.0640 - val_loss: 0.0163 - val_mae: 0.1050\n",
      "Epoch 565/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0078 - mae: 0.0706 - val_loss: 0.0083 - val_mae: 0.0707\n",
      "Epoch 566/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0086 - val_mae: 0.0720\n",
      "Epoch 567/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0044 - mae: 0.0534 - val_loss: 0.0097 - val_mae: 0.0766\n",
      "Epoch 568/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0077 - mae: 0.0711 - val_loss: 0.0101 - val_mae: 0.0798\n",
      "Epoch 569/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0124 - mae: 0.0920 - val_loss: 0.0110 - val_mae: 0.0837\n",
      "Epoch 570/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0078 - mae: 0.0708 - val_loss: 0.0090 - val_mae: 0.0750\n",
      "Epoch 571/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0097 - mae: 0.0798 - val_loss: 0.0168 - val_mae: 0.1074\n",
      "Epoch 572/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0101 - mae: 0.0823 - val_loss: 0.0073 - val_mae: 0.0670\n",
      "Epoch 573/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0067 - mae: 0.0653 - val_loss: 0.0086 - val_mae: 0.0725\n",
      "Epoch 574/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0046 - mae: 0.0538 - val_loss: 0.0131 - val_mae: 0.0911\n",
      "Epoch 575/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0072 - mae: 0.0679 - val_loss: 0.0107 - val_mae: 0.0829\n",
      "Epoch 576/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0057 - mae: 0.0602 - val_loss: 0.0096 - val_mae: 0.0765\n",
      "Epoch 577/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0050 - mae: 0.0565 - val_loss: 0.0075 - val_mae: 0.0681\n",
      "Epoch 578/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0041 - mae: 0.0499INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 494ms/step - loss: 0.0041 - mae: 0.0499 - val_loss: 0.0071 - val_mae: 0.0657\n",
      "Epoch 579/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0072 - val_mae: 0.0670\n",
      "Epoch 580/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0073 - val_mae: 0.0670\n",
      "Epoch 581/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0075 - val_mae: 0.0672\n",
      "Epoch 582/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0075 - val_mae: 0.0661\n",
      "Epoch 583/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0071 - val_mae: 0.0653\n",
      "Epoch 584/2000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0461INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 523ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0067 - val_mae: 0.0644\n",
      "Epoch 585/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0462INFO:tensorflow:Assets written to: C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\PARK\\Documents\\LAB\\RNN vs LSTM\\FInal Example\\wandb\\run-20221015_193900-3cszfnio\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 537ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0065 - val_mae: 0.0629\n",
      "Epoch 586/2000\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0049 - mae: 0.0561 - val_loss: 0.0065 - val_mae: 0.0627\n",
      "Epoch 587/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0059 - mae: 0.0626 - val_loss: 0.0081 - val_mae: 0.0698\n",
      "Epoch 588/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0055 - mae: 0.0596 - val_loss: 0.0078 - val_mae: 0.0678\n",
      "Epoch 589/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0076 - val_mae: 0.0672\n",
      "Epoch 590/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0066 - mae: 0.0659 - val_loss: 0.0072 - val_mae: 0.0669\n",
      "Epoch 591/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0093 - val_mae: 0.0765\n",
      "Epoch 592/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0066 - mae: 0.0660 - val_loss: 0.0075 - val_mae: 0.0678\n",
      "Epoch 593/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0067 - val_mae: 0.0644\n",
      "Epoch 594/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0071 - val_mae: 0.0660\n",
      "Epoch 595/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0069 - val_mae: 0.0635\n",
      "Epoch 596/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0105 - val_mae: 0.0827\n",
      "Epoch 597/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0066 - mae: 0.0660 - val_loss: 0.0289 - val_mae: 0.1502\n",
      "Epoch 598/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0180 - mae: 0.1137 - val_loss: 0.0155 - val_mae: 0.1021\n",
      "Epoch 599/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0203 - mae: 0.1190 - val_loss: 0.0200 - val_mae: 0.1164\n",
      "Epoch 600/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0124 - mae: 0.0903 - val_loss: 0.0163 - val_mae: 0.1023\n",
      "Epoch 601/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0100 - mae: 0.0820 - val_loss: 0.0225 - val_mae: 0.1287\n",
      "Epoch 602/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0126 - mae: 0.0929 - val_loss: 0.0139 - val_mae: 0.0954\n",
      "Epoch 603/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0134 - mae: 0.0953 - val_loss: 0.0405 - val_mae: 0.1768\n",
      "Epoch 604/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0312 - mae: 0.1481 - val_loss: 0.0417 - val_mae: 0.1816\n",
      "Epoch 605/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0259 - mae: 0.1369 - val_loss: 0.0096 - val_mae: 0.0778\n",
      "Epoch 606/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0121 - mae: 0.0887 - val_loss: 0.0191 - val_mae: 0.1143\n",
      "Epoch 607/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.4585 - mae: 0.3565 - val_loss: 0.2269 - val_mae: 0.3949\n",
      "Epoch 608/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.4869 - mae: 0.5363 - val_loss: 0.5295 - val_mae: 0.6077\n",
      "Epoch 609/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.4188 - mae: 0.5129 - val_loss: 0.3094 - val_mae: 0.4403\n",
      "Epoch 610/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.3222 - mae: 0.4501 - val_loss: 0.3273 - val_mae: 0.4672\n",
      "Epoch 611/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.2860 - mae: 0.4263 - val_loss: 0.1857 - val_mae: 0.3528\n",
      "Epoch 612/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2290 - mae: 0.3807 - val_loss: 0.1794 - val_mae: 0.3447\n",
      "Epoch 613/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2046 - mae: 0.3612 - val_loss: 0.1735 - val_mae: 0.3329\n",
      "Epoch 614/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1702 - mae: 0.3266 - val_loss: 0.1961 - val_mae: 0.3621\n",
      "Epoch 615/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1734 - mae: 0.3340 - val_loss: 0.1178 - val_mae: 0.2762\n",
      "Epoch 616/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.3353 - mae: 0.4588 - val_loss: 0.6723 - val_mae: 0.7308\n",
      "Epoch 617/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.4242 - mae: 0.5276 - val_loss: 0.3430 - val_mae: 0.4817\n",
      "Epoch 618/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.3062 - mae: 0.4314 - val_loss: 0.2607 - val_mae: 0.4179\n",
      "Epoch 619/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.2440 - mae: 0.3974 - val_loss: 0.1870 - val_mae: 0.3578\n",
      "Epoch 620/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2117 - mae: 0.3702 - val_loss: 0.1687 - val_mae: 0.3418\n",
      "Epoch 621/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1919 - mae: 0.3557 - val_loss: 0.1955 - val_mae: 0.3634\n",
      "Epoch 622/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1819 - mae: 0.3451 - val_loss: 0.1528 - val_mae: 0.3257\n",
      "Epoch 623/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1851 - mae: 0.3473 - val_loss: 0.2722 - val_mae: 0.4314\n",
      "Epoch 624/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2017 - mae: 0.3574 - val_loss: 0.1889 - val_mae: 0.3588\n",
      "Epoch 625/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2056 - mae: 0.3663 - val_loss: 0.2072 - val_mae: 0.3741\n",
      "Epoch 626/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.2070 - mae: 0.3682 - val_loss: 0.2057 - val_mae: 0.3710\n",
      "Epoch 627/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1753 - mae: 0.3343 - val_loss: 0.1348 - val_mae: 0.3048\n",
      "Epoch 628/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1488 - mae: 0.3113 - val_loss: 0.1268 - val_mae: 0.2954\n",
      "Epoch 629/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1460 - mae: 0.3075 - val_loss: 0.1738 - val_mae: 0.3392\n",
      "Epoch 630/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1794 - mae: 0.3442 - val_loss: 0.1299 - val_mae: 0.2953\n",
      "Epoch 631/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1316 - mae: 0.2916 - val_loss: 0.1109 - val_mae: 0.2709\n",
      "Epoch 632/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1874 - mae: 0.3329 - val_loss: 0.1457 - val_mae: 0.3123\n",
      "Epoch 633/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.2085 - mae: 0.3660 - val_loss: 0.1806 - val_mae: 0.3518\n",
      "Epoch 634/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1921 - mae: 0.3579 - val_loss: 0.1750 - val_mae: 0.3454\n",
      "Epoch 635/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1872 - mae: 0.3493 - val_loss: 0.1758 - val_mae: 0.3448\n",
      "Epoch 636/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.1901 - mae: 0.3526 - val_loss: 0.1649 - val_mae: 0.3365\n",
      "Epoch 637/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1875 - mae: 0.3495 - val_loss: 0.2121 - val_mae: 0.3760\n",
      "Epoch 638/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2117 - mae: 0.3704 - val_loss: 0.1441 - val_mae: 0.3170\n",
      "Epoch 639/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1518 - mae: 0.3213 - val_loss: 0.1471 - val_mae: 0.3142\n",
      "Epoch 640/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1555 - mae: 0.3180 - val_loss: 0.1404 - val_mae: 0.3089\n",
      "Epoch 641/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1601 - mae: 0.3243 - val_loss: 0.2062 - val_mae: 0.3718\n",
      "Epoch 642/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1882 - mae: 0.3505 - val_loss: 0.1887 - val_mae: 0.3575\n",
      "Epoch 643/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2226 - mae: 0.3887 - val_loss: 0.2022 - val_mae: 0.3675\n",
      "Epoch 644/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2192 - mae: 0.3765 - val_loss: 0.2774 - val_mae: 0.4316\n",
      "Epoch 645/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.2362 - mae: 0.3886 - val_loss: 0.1570 - val_mae: 0.3279\n",
      "Epoch 646/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1876 - mae: 0.3456 - val_loss: 0.1301 - val_mae: 0.2977\n",
      "Epoch 647/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1599 - mae: 0.3240 - val_loss: 0.1416 - val_mae: 0.3086\n",
      "Epoch 648/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2066 - mae: 0.3665 - val_loss: 0.1591 - val_mae: 0.3286\n",
      "Epoch 649/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.1892 - mae: 0.3515 - val_loss: 0.1638 - val_mae: 0.3252\n",
      "Epoch 650/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2279 - mae: 0.3834 - val_loss: 0.1624 - val_mae: 0.3331\n",
      "Epoch 651/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2549 - mae: 0.4073 - val_loss: 0.1738 - val_mae: 0.3428\n",
      "Epoch 652/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.2069 - mae: 0.3735 - val_loss: 0.2603 - val_mae: 0.4094\n",
      "Epoch 653/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2466 - mae: 0.4073 - val_loss: 0.2073 - val_mae: 0.3696\n",
      "Epoch 654/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2390 - mae: 0.3974 - val_loss: 0.2021 - val_mae: 0.3668\n",
      "Epoch 655/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1881 - mae: 0.3490 - val_loss: 0.1996 - val_mae: 0.3683\n",
      "Epoch 656/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1877 - mae: 0.3532 - val_loss: 0.2240 - val_mae: 0.3924\n",
      "Epoch 657/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2039 - mae: 0.3625 - val_loss: 0.1870 - val_mae: 0.3572\n",
      "Epoch 658/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2009 - mae: 0.3609 - val_loss: 0.1369 - val_mae: 0.3032\n",
      "Epoch 659/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1758 - mae: 0.3396 - val_loss: 0.1413 - val_mae: 0.3029\n",
      "Epoch 660/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.1511 - mae: 0.3102 - val_loss: 0.1242 - val_mae: 0.2881\n",
      "Epoch 661/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1315 - mae: 0.2894 - val_loss: 0.1130 - val_mae: 0.2724\n",
      "Epoch 662/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1288 - mae: 0.2875 - val_loss: 0.0947 - val_mae: 0.2482\n",
      "Epoch 663/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1106 - mae: 0.2627 - val_loss: 0.0988 - val_mae: 0.2505\n",
      "Epoch 664/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1505 - mae: 0.3167 - val_loss: 0.2490 - val_mae: 0.4200\n",
      "Epoch 665/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.2294 - mae: 0.3958 - val_loss: 0.1436 - val_mae: 0.3106\n",
      "Epoch 666/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1736 - mae: 0.3431 - val_loss: 0.1636 - val_mae: 0.3317\n",
      "Epoch 667/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1450 - mae: 0.3057 - val_loss: 0.1076 - val_mae: 0.2688\n",
      "Epoch 668/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1552 - mae: 0.3174 - val_loss: 0.1664 - val_mae: 0.3285\n",
      "Epoch 669/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1457 - mae: 0.3062 - val_loss: 0.1400 - val_mae: 0.3020\n",
      "Epoch 670/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1122 - mae: 0.2659 - val_loss: 0.1081 - val_mae: 0.2693\n",
      "Epoch 671/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1183 - mae: 0.2762 - val_loss: 0.0958 - val_mae: 0.2450\n",
      "Epoch 672/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1392 - mae: 0.2987 - val_loss: 0.0904 - val_mae: 0.2424\n",
      "Epoch 673/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1722 - mae: 0.3354 - val_loss: 0.2129 - val_mae: 0.3877\n",
      "Epoch 674/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1944 - mae: 0.3572 - val_loss: 0.3072 - val_mae: 0.4726\n",
      "Epoch 675/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.1879 - mae: 0.3486 - val_loss: 0.1607 - val_mae: 0.3297\n",
      "Epoch 676/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1518 - mae: 0.3152 - val_loss: 0.1185 - val_mae: 0.2788\n",
      "Epoch 677/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1088 - mae: 0.2595 - val_loss: 0.1114 - val_mae: 0.2718\n",
      "Epoch 678/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1049 - mae: 0.2562 - val_loss: 0.0741 - val_mae: 0.2152\n",
      "Epoch 679/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0886 - mae: 0.2334 - val_loss: 0.0900 - val_mae: 0.2458\n",
      "Epoch 680/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1130 - mae: 0.2681 - val_loss: 0.0734 - val_mae: 0.2130\n",
      "Epoch 681/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0900 - mae: 0.2379 - val_loss: 0.0743 - val_mae: 0.2146\n",
      "Epoch 682/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1084 - mae: 0.2647 - val_loss: 0.0734 - val_mae: 0.2122\n",
      "Epoch 683/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1098 - mae: 0.2631 - val_loss: 0.0785 - val_mae: 0.2205\n",
      "Epoch 684/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0976 - mae: 0.2478 - val_loss: 0.0906 - val_mae: 0.2338\n",
      "Epoch 685/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0855 - mae: 0.2280 - val_loss: 0.0662 - val_mae: 0.2038\n",
      "Epoch 686/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0956 - mae: 0.2465 - val_loss: 0.0941 - val_mae: 0.2368\n",
      "Epoch 687/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1019 - mae: 0.2516 - val_loss: 0.0890 - val_mae: 0.2387\n",
      "Epoch 688/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0944 - mae: 0.2427 - val_loss: 0.1042 - val_mae: 0.2551\n",
      "Epoch 689/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0902 - mae: 0.2349 - val_loss: 0.0707 - val_mae: 0.2119\n",
      "Epoch 690/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0831 - mae: 0.2287 - val_loss: 0.0827 - val_mae: 0.2286\n",
      "Epoch 691/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0875 - mae: 0.2334 - val_loss: 0.0733 - val_mae: 0.2107\n",
      "Epoch 692/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0811 - mae: 0.2238 - val_loss: 0.1312 - val_mae: 0.2850\n",
      "Epoch 693/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1127 - mae: 0.2670 - val_loss: 0.1094 - val_mae: 0.2638\n",
      "Epoch 694/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0958 - mae: 0.2430 - val_loss: 0.0952 - val_mae: 0.2519\n",
      "Epoch 695/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1052 - mae: 0.2599 - val_loss: 0.0760 - val_mae: 0.2145\n",
      "Epoch 696/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0791 - mae: 0.2198 - val_loss: 0.1020 - val_mae: 0.2664\n",
      "Epoch 697/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1536 - mae: 0.3160 - val_loss: 0.1029 - val_mae: 0.2570\n",
      "Epoch 698/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1389 - mae: 0.3002 - val_loss: 0.0953 - val_mae: 0.2495\n",
      "Epoch 699/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0986 - mae: 0.2499 - val_loss: 0.0933 - val_mae: 0.2395\n",
      "Epoch 700/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0950 - mae: 0.2406 - val_loss: 0.0680 - val_mae: 0.2076\n",
      "Epoch 701/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0823 - mae: 0.2278 - val_loss: 0.0846 - val_mae: 0.2251\n",
      "Epoch 702/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0918 - mae: 0.2398 - val_loss: 0.0765 - val_mae: 0.2213\n",
      "Epoch 703/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0834 - mae: 0.2269 - val_loss: 0.0686 - val_mae: 0.2079\n",
      "Epoch 704/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0782 - mae: 0.2180 - val_loss: 0.0640 - val_mae: 0.1973\n",
      "Epoch 705/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0865 - mae: 0.2282 - val_loss: 0.0710 - val_mae: 0.2052\n",
      "Epoch 706/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0928 - mae: 0.2394 - val_loss: 0.0876 - val_mae: 0.2443\n",
      "Epoch 707/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0856 - mae: 0.2318 - val_loss: 0.1059 - val_mae: 0.2531\n",
      "Epoch 708/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.1079 - mae: 0.2624 - val_loss: 0.1082 - val_mae: 0.2785\n",
      "Epoch 709/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0973 - mae: 0.2489 - val_loss: 0.0839 - val_mae: 0.2295\n",
      "Epoch 710/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0854 - mae: 0.2328 - val_loss: 0.0955 - val_mae: 0.2392\n",
      "Epoch 711/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0763 - mae: 0.2181 - val_loss: 0.0723 - val_mae: 0.2167\n",
      "Epoch 712/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0797 - mae: 0.2219 - val_loss: 0.0772 - val_mae: 0.2238\n",
      "Epoch 713/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0888 - mae: 0.2383 - val_loss: 0.1215 - val_mae: 0.2816\n",
      "Epoch 714/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0933 - mae: 0.2413 - val_loss: 0.0746 - val_mae: 0.2201\n",
      "Epoch 715/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0983 - mae: 0.2513 - val_loss: 0.1220 - val_mae: 0.2777\n",
      "Epoch 716/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1171 - mae: 0.2762 - val_loss: 0.0884 - val_mae: 0.2326\n",
      "Epoch 717/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1181 - mae: 0.2776 - val_loss: 0.1642 - val_mae: 0.3383\n",
      "Epoch 718/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1341 - mae: 0.2961 - val_loss: 0.1113 - val_mae: 0.2729\n",
      "Epoch 719/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1101 - mae: 0.2655 - val_loss: 0.0686 - val_mae: 0.2035\n",
      "Epoch 720/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0971 - mae: 0.2460 - val_loss: 0.0847 - val_mae: 0.2256\n",
      "Epoch 721/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0917 - mae: 0.2374 - val_loss: 0.1094 - val_mae: 0.2754\n",
      "Epoch 722/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1017 - mae: 0.2556 - val_loss: 0.1276 - val_mae: 0.2924\n",
      "Epoch 723/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1211 - mae: 0.2816 - val_loss: 0.1717 - val_mae: 0.3485\n",
      "Epoch 724/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1337 - mae: 0.2992 - val_loss: 0.1252 - val_mae: 0.2895\n",
      "Epoch 725/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1034 - mae: 0.2570 - val_loss: 0.1269 - val_mae: 0.2838\n",
      "Epoch 726/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1042 - mae: 0.2578 - val_loss: 0.0650 - val_mae: 0.2047\n",
      "Epoch 727/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0802 - mae: 0.2220 - val_loss: 0.0681 - val_mae: 0.2029\n",
      "Epoch 728/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0832 - mae: 0.2273 - val_loss: 0.0869 - val_mae: 0.2288\n",
      "Epoch 729/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0867 - mae: 0.2309 - val_loss: 0.0753 - val_mae: 0.2108\n",
      "Epoch 730/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0870 - mae: 0.2350 - val_loss: 0.0753 - val_mae: 0.2216\n",
      "Epoch 731/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0775 - mae: 0.2184 - val_loss: 0.0879 - val_mae: 0.2309\n",
      "Epoch 732/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0776 - mae: 0.2173 - val_loss: 0.0688 - val_mae: 0.2037\n",
      "Epoch 733/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0744 - mae: 0.2138 - val_loss: 0.0803 - val_mae: 0.2165\n",
      "Epoch 734/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0746 - mae: 0.2131 - val_loss: 0.0684 - val_mae: 0.2049\n",
      "Epoch 735/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0729 - mae: 0.2097 - val_loss: 0.0668 - val_mae: 0.2001\n",
      "Epoch 736/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0698 - mae: 0.2074 - val_loss: 0.0636 - val_mae: 0.1953\n",
      "Epoch 737/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0719 - mae: 0.2083 - val_loss: 0.0889 - val_mae: 0.2448\n",
      "Epoch 738/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0917 - mae: 0.2427 - val_loss: 0.0851 - val_mae: 0.2294\n",
      "Epoch 739/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0799 - mae: 0.2222 - val_loss: 0.0729 - val_mae: 0.2098\n",
      "Epoch 740/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0751 - mae: 0.2124 - val_loss: 0.0793 - val_mae: 0.2256\n",
      "Epoch 741/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0862 - mae: 0.2335 - val_loss: 0.0817 - val_mae: 0.2289\n",
      "Epoch 742/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0799 - mae: 0.2223 - val_loss: 0.0702 - val_mae: 0.2033\n",
      "Epoch 743/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0756 - mae: 0.2148 - val_loss: 0.0696 - val_mae: 0.2052\n",
      "Epoch 744/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0721 - mae: 0.2101 - val_loss: 0.0947 - val_mae: 0.2394\n",
      "Epoch 745/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0771 - mae: 0.2157 - val_loss: 0.0698 - val_mae: 0.2073\n",
      "Epoch 746/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0765 - mae: 0.2167 - val_loss: 0.0713 - val_mae: 0.2154\n",
      "Epoch 747/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0832 - mae: 0.2281 - val_loss: 0.0625 - val_mae: 0.1927\n",
      "Epoch 748/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0697 - mae: 0.2065 - val_loss: 0.0788 - val_mae: 0.2153\n",
      "Epoch 749/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0750 - mae: 0.2138 - val_loss: 0.0805 - val_mae: 0.2322\n",
      "Epoch 750/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0844 - mae: 0.2302 - val_loss: 0.0755 - val_mae: 0.2128\n",
      "Epoch 751/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0864 - mae: 0.2352 - val_loss: 0.0962 - val_mae: 0.2399\n",
      "Epoch 752/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0809 - mae: 0.2248 - val_loss: 0.0760 - val_mae: 0.2176\n",
      "Epoch 753/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0781 - mae: 0.2180 - val_loss: 0.0806 - val_mae: 0.2302\n",
      "Epoch 754/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0850 - mae: 0.2308 - val_loss: 0.0723 - val_mae: 0.2071\n",
      "Epoch 755/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0813 - mae: 0.2260 - val_loss: 0.1014 - val_mae: 0.2544\n",
      "Epoch 756/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0880 - mae: 0.2362 - val_loss: 0.0702 - val_mae: 0.2088\n",
      "Epoch 757/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0748 - mae: 0.2148 - val_loss: 0.0668 - val_mae: 0.1983\n",
      "Epoch 758/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0776 - mae: 0.2198 - val_loss: 0.1097 - val_mae: 0.2560\n",
      "Epoch 759/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0880 - mae: 0.2354 - val_loss: 0.0729 - val_mae: 0.2146\n",
      "Epoch 760/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0792 - mae: 0.2209 - val_loss: 0.0674 - val_mae: 0.2030\n",
      "Epoch 761/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0818 - mae: 0.2255 - val_loss: 0.0718 - val_mae: 0.2057\n",
      "Epoch 762/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0691 - mae: 0.2050 - val_loss: 0.0674 - val_mae: 0.1985\n",
      "Epoch 763/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0726 - mae: 0.2115 - val_loss: 0.0647 - val_mae: 0.1985\n",
      "Epoch 764/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0726 - mae: 0.2122 - val_loss: 0.0716 - val_mae: 0.2052\n",
      "Epoch 765/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0760 - mae: 0.2155 - val_loss: 0.0794 - val_mae: 0.2178\n",
      "Epoch 766/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0913 - mae: 0.2370 - val_loss: 0.0706 - val_mae: 0.2048\n",
      "Epoch 767/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0912 - mae: 0.2409 - val_loss: 0.0906 - val_mae: 0.2326\n",
      "Epoch 768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0845 - mae: 0.2277 - val_loss: 0.0826 - val_mae: 0.2289\n",
      "Epoch 769/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0754 - mae: 0.2176 - val_loss: 0.0753 - val_mae: 0.2134\n",
      "Epoch 770/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0779 - mae: 0.2187 - val_loss: 0.0684 - val_mae: 0.2042\n",
      "Epoch 771/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0844 - mae: 0.2290 - val_loss: 0.0820 - val_mae: 0.2213\n",
      "Epoch 772/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0767 - mae: 0.2186 - val_loss: 0.0732 - val_mae: 0.2147\n",
      "Epoch 773/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0756 - mae: 0.2171 - val_loss: 0.0785 - val_mae: 0.2151\n",
      "Epoch 774/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0926 - mae: 0.2392 - val_loss: 0.0671 - val_mae: 0.2014\n",
      "Epoch 775/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0714 - mae: 0.2109 - val_loss: 0.0715 - val_mae: 0.2032\n",
      "Epoch 776/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0709 - mae: 0.2050 - val_loss: 0.0727 - val_mae: 0.2178\n",
      "Epoch 777/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0769 - mae: 0.2222 - val_loss: 0.0712 - val_mae: 0.2040\n",
      "Epoch 778/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0717 - mae: 0.2086 - val_loss: 0.0717 - val_mae: 0.2059\n",
      "Epoch 779/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0719 - mae: 0.2078 - val_loss: 0.0731 - val_mae: 0.2114\n",
      "Epoch 780/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0736 - mae: 0.2123 - val_loss: 0.0647 - val_mae: 0.1954\n",
      "Epoch 781/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0693 - mae: 0.2042 - val_loss: 0.0713 - val_mae: 0.2039\n",
      "Epoch 782/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0702 - mae: 0.2049 - val_loss: 0.0740 - val_mae: 0.2089\n",
      "Epoch 783/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0713 - mae: 0.2087 - val_loss: 0.0725 - val_mae: 0.2113\n",
      "Epoch 784/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0707 - mae: 0.2057 - val_loss: 0.0639 - val_mae: 0.1967\n",
      "Epoch 785/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0705 - mae: 0.2083 - val_loss: 0.0666 - val_mae: 0.2009\n",
      "Epoch 786/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0819 - mae: 0.2232 - val_loss: 0.0913 - val_mae: 0.2381\n",
      "Epoch 787/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0818 - mae: 0.2269 - val_loss: 0.1004 - val_mae: 0.2442\n",
      "Epoch 788/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0907 - mae: 0.2391 - val_loss: 0.0885 - val_mae: 0.2447\n",
      "Epoch 789/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0911 - mae: 0.2389 - val_loss: 0.0947 - val_mae: 0.2385\n",
      "Epoch 790/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0798 - mae: 0.2224 - val_loss: 0.0760 - val_mae: 0.2197\n",
      "Epoch 791/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0742 - mae: 0.2171 - val_loss: 0.0790 - val_mae: 0.2187\n",
      "Epoch 792/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0746 - mae: 0.2134 - val_loss: 0.0796 - val_mae: 0.2118\n",
      "Epoch 793/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0731 - mae: 0.2117 - val_loss: 0.0700 - val_mae: 0.2105\n",
      "Epoch 794/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0757 - mae: 0.2155 - val_loss: 0.0628 - val_mae: 0.1965\n",
      "Epoch 795/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0757 - mae: 0.2154 - val_loss: 0.0921 - val_mae: 0.2363\n",
      "Epoch 796/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0799 - mae: 0.2206 - val_loss: 0.0682 - val_mae: 0.2040\n",
      "Epoch 797/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0688 - mae: 0.2038 - val_loss: 0.0709 - val_mae: 0.2022\n",
      "Epoch 798/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0668 - mae: 0.2006 - val_loss: 0.0651 - val_mae: 0.1983\n",
      "Epoch 799/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0720 - mae: 0.2071 - val_loss: 0.1090 - val_mae: 0.2585\n",
      "Epoch 800/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0852 - mae: 0.2292 - val_loss: 0.1047 - val_mae: 0.2562\n",
      "Epoch 801/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0925 - mae: 0.2381 - val_loss: 0.0974 - val_mae: 0.2577\n",
      "Epoch 802/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0897 - mae: 0.2389 - val_loss: 0.0805 - val_mae: 0.2313\n",
      "Epoch 803/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0889 - mae: 0.2368 - val_loss: 0.1439 - val_mae: 0.3108\n",
      "Epoch 804/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1368 - mae: 0.3010 - val_loss: 0.1926 - val_mae: 0.3617\n",
      "Epoch 805/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1357 - mae: 0.2965 - val_loss: 0.0997 - val_mae: 0.2513\n",
      "Epoch 806/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0921 - mae: 0.2438 - val_loss: 0.0791 - val_mae: 0.2175\n",
      "Epoch 807/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0911 - mae: 0.2397 - val_loss: 0.0782 - val_mae: 0.2245\n",
      "Epoch 808/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0860 - mae: 0.2311 - val_loss: 0.0755 - val_mae: 0.2153\n",
      "Epoch 809/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0781 - mae: 0.2157 - val_loss: 0.0744 - val_mae: 0.2169\n",
      "Epoch 810/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0942 - mae: 0.2435 - val_loss: 0.1631 - val_mae: 0.3347\n",
      "Epoch 811/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1542 - mae: 0.3274 - val_loss: 0.1007 - val_mae: 0.2528\n",
      "Epoch 812/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0931 - mae: 0.2409 - val_loss: 0.0733 - val_mae: 0.2238\n",
      "Epoch 813/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0813 - mae: 0.2261 - val_loss: 0.0660 - val_mae: 0.2000\n",
      "Epoch 814/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0710 - mae: 0.2089 - val_loss: 0.0701 - val_mae: 0.2064\n",
      "Epoch 815/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0698 - mae: 0.2047 - val_loss: 0.0741 - val_mae: 0.2081\n",
      "Epoch 816/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0672 - mae: 0.2018 - val_loss: 0.0785 - val_mae: 0.2176\n",
      "Epoch 817/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0733 - mae: 0.2137 - val_loss: 0.0669 - val_mae: 0.1990\n",
      "Epoch 818/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0696 - mae: 0.2060 - val_loss: 0.0606 - val_mae: 0.1922\n",
      "Epoch 819/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0703 - mae: 0.2061 - val_loss: 0.0610 - val_mae: 0.1955\n",
      "Epoch 820/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0768 - mae: 0.2174 - val_loss: 0.0858 - val_mae: 0.2247\n",
      "Epoch 821/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0723 - mae: 0.2082 - val_loss: 0.0915 - val_mae: 0.2359\n",
      "Epoch 822/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0847 - mae: 0.2280 - val_loss: 0.0892 - val_mae: 0.2423\n",
      "Epoch 823/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0969 - mae: 0.2505 - val_loss: 0.0792 - val_mae: 0.2289\n",
      "Epoch 824/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0770 - mae: 0.2172 - val_loss: 0.0627 - val_mae: 0.1935\n",
      "Epoch 825/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0764 - mae: 0.2176 - val_loss: 0.0850 - val_mae: 0.2247\n",
      "Epoch 826/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0739 - mae: 0.2125 - val_loss: 0.0672 - val_mae: 0.2020\n",
      "Epoch 827/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0656 - mae: 0.1986 - val_loss: 0.0712 - val_mae: 0.2040\n",
      "Epoch 828/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0713 - mae: 0.2059 - val_loss: 0.0635 - val_mae: 0.1977\n",
      "Epoch 829/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0717 - mae: 0.2085 - val_loss: 0.0624 - val_mae: 0.1973\n",
      "Epoch 830/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0694 - mae: 0.2052 - val_loss: 0.0604 - val_mae: 0.1900\n",
      "Epoch 831/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0685 - mae: 0.2034 - val_loss: 0.1035 - val_mae: 0.2442\n",
      "Epoch 832/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0759 - mae: 0.2168 - val_loss: 0.0626 - val_mae: 0.1999\n",
      "Epoch 833/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0724 - mae: 0.2094 - val_loss: 0.1008 - val_mae: 0.2512\n",
      "Epoch 834/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0800 - mae: 0.2214 - val_loss: 0.0645 - val_mae: 0.2023\n",
      "Epoch 835/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0725 - mae: 0.2108 - val_loss: 0.0766 - val_mae: 0.2098\n",
      "Epoch 836/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0708 - mae: 0.2059 - val_loss: 0.0874 - val_mae: 0.2384\n",
      "Epoch 837/2000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0804 - mae: 0.2234 - val_loss: 0.0719 - val_mae: 0.2148\n",
      "Epoch 838/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0725 - mae: 0.2103 - val_loss: 0.0671 - val_mae: 0.1966\n",
      "Epoch 839/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0683 - mae: 0.2008 - val_loss: 0.0738 - val_mae: 0.2105\n",
      "Epoch 840/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0689 - mae: 0.2049 - val_loss: 0.0662 - val_mae: 0.2043\n",
      "Epoch 841/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0674 - mae: 0.2030 - val_loss: 0.0865 - val_mae: 0.2262\n",
      "Epoch 842/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0741 - mae: 0.2125 - val_loss: 0.1063 - val_mae: 0.2548\n",
      "Epoch 843/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0792 - mae: 0.2199 - val_loss: 0.0730 - val_mae: 0.2162\n",
      "Epoch 844/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0905 - mae: 0.2381 - val_loss: 0.0782 - val_mae: 0.2242\n",
      "Epoch 845/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0787 - mae: 0.2183 - val_loss: 0.0740 - val_mae: 0.2178\n",
      "Epoch 846/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0794 - mae: 0.2210 - val_loss: 0.0688 - val_mae: 0.2091\n",
      "Epoch 847/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0738 - mae: 0.2130 - val_loss: 0.0826 - val_mae: 0.2218\n",
      "Epoch 848/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0812 - mae: 0.2224 - val_loss: 0.0793 - val_mae: 0.2147\n",
      "Epoch 849/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0764 - mae: 0.2161 - val_loss: 0.0666 - val_mae: 0.2059\n",
      "Epoch 850/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0710 - mae: 0.2060 - val_loss: 0.0760 - val_mae: 0.2128\n",
      "Epoch 851/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0709 - mae: 0.2080 - val_loss: 0.0894 - val_mae: 0.2276\n",
      "Epoch 852/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0763 - mae: 0.2167 - val_loss: 0.0695 - val_mae: 0.2042\n",
      "Epoch 853/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0731 - mae: 0.2119 - val_loss: 0.0668 - val_mae: 0.2029\n",
      "Epoch 854/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0677 - mae: 0.2048 - val_loss: 0.0931 - val_mae: 0.2329\n",
      "Epoch 855/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0722 - mae: 0.2086 - val_loss: 0.0589 - val_mae: 0.1864\n",
      "Epoch 856/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0634 - mae: 0.1961 - val_loss: 0.0666 - val_mae: 0.2003\n",
      "Epoch 857/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0679 - mae: 0.2031 - val_loss: 0.0779 - val_mae: 0.2123\n",
      "Epoch 858/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0669 - mae: 0.2004 - val_loss: 0.0769 - val_mae: 0.2137\n",
      "Epoch 859/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0694 - mae: 0.2031 - val_loss: 0.0692 - val_mae: 0.2094\n",
      "Epoch 860/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0701 - mae: 0.2076 - val_loss: 0.0736 - val_mae: 0.2085\n",
      "Epoch 861/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0649 - mae: 0.1968 - val_loss: 0.0658 - val_mae: 0.1934\n",
      "Epoch 862/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0649 - mae: 0.1961 - val_loss: 0.0690 - val_mae: 0.2116\n",
      "Epoch 863/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0713 - mae: 0.2104 - val_loss: 0.0786 - val_mae: 0.2181\n",
      "Epoch 864/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0676 - mae: 0.2047 - val_loss: 0.0664 - val_mae: 0.1996\n",
      "Epoch 865/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0641 - mae: 0.1945 - val_loss: 0.0596 - val_mae: 0.1870\n",
      "Epoch 866/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0675 - mae: 0.2012 - val_loss: 0.0814 - val_mae: 0.2204\n",
      "Epoch 867/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0706 - mae: 0.2048 - val_loss: 0.0679 - val_mae: 0.1999\n",
      "Epoch 868/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0783 - mae: 0.2230 - val_loss: 0.1409 - val_mae: 0.3228\n",
      "Epoch 869/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1108 - mae: 0.2696 - val_loss: 0.0725 - val_mae: 0.2092\n",
      "Epoch 870/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0853 - mae: 0.2326 - val_loss: 0.1009 - val_mae: 0.2524\n",
      "Epoch 871/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0789 - mae: 0.2225 - val_loss: 0.0879 - val_mae: 0.2248\n",
      "Epoch 872/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0700 - mae: 0.2082 - val_loss: 0.0680 - val_mae: 0.2042\n",
      "Epoch 873/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0758 - mae: 0.2166 - val_loss: 0.0723 - val_mae: 0.2181\n",
      "Epoch 874/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0717 - mae: 0.2110 - val_loss: 0.0665 - val_mae: 0.2068\n",
      "Epoch 875/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0698 - mae: 0.2073 - val_loss: 0.0755 - val_mae: 0.2101\n",
      "Epoch 876/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0655 - mae: 0.2010 - val_loss: 0.0686 - val_mae: 0.2003\n",
      "Epoch 877/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0674 - mae: 0.1978 - val_loss: 0.0625 - val_mae: 0.1983\n",
      "Epoch 878/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0625 - mae: 0.1937 - val_loss: 0.0623 - val_mae: 0.1914\n",
      "Epoch 879/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0639 - mae: 0.1942 - val_loss: 0.0744 - val_mae: 0.2217\n",
      "Epoch 880/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0816 - mae: 0.2283 - val_loss: 0.0969 - val_mae: 0.2361\n",
      "Epoch 881/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0759 - mae: 0.2113 - val_loss: 0.0647 - val_mae: 0.2007\n",
      "Epoch 882/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0703 - mae: 0.2075 - val_loss: 0.0651 - val_mae: 0.1988\n",
      "Epoch 883/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0674 - mae: 0.2029 - val_loss: 0.1008 - val_mae: 0.2490\n",
      "Epoch 884/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0748 - mae: 0.2140 - val_loss: 0.0928 - val_mae: 0.2452\n",
      "Epoch 885/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0880 - mae: 0.2341 - val_loss: 0.0875 - val_mae: 0.2390\n",
      "Epoch 886/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0975 - mae: 0.2512 - val_loss: 0.1291 - val_mae: 0.2827\n",
      "Epoch 887/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1154 - mae: 0.2679 - val_loss: 0.0812 - val_mae: 0.2350\n",
      "Epoch 888/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0979 - mae: 0.2531 - val_loss: 0.0698 - val_mae: 0.2090\n",
      "Epoch 889/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0714 - mae: 0.2103 - val_loss: 0.0747 - val_mae: 0.2163\n",
      "Epoch 890/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0682 - mae: 0.2051 - val_loss: 0.0756 - val_mae: 0.2136\n",
      "Epoch 891/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0673 - mae: 0.2017 - val_loss: 0.0695 - val_mae: 0.2078\n",
      "Epoch 892/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0708 - mae: 0.2070 - val_loss: 0.0639 - val_mae: 0.2039\n",
      "Epoch 893/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0675 - mae: 0.2017 - val_loss: 0.0604 - val_mae: 0.1944\n",
      "Epoch 894/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0729 - mae: 0.2106 - val_loss: 0.0658 - val_mae: 0.1972\n",
      "Epoch 895/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0693 - mae: 0.2040 - val_loss: 0.0866 - val_mae: 0.2250\n",
      "Epoch 896/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0691 - mae: 0.2036 - val_loss: 0.0771 - val_mae: 0.2105\n",
      "Epoch 897/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0725 - mae: 0.2073 - val_loss: 0.0740 - val_mae: 0.2168\n",
      "Epoch 898/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0759 - mae: 0.2111 - val_loss: 0.0596 - val_mae: 0.1869\n",
      "Epoch 899/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0668 - mae: 0.2006 - val_loss: 0.0701 - val_mae: 0.1997\n",
      "Epoch 900/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0673 - mae: 0.2011 - val_loss: 0.0591 - val_mae: 0.1915\n",
      "Epoch 901/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0654 - mae: 0.1992 - val_loss: 0.0752 - val_mae: 0.2164\n",
      "Epoch 902/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0643 - mae: 0.1971 - val_loss: 0.0697 - val_mae: 0.2102\n",
      "Epoch 903/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0819 - mae: 0.2267 - val_loss: 0.0754 - val_mae: 0.2178\n",
      "Epoch 904/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0705 - mae: 0.2066 - val_loss: 0.0733 - val_mae: 0.2117\n",
      "Epoch 905/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0703 - mae: 0.2064 - val_loss: 0.0628 - val_mae: 0.1988\n",
      "Epoch 906/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0704 - mae: 0.2100 - val_loss: 0.1278 - val_mae: 0.2739\n",
      "Epoch 907/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0815 - mae: 0.2189 - val_loss: 0.1039 - val_mae: 0.2539\n",
      "Epoch 908/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0883 - mae: 0.2344 - val_loss: 0.1171 - val_mae: 0.2875\n",
      "Epoch 909/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1104 - mae: 0.2731 - val_loss: 0.1077 - val_mae: 0.2743\n",
      "Epoch 910/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0956 - mae: 0.2484 - val_loss: 0.0762 - val_mae: 0.2111\n",
      "Epoch 911/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0786 - mae: 0.2173 - val_loss: 0.0930 - val_mae: 0.2415\n",
      "Epoch 912/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0742 - mae: 0.2138 - val_loss: 0.0842 - val_mae: 0.2224\n",
      "Epoch 913/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0722 - mae: 0.2119 - val_loss: 0.0665 - val_mae: 0.2012\n",
      "Epoch 914/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0670 - mae: 0.2050 - val_loss: 0.0644 - val_mae: 0.2024\n",
      "Epoch 915/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0708 - mae: 0.2086 - val_loss: 0.0625 - val_mae: 0.1996\n",
      "Epoch 916/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0639 - mae: 0.1953 - val_loss: 0.0597 - val_mae: 0.1911\n",
      "Epoch 917/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0576 - mae: 0.1857 - val_loss: 0.0711 - val_mae: 0.2003\n",
      "Epoch 918/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0593 - mae: 0.1880 - val_loss: 0.0651 - val_mae: 0.1927\n",
      "Epoch 919/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0588 - mae: 0.1873 - val_loss: 0.0579 - val_mae: 0.1842\n",
      "Epoch 920/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0571 - mae: 0.1841 - val_loss: 0.0749 - val_mae: 0.2211\n",
      "Epoch 921/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0604 - mae: 0.1901 - val_loss: 0.0683 - val_mae: 0.2022\n",
      "Epoch 922/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0568 - mae: 0.1843 - val_loss: 0.0838 - val_mae: 0.2222\n",
      "Epoch 923/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0685 - mae: 0.2062 - val_loss: 0.0718 - val_mae: 0.2090\n",
      "Epoch 924/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0647 - mae: 0.2009 - val_loss: 0.0745 - val_mae: 0.2095\n",
      "Epoch 925/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0602 - mae: 0.1892 - val_loss: 0.0574 - val_mae: 0.1817\n",
      "Epoch 926/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0570 - mae: 0.1812 - val_loss: 0.0605 - val_mae: 0.1887\n",
      "Epoch 927/2000\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0586 - mae: 0.1857 - val_loss: 0.0695 - val_mae: 0.2000\n",
      "Epoch 928/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0616 - mae: 0.1915 - val_loss: 0.0740 - val_mae: 0.2238\n",
      "Epoch 929/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0654 - mae: 0.2007 - val_loss: 0.0644 - val_mae: 0.2066\n",
      "Epoch 930/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0713 - mae: 0.2124 - val_loss: 0.1108 - val_mae: 0.2614\n",
      "Epoch 931/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0794 - mae: 0.2243 - val_loss: 0.0691 - val_mae: 0.1996\n",
      "Epoch 932/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0702 - mae: 0.2060 - val_loss: 0.0643 - val_mae: 0.2004\n",
      "Epoch 933/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0668 - mae: 0.2016 - val_loss: 0.0692 - val_mae: 0.2080\n",
      "Epoch 934/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0667 - mae: 0.2017 - val_loss: 0.1091 - val_mae: 0.2571\n",
      "Epoch 935/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0739 - mae: 0.2148 - val_loss: 0.0587 - val_mae: 0.1842\n",
      "Epoch 936/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0670 - mae: 0.2006 - val_loss: 0.0648 - val_mae: 0.2002\n",
      "Epoch 937/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0569 - mae: 0.1842 - val_loss: 0.0595 - val_mae: 0.1913\n",
      "Epoch 938/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0562 - mae: 0.1809 - val_loss: 0.0538 - val_mae: 0.1783\n",
      "Epoch 939/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0528 - mae: 0.1748 - val_loss: 0.0786 - val_mae: 0.2113\n",
      "Epoch 940/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0609 - mae: 0.1906 - val_loss: 0.0691 - val_mae: 0.1972\n",
      "Epoch 941/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0577 - mae: 0.1842 - val_loss: 0.0584 - val_mae: 0.1870\n",
      "Epoch 942/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0540 - mae: 0.1785 - val_loss: 0.0549 - val_mae: 0.1803\n",
      "Epoch 943/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0529 - mae: 0.1778 - val_loss: 0.0724 - val_mae: 0.2059\n",
      "Epoch 944/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0573 - mae: 0.1849 - val_loss: 0.0650 - val_mae: 0.2069\n",
      "Epoch 945/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0609 - mae: 0.1944 - val_loss: 0.0799 - val_mae: 0.2165\n",
      "Epoch 946/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0653 - mae: 0.2003 - val_loss: 0.1045 - val_mae: 0.2571\n",
      "Epoch 947/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0749 - mae: 0.2149 - val_loss: 0.0601 - val_mae: 0.1893\n",
      "Epoch 948/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0644 - mae: 0.1961 - val_loss: 0.0532 - val_mae: 0.1778\n",
      "Epoch 949/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0550 - mae: 0.1806 - val_loss: 0.0688 - val_mae: 0.2027\n",
      "Epoch 950/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0523 - mae: 0.1756 - val_loss: 0.0615 - val_mae: 0.1908\n",
      "Epoch 951/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0517 - mae: 0.1719 - val_loss: 0.0638 - val_mae: 0.2064\n",
      "Epoch 952/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0539 - mae: 0.1824 - val_loss: 0.0579 - val_mae: 0.1822\n",
      "Epoch 953/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0472 - mae: 0.1643 - val_loss: 0.0526 - val_mae: 0.1770\n",
      "Epoch 954/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0547 - mae: 0.1809 - val_loss: 0.0648 - val_mae: 0.1952\n",
      "Epoch 955/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0520 - mae: 0.1763 - val_loss: 0.0683 - val_mae: 0.2113\n",
      "Epoch 956/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0634 - mae: 0.1993 - val_loss: 0.0602 - val_mae: 0.1950\n",
      "Epoch 957/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0688 - mae: 0.2058 - val_loss: 0.0829 - val_mae: 0.2329\n",
      "Epoch 958/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0714 - mae: 0.2106 - val_loss: 0.0623 - val_mae: 0.1899\n",
      "Epoch 959/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0696 - mae: 0.2082 - val_loss: 0.0766 - val_mae: 0.2313\n",
      "Epoch 960/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0586 - mae: 0.1883 - val_loss: 0.0650 - val_mae: 0.2047\n",
      "Epoch 961/2000\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.0613 - mae: 0.1949 - val_loss: 0.0640 - val_mae: 0.1992\n",
      "Epoch 962/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0552 - mae: 0.1832 - val_loss: 0.0657 - val_mae: 0.1979\n",
      "Epoch 963/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0554 - mae: 0.1820 - val_loss: 0.0575 - val_mae: 0.1850\n",
      "Epoch 964/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0505 - mae: 0.1725 - val_loss: 0.0624 - val_mae: 0.1974\n",
      "Epoch 965/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0638 - mae: 0.1967 - val_loss: 0.0695 - val_mae: 0.2098\n",
      "Epoch 966/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0622 - mae: 0.1971 - val_loss: 0.0563 - val_mae: 0.1877\n",
      "Epoch 967/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0474 - mae: 0.1661 - val_loss: 0.0583 - val_mae: 0.1869\n",
      "Epoch 968/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0462 - mae: 0.1648 - val_loss: 0.0590 - val_mae: 0.1828\n",
      "Epoch 969/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0488 - mae: 0.1700 - val_loss: 0.0491 - val_mae: 0.1669\n",
      "Epoch 970/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0430 - mae: 0.1585 - val_loss: 0.0477 - val_mae: 0.1706\n",
      "Epoch 971/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0439 - mae: 0.1610 - val_loss: 0.0609 - val_mae: 0.1914\n",
      "Epoch 972/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0446 - mae: 0.1635 - val_loss: 0.0539 - val_mae: 0.1825\n",
      "Epoch 973/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0452 - mae: 0.1636 - val_loss: 0.0668 - val_mae: 0.2111\n",
      "Epoch 974/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0566 - mae: 0.1890 - val_loss: 0.0595 - val_mae: 0.1937\n",
      "Epoch 975/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0573 - mae: 0.1894 - val_loss: 0.0735 - val_mae: 0.2130\n",
      "Epoch 976/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0535 - mae: 0.1818 - val_loss: 0.0637 - val_mae: 0.2001\n",
      "Epoch 977/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0534 - mae: 0.1802 - val_loss: 0.0539 - val_mae: 0.1844\n",
      "Epoch 978/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0464 - mae: 0.1665 - val_loss: 0.0548 - val_mae: 0.1851\n",
      "Epoch 979/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0470 - mae: 0.1659 - val_loss: 0.0538 - val_mae: 0.1828\n",
      "Epoch 980/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0449 - mae: 0.1637 - val_loss: 0.0549 - val_mae: 0.1788\n",
      "Epoch 981/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0459 - mae: 0.1651 - val_loss: 0.0500 - val_mae: 0.1726\n",
      "Epoch 982/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0423 - mae: 0.1584 - val_loss: 0.0496 - val_mae: 0.1751\n",
      "Epoch 983/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0439 - mae: 0.1639 - val_loss: 0.0551 - val_mae: 0.1775\n",
      "Epoch 984/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0422 - mae: 0.1584 - val_loss: 0.0504 - val_mae: 0.1687\n",
      "Epoch 985/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0455 - mae: 0.1645 - val_loss: 0.0571 - val_mae: 0.1831\n",
      "Epoch 986/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0447 - mae: 0.1629 - val_loss: 0.0641 - val_mae: 0.2023\n",
      "Epoch 987/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0496 - mae: 0.1744 - val_loss: 0.0593 - val_mae: 0.1978\n",
      "Epoch 988/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0529 - mae: 0.1818 - val_loss: 0.0558 - val_mae: 0.1846\n",
      "Epoch 989/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0473 - mae: 0.1714 - val_loss: 0.0548 - val_mae: 0.1797\n",
      "Epoch 990/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0460 - mae: 0.1682 - val_loss: 0.0528 - val_mae: 0.1826\n",
      "Epoch 991/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0487 - mae: 0.1734 - val_loss: 0.0522 - val_mae: 0.1782\n",
      "Epoch 992/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0458 - mae: 0.1681 - val_loss: 0.0540 - val_mae: 0.1773\n",
      "Epoch 993/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0459 - mae: 0.1654 - val_loss: 0.0622 - val_mae: 0.1994\n",
      "Epoch 994/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0477 - mae: 0.1720 - val_loss: 0.0492 - val_mae: 0.1763\n",
      "Epoch 995/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0487 - mae: 0.1752 - val_loss: 0.0586 - val_mae: 0.1900\n",
      "Epoch 996/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0495 - mae: 0.1755 - val_loss: 0.0569 - val_mae: 0.1914\n",
      "Epoch 997/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0444 - mae: 0.1655 - val_loss: 0.0477 - val_mae: 0.1687\n",
      "Epoch 998/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0424 - mae: 0.1578 - val_loss: 0.0493 - val_mae: 0.1789\n",
      "Epoch 999/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0422 - mae: 0.1638 - val_loss: 0.0754 - val_mae: 0.2065\n",
      "Epoch 1000/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0511 - mae: 0.1773 - val_loss: 0.0563 - val_mae: 0.1875\n",
      "Epoch 1001/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0454 - mae: 0.1668 - val_loss: 0.0474 - val_mae: 0.1723\n",
      "Epoch 1002/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0452 - mae: 0.1684 - val_loss: 0.0604 - val_mae: 0.1921\n",
      "Epoch 1003/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0458 - mae: 0.1679 - val_loss: 0.0527 - val_mae: 0.1805\n",
      "Epoch 1004/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0439 - mae: 0.1640 - val_loss: 0.0815 - val_mae: 0.2314\n",
      "Epoch 1005/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0629 - mae: 0.1990 - val_loss: 0.0588 - val_mae: 0.1876\n",
      "Epoch 1006/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0605 - mae: 0.1949 - val_loss: 0.0822 - val_mae: 0.2365\n",
      "Epoch 1007/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0749 - mae: 0.2242 - val_loss: 0.0696 - val_mae: 0.2125\n",
      "Epoch 1008/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0816 - mae: 0.2285 - val_loss: 0.1470 - val_mae: 0.3097\n",
      "Epoch 1009/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0967 - mae: 0.2474 - val_loss: 0.0874 - val_mae: 0.2294\n",
      "Epoch 1010/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0770 - mae: 0.2226 - val_loss: 0.0635 - val_mae: 0.2001\n",
      "Epoch 1011/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0624 - mae: 0.1949 - val_loss: 0.0512 - val_mae: 0.1772\n",
      "Epoch 1012/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0520 - mae: 0.1781 - val_loss: 0.0649 - val_mae: 0.1949\n",
      "Epoch 1013/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0543 - mae: 0.1808 - val_loss: 0.0596 - val_mae: 0.1970\n",
      "Epoch 1014/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0580 - mae: 0.1918 - val_loss: 0.0538 - val_mae: 0.1848\n",
      "Epoch 1015/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0536 - mae: 0.1810 - val_loss: 0.0501 - val_mae: 0.1740\n",
      "Epoch 1016/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0486 - mae: 0.1747 - val_loss: 0.0660 - val_mae: 0.1955\n",
      "Epoch 1017/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0520 - mae: 0.1812 - val_loss: 0.0476 - val_mae: 0.1696\n",
      "Epoch 1018/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0456 - mae: 0.1681 - val_loss: 0.0580 - val_mae: 0.1895\n",
      "Epoch 1019/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0456 - mae: 0.1675 - val_loss: 0.0508 - val_mae: 0.1711\n",
      "Epoch 1020/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0471 - mae: 0.1687 - val_loss: 0.0498 - val_mae: 0.1766\n",
      "Epoch 1021/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0441 - mae: 0.1644 - val_loss: 0.0516 - val_mae: 0.1771\n",
      "Epoch 1022/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0400 - mae: 0.1572 - val_loss: 0.0469 - val_mae: 0.1631\n",
      "Epoch 1023/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0396 - mae: 0.1550 - val_loss: 0.0507 - val_mae: 0.1705\n",
      "Epoch 1024/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0407 - mae: 0.1571 - val_loss: 0.0451 - val_mae: 0.1663\n",
      "Epoch 1025/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0388 - mae: 0.1541 - val_loss: 0.0547 - val_mae: 0.1849\n",
      "Epoch 1026/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0408 - mae: 0.1574 - val_loss: 0.0500 - val_mae: 0.1737\n",
      "Epoch 1027/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0449 - mae: 0.1647 - val_loss: 0.0677 - val_mae: 0.2088\n",
      "Epoch 1028/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0527 - mae: 0.1820 - val_loss: 0.0527 - val_mae: 0.1768\n",
      "Epoch 1029/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0471 - mae: 0.1717 - val_loss: 0.0589 - val_mae: 0.1894\n",
      "Epoch 1030/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0466 - mae: 0.1705 - val_loss: 0.0500 - val_mae: 0.1753\n",
      "Epoch 1031/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0436 - mae: 0.1649 - val_loss: 0.0570 - val_mae: 0.1874\n",
      "Epoch 1032/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0507 - mae: 0.1782 - val_loss: 0.0584 - val_mae: 0.1865\n",
      "Epoch 1033/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0487 - mae: 0.1756 - val_loss: 0.0574 - val_mae: 0.1957\n",
      "Epoch 1034/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0523 - mae: 0.1773 - val_loss: 0.0574 - val_mae: 0.1824\n",
      "Epoch 1035/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0595 - mae: 0.1911 - val_loss: 0.0713 - val_mae: 0.2072\n",
      "Epoch 1036/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0631 - mae: 0.1928 - val_loss: 0.0587 - val_mae: 0.1876\n",
      "Epoch 1037/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0589 - mae: 0.1885 - val_loss: 0.0510 - val_mae: 0.1796\n",
      "Epoch 1038/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0572 - mae: 0.1836 - val_loss: 0.0627 - val_mae: 0.1925\n",
      "Epoch 1039/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0633 - mae: 0.1987 - val_loss: 0.0738 - val_mae: 0.2188\n",
      "Epoch 1040/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0588 - mae: 0.1963 - val_loss: 0.0975 - val_mae: 0.2407\n",
      "Epoch 1041/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0641 - mae: 0.2020 - val_loss: 0.0621 - val_mae: 0.2021\n",
      "Epoch 1042/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0648 - mae: 0.1984 - val_loss: 0.0699 - val_mae: 0.1991\n",
      "Epoch 1043/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0635 - mae: 0.1896 - val_loss: 0.0574 - val_mae: 0.1878\n",
      "Epoch 1044/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0582 - mae: 0.1888 - val_loss: 0.0541 - val_mae: 0.1871\n",
      "Epoch 1045/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0608 - mae: 0.1953 - val_loss: 0.0512 - val_mae: 0.1750\n",
      "Epoch 1046/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0538 - mae: 0.1830 - val_loss: 0.0585 - val_mae: 0.1908\n",
      "Epoch 1047/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0570 - mae: 0.1902 - val_loss: 0.0884 - val_mae: 0.2325\n",
      "Epoch 1048/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0885 - mae: 0.2378 - val_loss: 0.0914 - val_mae: 0.2455\n",
      "Epoch 1049/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0783 - mae: 0.2234 - val_loss: 0.0576 - val_mae: 0.1875\n",
      "Epoch 1050/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0544 - mae: 0.1836 - val_loss: 0.0539 - val_mae: 0.1774\n",
      "Epoch 1051/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0612 - mae: 0.1968 - val_loss: 0.1477 - val_mae: 0.3240\n",
      "Epoch 1052/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0997 - mae: 0.2582 - val_loss: 0.1541 - val_mae: 0.3291\n",
      "Epoch 1053/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1032 - mae: 0.2590 - val_loss: 0.0798 - val_mae: 0.2250\n",
      "Epoch 1054/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0820 - mae: 0.2316 - val_loss: 0.0652 - val_mae: 0.2038\n",
      "Epoch 1055/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0621 - mae: 0.1972 - val_loss: 0.0551 - val_mae: 0.1767\n",
      "Epoch 1056/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0478 - mae: 0.1719 - val_loss: 0.0671 - val_mae: 0.2038\n",
      "Epoch 1057/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0573 - mae: 0.1908 - val_loss: 0.0600 - val_mae: 0.2004\n",
      "Epoch 1058/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0703 - mae: 0.2164 - val_loss: 0.0537 - val_mae: 0.1810\n",
      "Epoch 1059/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0535 - mae: 0.1849 - val_loss: 0.0540 - val_mae: 0.1864\n",
      "Epoch 1060/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0502 - mae: 0.1771 - val_loss: 0.0562 - val_mae: 0.1839\n",
      "Epoch 1061/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0493 - mae: 0.1736 - val_loss: 0.0517 - val_mae: 0.1791\n",
      "Epoch 1062/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0595 - mae: 0.1948 - val_loss: 0.0705 - val_mae: 0.2120\n",
      "Epoch 1063/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0561 - mae: 0.1883 - val_loss: 0.0547 - val_mae: 0.1830\n",
      "Epoch 1064/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0448 - mae: 0.1682 - val_loss: 0.0491 - val_mae: 0.1721\n",
      "Epoch 1065/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0474 - mae: 0.1726 - val_loss: 0.0429 - val_mae: 0.1632\n",
      "Epoch 1066/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0411 - mae: 0.1594 - val_loss: 0.0478 - val_mae: 0.1742\n",
      "Epoch 1067/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0519 - mae: 0.1830 - val_loss: 0.0585 - val_mae: 0.1934\n",
      "Epoch 1068/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0496 - mae: 0.1771 - val_loss: 0.0571 - val_mae: 0.1987\n",
      "Epoch 1069/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0543 - mae: 0.1877 - val_loss: 0.1185 - val_mae: 0.2923\n",
      "Epoch 1070/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0823 - mae: 0.2400 - val_loss: 0.0602 - val_mae: 0.2035\n",
      "Epoch 1071/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0525 - mae: 0.1840 - val_loss: 0.0497 - val_mae: 0.1692\n",
      "Epoch 1072/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0444 - mae: 0.1670 - val_loss: 0.0559 - val_mae: 0.1837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1073/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0439 - mae: 0.1648 - val_loss: 0.0484 - val_mae: 0.1710\n",
      "Epoch 1074/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0422 - mae: 0.1615 - val_loss: 0.0412 - val_mae: 0.1563\n",
      "Epoch 1075/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0408 - mae: 0.1600 - val_loss: 0.0467 - val_mae: 0.1695\n",
      "Epoch 1076/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0393 - mae: 0.1569 - val_loss: 0.0470 - val_mae: 0.1693\n",
      "Epoch 1077/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0413 - mae: 0.1587 - val_loss: 0.0388 - val_mae: 0.1564\n",
      "Epoch 1078/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0418 - mae: 0.1601 - val_loss: 0.0529 - val_mae: 0.1807\n",
      "Epoch 1079/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0518 - mae: 0.1811 - val_loss: 0.0441 - val_mae: 0.1607\n",
      "Epoch 1080/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0383 - mae: 0.1559 - val_loss: 0.0488 - val_mae: 0.1687\n",
      "Epoch 1081/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0391 - mae: 0.1556 - val_loss: 0.0455 - val_mae: 0.1688\n",
      "Epoch 1082/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0423 - mae: 0.1639 - val_loss: 0.0424 - val_mae: 0.1649\n",
      "Epoch 1083/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0522 - mae: 0.1828 - val_loss: 0.0878 - val_mae: 0.2195\n",
      "Epoch 1084/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0611 - mae: 0.1929 - val_loss: 0.0515 - val_mae: 0.1771\n",
      "Epoch 1085/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0528 - mae: 0.1782 - val_loss: 0.0475 - val_mae: 0.1685\n",
      "Epoch 1086/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0529 - mae: 0.1822 - val_loss: 0.0619 - val_mae: 0.1935\n",
      "Epoch 1087/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0508 - mae: 0.1777 - val_loss: 0.0512 - val_mae: 0.1822\n",
      "Epoch 1088/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0521 - mae: 0.1824 - val_loss: 0.0647 - val_mae: 0.2088\n",
      "Epoch 1089/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0573 - mae: 0.1935 - val_loss: 0.0664 - val_mae: 0.2025\n",
      "Epoch 1090/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0524 - mae: 0.1820 - val_loss: 0.0539 - val_mae: 0.1808\n",
      "Epoch 1091/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0448 - mae: 0.1682 - val_loss: 0.0427 - val_mae: 0.1625\n",
      "Epoch 1092/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0419 - mae: 0.1626 - val_loss: 0.0492 - val_mae: 0.1796\n",
      "Epoch 1093/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0439 - mae: 0.1678 - val_loss: 0.0471 - val_mae: 0.1645\n",
      "Epoch 1094/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0412 - mae: 0.1591 - val_loss: 0.0459 - val_mae: 0.1682\n",
      "Epoch 1095/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0438 - mae: 0.1651 - val_loss: 0.0442 - val_mae: 0.1675\n",
      "Epoch 1096/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0443 - mae: 0.1668 - val_loss: 0.0465 - val_mae: 0.1696\n",
      "Epoch 1097/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0385 - mae: 0.1551 - val_loss: 0.0519 - val_mae: 0.1713\n",
      "Epoch 1098/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0438 - mae: 0.1659 - val_loss: 0.0431 - val_mae: 0.1622\n",
      "Epoch 1099/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0437 - mae: 0.1650 - val_loss: 0.0522 - val_mae: 0.1801\n",
      "Epoch 1100/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0453 - mae: 0.1691 - val_loss: 0.0499 - val_mae: 0.1790\n",
      "Epoch 1101/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0432 - mae: 0.1644 - val_loss: 0.0877 - val_mae: 0.2478\n",
      "Epoch 1102/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0635 - mae: 0.2067 - val_loss: 0.0664 - val_mae: 0.2029\n",
      "Epoch 1103/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0553 - mae: 0.1881 - val_loss: 0.0563 - val_mae: 0.1963\n",
      "Epoch 1104/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0507 - mae: 0.1826 - val_loss: 0.0603 - val_mae: 0.1983\n",
      "Epoch 1105/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0578 - mae: 0.1976 - val_loss: 0.0689 - val_mae: 0.2029\n",
      "Epoch 1106/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0477 - mae: 0.1718 - val_loss: 0.0890 - val_mae: 0.2263\n",
      "Epoch 1107/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0747 - mae: 0.2166 - val_loss: 0.0802 - val_mae: 0.2245\n",
      "Epoch 1108/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0764 - mae: 0.2175 - val_loss: 0.0665 - val_mae: 0.2050\n",
      "Epoch 1109/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0746 - mae: 0.2150 - val_loss: 0.0948 - val_mae: 0.2402\n",
      "Epoch 1110/2000\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0763 - mae: 0.2185 - val_loss: 0.0674 - val_mae: 0.2028\n",
      "Epoch 1111/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0715 - mae: 0.2117 - val_loss: 0.0801 - val_mae: 0.2187\n",
      "Epoch 1112/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0731 - mae: 0.2104 - val_loss: 0.0672 - val_mae: 0.2047\n",
      "Epoch 1113/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0727 - mae: 0.2128 - val_loss: 0.0684 - val_mae: 0.2016\n",
      "Epoch 1114/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0662 - mae: 0.2005 - val_loss: 0.0764 - val_mae: 0.2135\n",
      "Epoch 1115/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0757 - mae: 0.2181 - val_loss: 0.0680 - val_mae: 0.2053\n",
      "Epoch 1116/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0729 - mae: 0.2126 - val_loss: 0.0774 - val_mae: 0.2158\n",
      "Epoch 1117/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0775 - mae: 0.2198 - val_loss: 0.0984 - val_mae: 0.2389\n",
      "Epoch 1118/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0856 - mae: 0.2303 - val_loss: 0.0698 - val_mae: 0.2152\n",
      "Epoch 1119/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0762 - mae: 0.2173 - val_loss: 0.0694 - val_mae: 0.2055\n",
      "Epoch 1120/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0753 - mae: 0.2184 - val_loss: 0.0860 - val_mae: 0.2253\n",
      "Epoch 1121/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0936 - mae: 0.2409 - val_loss: 0.0993 - val_mae: 0.2561\n",
      "Epoch 1122/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1141 - mae: 0.2707 - val_loss: 0.0915 - val_mae: 0.2420\n",
      "Epoch 1123/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0973 - mae: 0.2452 - val_loss: 0.0891 - val_mae: 0.2421\n",
      "Epoch 1124/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0907 - mae: 0.2376 - val_loss: 0.0746 - val_mae: 0.2163\n",
      "Epoch 1125/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0902 - mae: 0.2387 - val_loss: 0.0769 - val_mae: 0.2170\n",
      "Epoch 1126/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1044 - mae: 0.2576 - val_loss: 0.1079 - val_mae: 0.2757\n",
      "Epoch 1127/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.1221 - mae: 0.2849 - val_loss: 0.1531 - val_mae: 0.3203\n",
      "Epoch 1128/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1150 - mae: 0.2668 - val_loss: 0.1255 - val_mae: 0.2856\n",
      "Epoch 1129/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1097 - mae: 0.2645 - val_loss: 0.0821 - val_mae: 0.2275\n",
      "Epoch 1130/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1065 - mae: 0.2587 - val_loss: 0.0942 - val_mae: 0.2500\n",
      "Epoch 1131/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1245 - mae: 0.2825 - val_loss: 0.1253 - val_mae: 0.2820\n",
      "Epoch 1132/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.1021 - mae: 0.2535 - val_loss: 0.0860 - val_mae: 0.2249\n",
      "Epoch 1133/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0875 - mae: 0.2344 - val_loss: 0.0816 - val_mae: 0.2307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1134/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0958 - mae: 0.2470 - val_loss: 0.0723 - val_mae: 0.2123\n",
      "Epoch 1135/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0792 - mae: 0.2238 - val_loss: 0.0696 - val_mae: 0.2086\n",
      "Epoch 1136/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0899 - mae: 0.2354 - val_loss: 0.1243 - val_mae: 0.2868\n",
      "Epoch 1137/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0865 - mae: 0.2328 - val_loss: 0.1188 - val_mae: 0.2887\n",
      "Epoch 1138/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0873 - mae: 0.2359 - val_loss: 0.0685 - val_mae: 0.2097\n",
      "Epoch 1139/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0738 - mae: 0.2150 - val_loss: 0.0621 - val_mae: 0.1986\n",
      "Epoch 1140/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0706 - mae: 0.2104 - val_loss: 0.0624 - val_mae: 0.1940\n",
      "Epoch 1141/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0638 - mae: 0.1995 - val_loss: 0.0896 - val_mae: 0.2400\n",
      "Epoch 1142/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0702 - mae: 0.2108 - val_loss: 0.0655 - val_mae: 0.1920\n",
      "Epoch 1143/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0559 - mae: 0.1839 - val_loss: 0.0615 - val_mae: 0.1883\n",
      "Epoch 1144/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0561 - mae: 0.1836 - val_loss: 0.0510 - val_mae: 0.1748\n",
      "Epoch 1145/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0561 - mae: 0.1836 - val_loss: 0.0512 - val_mae: 0.1781\n",
      "Epoch 1146/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0533 - mae: 0.1813 - val_loss: 0.0672 - val_mae: 0.2001\n",
      "Epoch 1147/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0583 - mae: 0.1899 - val_loss: 0.0629 - val_mae: 0.1925\n",
      "Epoch 1148/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0529 - mae: 0.1808 - val_loss: 0.0602 - val_mae: 0.1883\n",
      "Epoch 1149/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0519 - mae: 0.1788 - val_loss: 0.0484 - val_mae: 0.1731\n",
      "Epoch 1150/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0473 - mae: 0.1703 - val_loss: 0.0484 - val_mae: 0.1708\n",
      "Epoch 1151/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0479 - mae: 0.1702 - val_loss: 0.0616 - val_mae: 0.2010\n",
      "Epoch 1152/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0566 - mae: 0.1901 - val_loss: 0.0578 - val_mae: 0.1862\n",
      "Epoch 1153/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0514 - mae: 0.1798 - val_loss: 0.0542 - val_mae: 0.1772\n",
      "Epoch 1154/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0488 - mae: 0.1728 - val_loss: 0.0494 - val_mae: 0.1784\n",
      "Epoch 1155/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0534 - mae: 0.1827 - val_loss: 0.0511 - val_mae: 0.1766\n",
      "Epoch 1156/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0468 - mae: 0.1692 - val_loss: 0.0516 - val_mae: 0.1785\n",
      "Epoch 1157/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0495 - mae: 0.1755 - val_loss: 0.0704 - val_mae: 0.2144\n",
      "Epoch 1158/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0608 - mae: 0.1972 - val_loss: 0.0605 - val_mae: 0.1865\n",
      "Epoch 1159/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0577 - mae: 0.1890 - val_loss: 0.0643 - val_mae: 0.2038\n",
      "Epoch 1160/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0551 - mae: 0.1859 - val_loss: 0.0491 - val_mae: 0.1780\n",
      "Epoch 1161/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0494 - mae: 0.1760 - val_loss: 0.0537 - val_mae: 0.1774\n",
      "Epoch 1162/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0454 - mae: 0.1677 - val_loss: 0.0504 - val_mae: 0.1755\n",
      "Epoch 1163/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0533 - mae: 0.1804 - val_loss: 0.0575 - val_mae: 0.1922\n",
      "Epoch 1164/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0551 - mae: 0.1888 - val_loss: 0.0610 - val_mae: 0.1877\n",
      "Epoch 1165/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0525 - mae: 0.1803 - val_loss: 0.0452 - val_mae: 0.1674\n",
      "Epoch 1166/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0496 - mae: 0.1758 - val_loss: 0.0558 - val_mae: 0.1864\n",
      "Epoch 1167/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0487 - mae: 0.1735 - val_loss: 0.0498 - val_mae: 0.1759\n",
      "Epoch 1168/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0463 - mae: 0.1714 - val_loss: 0.0470 - val_mae: 0.1680\n",
      "Epoch 1169/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0446 - mae: 0.1665 - val_loss: 0.0524 - val_mae: 0.1771\n",
      "Epoch 1170/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0433 - mae: 0.1634 - val_loss: 0.0516 - val_mae: 0.1753\n",
      "Epoch 1171/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0428 - mae: 0.1631 - val_loss: 0.0495 - val_mae: 0.1796\n",
      "Epoch 1172/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0449 - mae: 0.1656 - val_loss: 0.0514 - val_mae: 0.1766\n",
      "Epoch 1173/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0450 - mae: 0.1666 - val_loss: 0.0467 - val_mae: 0.1692\n",
      "Epoch 1174/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0449 - mae: 0.1679 - val_loss: 0.0489 - val_mae: 0.1740\n",
      "Epoch 1175/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0525 - mae: 0.1841 - val_loss: 0.0798 - val_mae: 0.2256\n",
      "Epoch 1176/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0497 - mae: 0.1759 - val_loss: 0.0455 - val_mae: 0.1656\n",
      "Epoch 1177/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0426 - mae: 0.1616 - val_loss: 0.0461 - val_mae: 0.1727\n",
      "Epoch 1178/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0441 - mae: 0.1677 - val_loss: 0.0466 - val_mae: 0.1672\n",
      "Epoch 1179/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0441 - mae: 0.1664 - val_loss: 0.0644 - val_mae: 0.2006\n",
      "Epoch 1180/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0459 - mae: 0.1679 - val_loss: 0.0489 - val_mae: 0.1817\n",
      "Epoch 1181/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0526 - mae: 0.1835 - val_loss: 0.0515 - val_mae: 0.1827\n",
      "Epoch 1182/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0500 - mae: 0.1774 - val_loss: 0.0570 - val_mae: 0.1918\n",
      "Epoch 1183/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0449 - mae: 0.1663 - val_loss: 0.0472 - val_mae: 0.1726\n",
      "Epoch 1184/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0462 - mae: 0.1710 - val_loss: 0.0427 - val_mae: 0.1618\n",
      "Epoch 1185/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0426 - mae: 0.1642 - val_loss: 0.0693 - val_mae: 0.2085\n",
      "Epoch 1186/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0452 - mae: 0.1682 - val_loss: 0.0478 - val_mae: 0.1704\n",
      "Epoch 1187/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0439 - mae: 0.1670 - val_loss: 0.0427 - val_mae: 0.1599\n",
      "Epoch 1188/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0379 - mae: 0.1528 - val_loss: 0.0462 - val_mae: 0.1697\n",
      "Epoch 1189/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0390 - mae: 0.1559 - val_loss: 0.0506 - val_mae: 0.1803\n",
      "Epoch 1190/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0390 - mae: 0.1567 - val_loss: 0.0476 - val_mae: 0.1687\n",
      "Epoch 1191/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0367 - mae: 0.1513 - val_loss: 0.0441 - val_mae: 0.1600\n",
      "Epoch 1192/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0397 - mae: 0.1581 - val_loss: 0.0456 - val_mae: 0.1620\n",
      "Epoch 1193/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0390 - mae: 0.1551 - val_loss: 0.0400 - val_mae: 0.1587\n",
      "Epoch 1194/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0419 - mae: 0.1626 - val_loss: 0.0511 - val_mae: 0.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1195/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0444 - mae: 0.1668 - val_loss: 0.0497 - val_mae: 0.1770\n",
      "Epoch 1196/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0462 - mae: 0.1716 - val_loss: 0.0574 - val_mae: 0.1914\n",
      "Epoch 1197/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0678 - mae: 0.2023 - val_loss: 0.1055 - val_mae: 0.2700\n",
      "Epoch 1198/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0901 - mae: 0.2394 - val_loss: 0.0970 - val_mae: 0.2393\n",
      "Epoch 1199/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0867 - mae: 0.2303 - val_loss: 0.0906 - val_mae: 0.2344\n",
      "Epoch 1200/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0869 - mae: 0.2305 - val_loss: 0.0787 - val_mae: 0.2192\n",
      "Epoch 1201/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0851 - mae: 0.2272 - val_loss: 0.0812 - val_mae: 0.2222\n",
      "Epoch 1202/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0830 - mae: 0.2253 - val_loss: 0.0890 - val_mae: 0.2282\n",
      "Epoch 1203/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0903 - mae: 0.2376 - val_loss: 0.0893 - val_mae: 0.2407\n",
      "Epoch 1204/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0808 - mae: 0.2274 - val_loss: 0.0745 - val_mae: 0.2177\n",
      "Epoch 1205/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0770 - mae: 0.2205 - val_loss: 0.0896 - val_mae: 0.2283\n",
      "Epoch 1206/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0768 - mae: 0.2159 - val_loss: 0.0843 - val_mae: 0.2287\n",
      "Epoch 1207/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0709 - mae: 0.2095 - val_loss: 0.0663 - val_mae: 0.2023\n",
      "Epoch 1208/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0720 - mae: 0.2132 - val_loss: 0.0705 - val_mae: 0.2046\n",
      "Epoch 1209/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0643 - mae: 0.1950 - val_loss: 0.0740 - val_mae: 0.2168\n",
      "Epoch 1210/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0714 - mae: 0.2122 - val_loss: 0.0640 - val_mae: 0.1936\n",
      "Epoch 1211/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0674 - mae: 0.2057 - val_loss: 0.0697 - val_mae: 0.2059\n",
      "Epoch 1212/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0684 - mae: 0.2061 - val_loss: 0.0856 - val_mae: 0.2258\n",
      "Epoch 1213/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0729 - mae: 0.2094 - val_loss: 0.0715 - val_mae: 0.2048\n",
      "Epoch 1214/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0661 - mae: 0.1938 - val_loss: 0.0740 - val_mae: 0.2226\n",
      "Epoch 1215/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0716 - mae: 0.2135 - val_loss: 0.0656 - val_mae: 0.1949\n",
      "Epoch 1216/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0587 - mae: 0.1904 - val_loss: 0.0628 - val_mae: 0.1841\n",
      "Epoch 1217/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0571 - mae: 0.1856 - val_loss: 0.0628 - val_mae: 0.2013\n",
      "Epoch 1218/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0521 - mae: 0.1764 - val_loss: 0.0460 - val_mae: 0.1648\n",
      "Epoch 1219/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0534 - mae: 0.1808 - val_loss: 0.0807 - val_mae: 0.2256\n",
      "Epoch 1220/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0552 - mae: 0.1857 - val_loss: 0.0542 - val_mae: 0.1780\n",
      "Epoch 1221/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0456 - mae: 0.1657 - val_loss: 0.0496 - val_mae: 0.1701\n",
      "Epoch 1222/2000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0429 - mae: 0.1586 - val_loss: 0.0512 - val_mae: 0.1772\n",
      "Epoch 1223/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0454 - mae: 0.1635 - val_loss: 0.0535 - val_mae: 0.1805\n",
      "Epoch 1224/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0482 - mae: 0.1706 - val_loss: 0.0494 - val_mae: 0.1691\n",
      "Epoch 1225/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0416 - mae: 0.1595 - val_loss: 0.0482 - val_mae: 0.1657\n",
      "Epoch 1226/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0395 - mae: 0.1525 - val_loss: 0.0495 - val_mae: 0.1728\n",
      "Epoch 1227/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0411 - mae: 0.1580 - val_loss: 0.0723 - val_mae: 0.2132\n",
      "Epoch 1228/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0440 - mae: 0.1660 - val_loss: 0.0444 - val_mae: 0.1651\n",
      "Epoch 1229/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0397 - mae: 0.1542 - val_loss: 0.0451 - val_mae: 0.1661\n",
      "Epoch 1230/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0422 - mae: 0.1617 - val_loss: 0.0628 - val_mae: 0.1982\n",
      "Epoch 1231/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0483 - mae: 0.1756 - val_loss: 0.0507 - val_mae: 0.1719\n",
      "Epoch 1232/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0492 - mae: 0.1750 - val_loss: 0.0557 - val_mae: 0.1861\n",
      "Epoch 1233/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0503 - mae: 0.1778 - val_loss: 0.0562 - val_mae: 0.1869\n",
      "Epoch 1234/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0431 - mae: 0.1655 - val_loss: 0.0470 - val_mae: 0.1641\n",
      "Epoch 1235/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0432 - mae: 0.1640 - val_loss: 0.0531 - val_mae: 0.1753\n",
      "Epoch 1236/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0422 - mae: 0.1607 - val_loss: 0.0507 - val_mae: 0.1771\n",
      "Epoch 1237/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0409 - mae: 0.1565 - val_loss: 0.0462 - val_mae: 0.1746\n",
      "Epoch 1238/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0390 - mae: 0.1555 - val_loss: 0.0403 - val_mae: 0.1571\n",
      "Epoch 1239/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0373 - mae: 0.1533 - val_loss: 0.0543 - val_mae: 0.1773\n",
      "Epoch 1240/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0383 - mae: 0.1532 - val_loss: 0.0445 - val_mae: 0.1691\n",
      "Epoch 1241/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0417 - mae: 0.1592 - val_loss: 0.0474 - val_mae: 0.1796\n",
      "Epoch 1242/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0421 - mae: 0.1641 - val_loss: 0.0454 - val_mae: 0.1640\n",
      "Epoch 1243/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0404 - mae: 0.1599 - val_loss: 0.0442 - val_mae: 0.1628\n",
      "Epoch 1244/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0391 - mae: 0.1549 - val_loss: 0.0617 - val_mae: 0.1986\n",
      "Epoch 1245/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0450 - mae: 0.1707 - val_loss: 0.0480 - val_mae: 0.1751\n",
      "Epoch 1246/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0451 - mae: 0.1687 - val_loss: 0.0482 - val_mae: 0.1758\n",
      "Epoch 1247/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0474 - mae: 0.1753 - val_loss: 0.0608 - val_mae: 0.2037\n",
      "Epoch 1248/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0445 - mae: 0.1688 - val_loss: 0.0567 - val_mae: 0.1856\n",
      "Epoch 1249/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0417 - mae: 0.1625 - val_loss: 0.0425 - val_mae: 0.1613\n",
      "Epoch 1250/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0352 - mae: 0.1473 - val_loss: 0.0560 - val_mae: 0.1865\n",
      "Epoch 1251/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0423 - mae: 0.1642 - val_loss: 0.0436 - val_mae: 0.1654\n",
      "Epoch 1252/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0397 - mae: 0.1562 - val_loss: 0.0414 - val_mae: 0.1634\n",
      "Epoch 1253/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0409 - mae: 0.1602 - val_loss: 0.0529 - val_mae: 0.1824\n",
      "Epoch 1254/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0417 - mae: 0.1632 - val_loss: 0.0568 - val_mae: 0.1884\n",
      "Epoch 1255/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0444 - mae: 0.1671 - val_loss: 0.0757 - val_mae: 0.2251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0564 - mae: 0.1936 - val_loss: 0.0659 - val_mae: 0.2060\n",
      "Epoch 1257/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0764 - mae: 0.2293 - val_loss: 0.0767 - val_mae: 0.2295\n",
      "Epoch 1258/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0832 - mae: 0.2416 - val_loss: 0.1003 - val_mae: 0.2629\n",
      "Epoch 1259/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0776 - mae: 0.2285 - val_loss: 0.0630 - val_mae: 0.1973\n",
      "Epoch 1260/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0541 - mae: 0.1852 - val_loss: 0.0536 - val_mae: 0.1874\n",
      "Epoch 1261/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0503 - mae: 0.1766 - val_loss: 0.0453 - val_mae: 0.1684\n",
      "Epoch 1262/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0602 - mae: 0.1958 - val_loss: 0.0939 - val_mae: 0.2396\n",
      "Epoch 1263/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0918 - mae: 0.2382 - val_loss: 0.0941 - val_mae: 0.2346\n",
      "Epoch 1264/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0820 - mae: 0.2293 - val_loss: 0.0725 - val_mae: 0.2187\n",
      "Epoch 1265/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0819 - mae: 0.2275 - val_loss: 0.0770 - val_mae: 0.2215\n",
      "Epoch 1266/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0831 - mae: 0.2301 - val_loss: 0.0748 - val_mae: 0.2133\n",
      "Epoch 1267/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0723 - mae: 0.2149 - val_loss: 0.0944 - val_mae: 0.2370\n",
      "Epoch 1268/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0714 - mae: 0.2117 - val_loss: 0.0612 - val_mae: 0.1958\n",
      "Epoch 1269/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0630 - mae: 0.1989 - val_loss: 0.0608 - val_mae: 0.1987\n",
      "Epoch 1270/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0694 - mae: 0.2103 - val_loss: 0.0688 - val_mae: 0.2045\n",
      "Epoch 1271/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0737 - mae: 0.2136 - val_loss: 0.0961 - val_mae: 0.2515\n",
      "Epoch 1272/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0759 - mae: 0.2215 - val_loss: 0.0812 - val_mae: 0.2309\n",
      "Epoch 1273/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0676 - mae: 0.2063 - val_loss: 0.0708 - val_mae: 0.2184\n",
      "Epoch 1274/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0610 - mae: 0.1993 - val_loss: 0.0660 - val_mae: 0.1976\n",
      "Epoch 1275/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0599 - mae: 0.1963 - val_loss: 0.0593 - val_mae: 0.1926\n",
      "Epoch 1276/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0548 - mae: 0.1880 - val_loss: 0.0503 - val_mae: 0.1771\n",
      "Epoch 1277/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0577 - mae: 0.1882 - val_loss: 0.0601 - val_mae: 0.1968\n",
      "Epoch 1278/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0519 - mae: 0.1799 - val_loss: 0.0577 - val_mae: 0.1828\n",
      "Epoch 1279/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0493 - mae: 0.1774 - val_loss: 0.0524 - val_mae: 0.1805\n",
      "Epoch 1280/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0534 - mae: 0.1834 - val_loss: 0.0485 - val_mae: 0.1774\n",
      "Epoch 1281/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0493 - mae: 0.1764 - val_loss: 0.0590 - val_mae: 0.1913\n",
      "Epoch 1282/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0509 - mae: 0.1772 - val_loss: 0.0536 - val_mae: 0.1763\n",
      "Epoch 1283/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0462 - mae: 0.1692 - val_loss: 0.0436 - val_mae: 0.1682\n",
      "Epoch 1284/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0427 - mae: 0.1641 - val_loss: 0.0602 - val_mae: 0.1872\n",
      "Epoch 1285/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0506 - mae: 0.1796 - val_loss: 0.0520 - val_mae: 0.1769\n",
      "Epoch 1286/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0471 - mae: 0.1714 - val_loss: 0.0441 - val_mae: 0.1662\n",
      "Epoch 1287/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0428 - mae: 0.1630 - val_loss: 0.0408 - val_mae: 0.1583\n",
      "Epoch 1288/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0420 - mae: 0.1616 - val_loss: 0.0606 - val_mae: 0.1866\n",
      "Epoch 1289/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0448 - mae: 0.1649 - val_loss: 0.0458 - val_mae: 0.1665\n",
      "Epoch 1290/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0419 - mae: 0.1601 - val_loss: 0.0473 - val_mae: 0.1780\n",
      "Epoch 1291/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0443 - mae: 0.1663 - val_loss: 0.0440 - val_mae: 0.1646\n",
      "Epoch 1292/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0405 - mae: 0.1595 - val_loss: 0.0700 - val_mae: 0.2043\n",
      "Epoch 1293/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0440 - mae: 0.1638 - val_loss: 0.0457 - val_mae: 0.1682\n",
      "Epoch 1294/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0420 - mae: 0.1592 - val_loss: 0.0463 - val_mae: 0.1713\n",
      "Epoch 1295/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0422 - mae: 0.1608 - val_loss: 0.0612 - val_mae: 0.1954\n",
      "Epoch 1296/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0492 - mae: 0.1754 - val_loss: 0.0535 - val_mae: 0.1833\n",
      "Epoch 1297/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0431 - mae: 0.1632 - val_loss: 0.0581 - val_mae: 0.1911\n",
      "Epoch 1298/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0456 - mae: 0.1687 - val_loss: 0.0492 - val_mae: 0.1689\n",
      "Epoch 1299/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0453 - mae: 0.1678 - val_loss: 0.0566 - val_mae: 0.1888\n",
      "Epoch 1300/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0497 - mae: 0.1788 - val_loss: 0.0681 - val_mae: 0.2067\n",
      "Epoch 1301/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0662 - mae: 0.2101 - val_loss: 0.1018 - val_mae: 0.2669\n",
      "Epoch 1302/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0668 - mae: 0.2117 - val_loss: 0.0795 - val_mae: 0.2278\n",
      "Epoch 1303/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0643 - mae: 0.2064 - val_loss: 0.0497 - val_mae: 0.1724\n",
      "Epoch 1304/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0655 - mae: 0.2058 - val_loss: 0.0917 - val_mae: 0.2475\n",
      "Epoch 1305/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0736 - mae: 0.2199 - val_loss: 0.0849 - val_mae: 0.2408\n",
      "Epoch 1306/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0715 - mae: 0.2151 - val_loss: 0.0843 - val_mae: 0.2380\n",
      "Epoch 1307/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1038 - mae: 0.2623 - val_loss: 0.1442 - val_mae: 0.3266\n",
      "Epoch 1308/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0937 - mae: 0.2530 - val_loss: 0.1318 - val_mae: 0.3121\n",
      "Epoch 1309/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0761 - mae: 0.2253 - val_loss: 0.0870 - val_mae: 0.2456\n",
      "Epoch 1310/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0664 - mae: 0.2087 - val_loss: 0.0605 - val_mae: 0.1973\n",
      "Epoch 1311/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0585 - mae: 0.1920 - val_loss: 0.0475 - val_mae: 0.1756\n",
      "Epoch 1312/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0646 - mae: 0.2064 - val_loss: 0.0563 - val_mae: 0.1898\n",
      "Epoch 1313/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0507 - mae: 0.1823 - val_loss: 0.0710 - val_mae: 0.2139\n",
      "Epoch 1314/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0537 - mae: 0.1880 - val_loss: 0.0637 - val_mae: 0.2020\n",
      "Epoch 1315/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0550 - mae: 0.1882 - val_loss: 0.0497 - val_mae: 0.1772\n",
      "Epoch 1316/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0515 - mae: 0.1789 - val_loss: 0.0515 - val_mae: 0.1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1317/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0590 - mae: 0.1965 - val_loss: 0.0557 - val_mae: 0.1870\n",
      "Epoch 1318/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0447 - mae: 0.1683 - val_loss: 0.0481 - val_mae: 0.1735\n",
      "Epoch 1319/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0386 - mae: 0.1569 - val_loss: 0.0461 - val_mae: 0.1676\n",
      "Epoch 1320/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0394 - mae: 0.1577 - val_loss: 0.0426 - val_mae: 0.1626\n",
      "Epoch 1321/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0406 - mae: 0.1607 - val_loss: 0.0400 - val_mae: 0.1580\n",
      "Epoch 1322/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0436 - mae: 0.1670 - val_loss: 0.0390 - val_mae: 0.1545\n",
      "Epoch 1323/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0362 - mae: 0.1508 - val_loss: 0.0507 - val_mae: 0.1795\n",
      "Epoch 1324/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0348 - mae: 0.1463 - val_loss: 0.0357 - val_mae: 0.1475\n",
      "Epoch 1325/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0341 - mae: 0.1450 - val_loss: 0.0369 - val_mae: 0.1547\n",
      "Epoch 1326/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0333 - mae: 0.1439 - val_loss: 0.0456 - val_mae: 0.1674\n",
      "Epoch 1327/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0336 - mae: 0.1441 - val_loss: 0.0432 - val_mae: 0.1622\n",
      "Epoch 1328/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0334 - mae: 0.1434 - val_loss: 0.0376 - val_mae: 0.1559\n",
      "Epoch 1329/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0327 - mae: 0.1425 - val_loss: 0.0418 - val_mae: 0.1595\n",
      "Epoch 1330/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0327 - mae: 0.1415 - val_loss: 0.0378 - val_mae: 0.1521\n",
      "Epoch 1331/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0325 - mae: 0.1414 - val_loss: 0.0366 - val_mae: 0.1470\n",
      "Epoch 1332/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0342 - mae: 0.1453 - val_loss: 0.0432 - val_mae: 0.1649\n",
      "Epoch 1333/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0345 - mae: 0.1461 - val_loss: 0.0416 - val_mae: 0.1625\n",
      "Epoch 1334/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0355 - mae: 0.1488 - val_loss: 0.0403 - val_mae: 0.1589\n",
      "Epoch 1335/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0334 - mae: 0.1429 - val_loss: 0.0373 - val_mae: 0.1537\n",
      "Epoch 1336/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0356 - mae: 0.1498 - val_loss: 0.0392 - val_mae: 0.1531\n",
      "Epoch 1337/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0324 - mae: 0.1404 - val_loss: 0.0449 - val_mae: 0.1694\n",
      "Epoch 1338/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0362 - mae: 0.1481 - val_loss: 0.0406 - val_mae: 0.1604\n",
      "Epoch 1339/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0370 - mae: 0.1515 - val_loss: 0.0448 - val_mae: 0.1651\n",
      "Epoch 1340/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0380 - mae: 0.1549 - val_loss: 0.0442 - val_mae: 0.1636\n",
      "Epoch 1341/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0403 - mae: 0.1574 - val_loss: 0.0621 - val_mae: 0.2091\n",
      "Epoch 1342/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0414 - mae: 0.1630 - val_loss: 0.0667 - val_mae: 0.2157\n",
      "Epoch 1343/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0604 - mae: 0.1994 - val_loss: 0.0506 - val_mae: 0.1758\n",
      "Epoch 1344/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0463 - mae: 0.1719 - val_loss: 0.0487 - val_mae: 0.1748\n",
      "Epoch 1345/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0460 - mae: 0.1699 - val_loss: 0.0548 - val_mae: 0.1886\n",
      "Epoch 1346/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0501 - mae: 0.1777 - val_loss: 0.0446 - val_mae: 0.1658\n",
      "Epoch 1347/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0450 - mae: 0.1696 - val_loss: 0.0467 - val_mae: 0.1704\n",
      "Epoch 1348/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0472 - mae: 0.1738 - val_loss: 0.0564 - val_mae: 0.1943\n",
      "Epoch 1349/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0446 - mae: 0.1672 - val_loss: 0.0487 - val_mae: 0.1791\n",
      "Epoch 1350/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0461 - mae: 0.1744 - val_loss: 0.0444 - val_mae: 0.1664\n",
      "Epoch 1351/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0491 - mae: 0.1796 - val_loss: 0.0912 - val_mae: 0.2564\n",
      "Epoch 1352/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0530 - mae: 0.1847 - val_loss: 0.0780 - val_mae: 0.2297\n",
      "Epoch 1353/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0560 - mae: 0.1932 - val_loss: 0.0394 - val_mae: 0.1563\n",
      "Epoch 1354/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0435 - mae: 0.1665 - val_loss: 0.0619 - val_mae: 0.2026\n",
      "Epoch 1355/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0548 - mae: 0.1888 - val_loss: 0.0427 - val_mae: 0.1639\n",
      "Epoch 1356/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0444 - mae: 0.1673 - val_loss: 0.0552 - val_mae: 0.1933\n",
      "Epoch 1357/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0397 - mae: 0.1589 - val_loss: 0.0543 - val_mae: 0.1860\n",
      "Epoch 1358/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0376 - mae: 0.1536 - val_loss: 0.0378 - val_mae: 0.1514\n",
      "Epoch 1359/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0338 - mae: 0.1452 - val_loss: 0.0369 - val_mae: 0.1507\n",
      "Epoch 1360/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0333 - mae: 0.1427 - val_loss: 0.0366 - val_mae: 0.1514\n",
      "Epoch 1361/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0338 - mae: 0.1449 - val_loss: 0.0414 - val_mae: 0.1614\n",
      "Epoch 1362/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0378 - mae: 0.1552 - val_loss: 0.0436 - val_mae: 0.1657\n",
      "Epoch 1363/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0347 - mae: 0.1470 - val_loss: 0.0422 - val_mae: 0.1632\n",
      "Epoch 1364/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0359 - mae: 0.1498 - val_loss: 0.0456 - val_mae: 0.1718\n",
      "Epoch 1365/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0448 - mae: 0.1674 - val_loss: 0.0569 - val_mae: 0.1960\n",
      "Epoch 1366/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0455 - mae: 0.1696 - val_loss: 0.0364 - val_mae: 0.1534\n",
      "Epoch 1367/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0429 - mae: 0.1629 - val_loss: 0.0469 - val_mae: 0.1747\n",
      "Epoch 1368/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0395 - mae: 0.1599 - val_loss: 0.0496 - val_mae: 0.1743\n",
      "Epoch 1369/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0393 - mae: 0.1581 - val_loss: 0.0418 - val_mae: 0.1624\n",
      "Epoch 1370/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0348 - mae: 0.1466 - val_loss: 0.0377 - val_mae: 0.1532\n",
      "Epoch 1371/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0333 - mae: 0.1435 - val_loss: 0.0436 - val_mae: 0.1633\n",
      "Epoch 1372/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0396 - mae: 0.1593 - val_loss: 0.0483 - val_mae: 0.1717\n",
      "Epoch 1373/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0377 - mae: 0.1534 - val_loss: 0.0513 - val_mae: 0.1817\n",
      "Epoch 1374/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0354 - mae: 0.1489 - val_loss: 0.0385 - val_mae: 0.1576\n",
      "Epoch 1375/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0379 - mae: 0.1541 - val_loss: 0.0464 - val_mae: 0.1675\n",
      "Epoch 1376/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0464 - mae: 0.1718 - val_loss: 0.0560 - val_mae: 0.1909\n",
      "Epoch 1377/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0393 - mae: 0.1587 - val_loss: 0.0509 - val_mae: 0.1790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1378/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0398 - mae: 0.1583 - val_loss: 0.0411 - val_mae: 0.1619\n",
      "Epoch 1379/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0395 - mae: 0.1579 - val_loss: 0.0484 - val_mae: 0.1768\n",
      "Epoch 1380/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0504 - mae: 0.1817 - val_loss: 0.0591 - val_mae: 0.1934\n",
      "Epoch 1381/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0455 - mae: 0.1700 - val_loss: 0.0703 - val_mae: 0.2153\n",
      "Epoch 1382/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0414 - mae: 0.1619 - val_loss: 0.0391 - val_mae: 0.1580\n",
      "Epoch 1383/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0340 - mae: 0.1447 - val_loss: 0.0425 - val_mae: 0.1648\n",
      "Epoch 1384/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0363 - mae: 0.1496 - val_loss: 0.0413 - val_mae: 0.1593\n",
      "Epoch 1385/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0369 - mae: 0.1535 - val_loss: 0.0552 - val_mae: 0.1873\n",
      "Epoch 1386/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0415 - mae: 0.1614 - val_loss: 0.0486 - val_mae: 0.1739\n",
      "Epoch 1387/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0388 - mae: 0.1580 - val_loss: 0.0392 - val_mae: 0.1589\n",
      "Epoch 1388/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0369 - mae: 0.1524 - val_loss: 0.0734 - val_mae: 0.2244\n",
      "Epoch 1389/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0491 - mae: 0.1768 - val_loss: 0.0437 - val_mae: 0.1666\n",
      "Epoch 1390/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0420 - mae: 0.1622 - val_loss: 0.0459 - val_mae: 0.1690\n",
      "Epoch 1391/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0388 - mae: 0.1567 - val_loss: 0.0561 - val_mae: 0.1882\n",
      "Epoch 1392/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0469 - mae: 0.1744 - val_loss: 0.0539 - val_mae: 0.1787\n",
      "Epoch 1393/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0403 - mae: 0.1581 - val_loss: 0.0417 - val_mae: 0.1634\n",
      "Epoch 1394/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0360 - mae: 0.1497 - val_loss: 0.0390 - val_mae: 0.1599\n",
      "Epoch 1395/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0411 - mae: 0.1637 - val_loss: 0.0458 - val_mae: 0.1654\n",
      "Epoch 1396/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0397 - mae: 0.1581 - val_loss: 0.0605 - val_mae: 0.1968\n",
      "Epoch 1397/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0402 - mae: 0.1601 - val_loss: 0.0665 - val_mae: 0.2197\n",
      "Epoch 1398/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0742 - mae: 0.2242 - val_loss: 0.0546 - val_mae: 0.1918\n",
      "Epoch 1399/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0793 - mae: 0.2256 - val_loss: 0.0721 - val_mae: 0.2156\n",
      "Epoch 1400/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0673 - mae: 0.2114 - val_loss: 0.0482 - val_mae: 0.1739\n",
      "Epoch 1401/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0561 - mae: 0.1884 - val_loss: 0.0723 - val_mae: 0.2210\n",
      "Epoch 1402/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0509 - mae: 0.1794 - val_loss: 0.0644 - val_mae: 0.2090\n",
      "Epoch 1403/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0454 - mae: 0.1684 - val_loss: 0.0522 - val_mae: 0.1794\n",
      "Epoch 1404/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0428 - mae: 0.1642 - val_loss: 0.0478 - val_mae: 0.1742\n",
      "Epoch 1405/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0403 - mae: 0.1590 - val_loss: 0.0427 - val_mae: 0.1608\n",
      "Epoch 1406/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0384 - mae: 0.1571 - val_loss: 0.0521 - val_mae: 0.1832\n",
      "Epoch 1407/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0344 - mae: 0.1473 - val_loss: 0.0412 - val_mae: 0.1610\n",
      "Epoch 1408/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0356 - mae: 0.1491 - val_loss: 0.0484 - val_mae: 0.1750\n",
      "Epoch 1409/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0408 - mae: 0.1619 - val_loss: 0.0442 - val_mae: 0.1638\n",
      "Epoch 1410/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0373 - mae: 0.1534 - val_loss: 0.0483 - val_mae: 0.1713\n",
      "Epoch 1411/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0338 - mae: 0.1450 - val_loss: 0.0380 - val_mae: 0.1536\n",
      "Epoch 1412/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0335 - mae: 0.1420 - val_loss: 0.0546 - val_mae: 0.1902\n",
      "Epoch 1413/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0367 - mae: 0.1524 - val_loss: 0.0460 - val_mae: 0.1709\n",
      "Epoch 1414/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0344 - mae: 0.1477 - val_loss: 0.0425 - val_mae: 0.1658\n",
      "Epoch 1415/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0319 - mae: 0.1409 - val_loss: 0.0364 - val_mae: 0.1512\n",
      "Epoch 1416/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0342 - mae: 0.1462 - val_loss: 0.0422 - val_mae: 0.1671\n",
      "Epoch 1417/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0367 - mae: 0.1544 - val_loss: 0.0578 - val_mae: 0.1981\n",
      "Epoch 1418/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0410 - mae: 0.1623 - val_loss: 0.0405 - val_mae: 0.1567\n",
      "Epoch 1419/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0372 - mae: 0.1541 - val_loss: 0.0382 - val_mae: 0.1544\n",
      "Epoch 1420/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0315 - mae: 0.1400 - val_loss: 0.0365 - val_mae: 0.1499\n",
      "Epoch 1421/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0351 - mae: 0.1479 - val_loss: 0.0443 - val_mae: 0.1684\n",
      "Epoch 1422/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0385 - mae: 0.1566 - val_loss: 0.0438 - val_mae: 0.1666\n",
      "Epoch 1423/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0363 - mae: 0.1497 - val_loss: 0.0399 - val_mae: 0.1578\n",
      "Epoch 1424/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0375 - mae: 0.1524 - val_loss: 0.0419 - val_mae: 0.1606\n",
      "Epoch 1425/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0346 - mae: 0.1460 - val_loss: 0.0437 - val_mae: 0.1655\n",
      "Epoch 1426/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0389 - mae: 0.1550 - val_loss: 0.0379 - val_mae: 0.1497\n",
      "Epoch 1427/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0346 - mae: 0.1484 - val_loss: 0.0590 - val_mae: 0.1951\n",
      "Epoch 1428/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0395 - mae: 0.1575 - val_loss: 0.0447 - val_mae: 0.1676\n",
      "Epoch 1429/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0396 - mae: 0.1580 - val_loss: 0.0399 - val_mae: 0.1572\n",
      "Epoch 1430/2000\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0391 - mae: 0.1562 - val_loss: 0.0541 - val_mae: 0.1846\n",
      "Epoch 1431/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0467 - mae: 0.1715 - val_loss: 0.0497 - val_mae: 0.1761\n",
      "Epoch 1432/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0450 - mae: 0.1684 - val_loss: 0.0586 - val_mae: 0.1923\n",
      "Epoch 1433/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0413 - mae: 0.1615 - val_loss: 0.0498 - val_mae: 0.1745\n",
      "Epoch 1434/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0387 - mae: 0.1558 - val_loss: 0.0410 - val_mae: 0.1634\n",
      "Epoch 1435/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0406 - mae: 0.1599 - val_loss: 0.0483 - val_mae: 0.1793\n",
      "Epoch 1436/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0440 - mae: 0.1699 - val_loss: 0.0617 - val_mae: 0.2016\n",
      "Epoch 1437/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0407 - mae: 0.1615 - val_loss: 0.0469 - val_mae: 0.1715\n",
      "Epoch 1438/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0389 - mae: 0.1575 - val_loss: 0.0429 - val_mae: 0.1690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1439/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0370 - mae: 0.1534 - val_loss: 0.0435 - val_mae: 0.1659\n",
      "Epoch 1440/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0440 - mae: 0.1672 - val_loss: 0.0475 - val_mae: 0.1727\n",
      "Epoch 1441/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0397 - mae: 0.1583 - val_loss: 0.0644 - val_mae: 0.2051\n",
      "Epoch 1442/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0410 - mae: 0.1604 - val_loss: 0.0398 - val_mae: 0.1597\n",
      "Epoch 1443/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0365 - mae: 0.1507 - val_loss: 0.0422 - val_mae: 0.1681\n",
      "Epoch 1444/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0395 - mae: 0.1575 - val_loss: 0.0418 - val_mae: 0.1623\n",
      "Epoch 1445/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0395 - mae: 0.1585 - val_loss: 0.0459 - val_mae: 0.1668\n",
      "Epoch 1446/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0371 - mae: 0.1516 - val_loss: 0.0393 - val_mae: 0.1589\n",
      "Epoch 1447/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0340 - mae: 0.1453 - val_loss: 0.0436 - val_mae: 0.1676\n",
      "Epoch 1448/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0356 - mae: 0.1497 - val_loss: 0.0472 - val_mae: 0.1763\n",
      "Epoch 1449/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0379 - mae: 0.1528 - val_loss: 0.0406 - val_mae: 0.1625\n",
      "Epoch 1450/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0394 - mae: 0.1594 - val_loss: 0.0426 - val_mae: 0.1627\n",
      "Epoch 1451/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0398 - mae: 0.1593 - val_loss: 0.0584 - val_mae: 0.1918\n",
      "Epoch 1452/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0376 - mae: 0.1536 - val_loss: 0.0616 - val_mae: 0.2043\n",
      "Epoch 1453/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0438 - mae: 0.1683 - val_loss: 0.0487 - val_mae: 0.1735\n",
      "Epoch 1454/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0425 - mae: 0.1641 - val_loss: 0.0447 - val_mae: 0.1633\n",
      "Epoch 1455/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0401 - mae: 0.1595 - val_loss: 0.0410 - val_mae: 0.1602\n",
      "Epoch 1456/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0362 - mae: 0.1510 - val_loss: 0.0442 - val_mae: 0.1679\n",
      "Epoch 1457/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0380 - mae: 0.1548 - val_loss: 0.0551 - val_mae: 0.1850\n",
      "Epoch 1458/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0397 - mae: 0.1573 - val_loss: 0.0533 - val_mae: 0.1817\n",
      "Epoch 1459/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0507 - mae: 0.1803 - val_loss: 0.0459 - val_mae: 0.1704\n",
      "Epoch 1460/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0478 - mae: 0.1764 - val_loss: 0.0706 - val_mae: 0.2250\n",
      "Epoch 1461/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0566 - mae: 0.1925 - val_loss: 0.0554 - val_mae: 0.1858\n",
      "Epoch 1462/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0536 - mae: 0.1862 - val_loss: 0.0659 - val_mae: 0.2104\n",
      "Epoch 1463/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0500 - mae: 0.1813 - val_loss: 0.0696 - val_mae: 0.2111\n",
      "Epoch 1464/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0538 - mae: 0.1850 - val_loss: 0.0515 - val_mae: 0.1804\n",
      "Epoch 1465/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0486 - mae: 0.1736 - val_loss: 0.0446 - val_mae: 0.1685\n",
      "Epoch 1466/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0469 - mae: 0.1740 - val_loss: 0.0479 - val_mae: 0.1729\n",
      "Epoch 1467/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0475 - mae: 0.1763 - val_loss: 0.0809 - val_mae: 0.2316\n",
      "Epoch 1468/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0565 - mae: 0.1900 - val_loss: 0.0466 - val_mae: 0.1700\n",
      "Epoch 1469/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0503 - mae: 0.1807 - val_loss: 0.0464 - val_mae: 0.1686\n",
      "Epoch 1470/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0475 - mae: 0.1747 - val_loss: 0.0503 - val_mae: 0.1822\n",
      "Epoch 1471/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0447 - mae: 0.1691 - val_loss: 0.0686 - val_mae: 0.2161\n",
      "Epoch 1472/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0478 - mae: 0.1748 - val_loss: 0.0489 - val_mae: 0.1788\n",
      "Epoch 1473/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0439 - mae: 0.1677 - val_loss: 0.0460 - val_mae: 0.1720\n",
      "Epoch 1474/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0430 - mae: 0.1652 - val_loss: 0.0482 - val_mae: 0.1738\n",
      "Epoch 1475/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0444 - mae: 0.1673 - val_loss: 0.0440 - val_mae: 0.1695\n",
      "Epoch 1476/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0483 - mae: 0.1755 - val_loss: 0.0574 - val_mae: 0.1929\n",
      "Epoch 1477/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0443 - mae: 0.1690 - val_loss: 0.0636 - val_mae: 0.2072\n",
      "Epoch 1478/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0549 - mae: 0.1892 - val_loss: 0.0433 - val_mae: 0.1633\n",
      "Epoch 1479/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0456 - mae: 0.1696 - val_loss: 0.0655 - val_mae: 0.2011\n",
      "Epoch 1480/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0761 - mae: 0.2172 - val_loss: 0.0825 - val_mae: 0.2309\n",
      "Epoch 1481/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0842 - mae: 0.2322 - val_loss: 0.0793 - val_mae: 0.2160\n",
      "Epoch 1482/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0733 - mae: 0.2117 - val_loss: 0.0861 - val_mae: 0.2237\n",
      "Epoch 1483/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0722 - mae: 0.2102 - val_loss: 0.0695 - val_mae: 0.2054\n",
      "Epoch 1484/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0692 - mae: 0.2061 - val_loss: 0.0868 - val_mae: 0.2298\n",
      "Epoch 1485/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0778 - mae: 0.2204 - val_loss: 0.0697 - val_mae: 0.2022\n",
      "Epoch 1486/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0705 - mae: 0.2114 - val_loss: 0.0793 - val_mae: 0.2226\n",
      "Epoch 1487/2000\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0829 - mae: 0.2242 - val_loss: 0.0884 - val_mae: 0.2475\n",
      "Epoch 1488/2000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0928 - mae: 0.2428 - val_loss: 0.0907 - val_mae: 0.2344\n",
      "Epoch 1489/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0798 - mae: 0.2247 - val_loss: 0.0650 - val_mae: 0.2021\n",
      "Epoch 1490/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0717 - mae: 0.2117 - val_loss: 0.0668 - val_mae: 0.2036\n",
      "Epoch 1491/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0655 - mae: 0.2014 - val_loss: 0.0815 - val_mae: 0.2173\n",
      "Epoch 1492/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0690 - mae: 0.2037 - val_loss: 0.0713 - val_mae: 0.2194\n",
      "Epoch 1493/2000\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0706 - mae: 0.2120 - val_loss: 0.0719 - val_mae: 0.2126\n",
      "Epoch 1494/2000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0657 - mae: 0.2022 - val_loss: 0.0749 - val_mae: 0.2249\n",
      "Epoch 1495/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0761 - mae: 0.2212 - val_loss: 0.0783 - val_mae: 0.2161\n",
      "Epoch 1496/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0742 - mae: 0.2131 - val_loss: 0.0712 - val_mae: 0.2085\n",
      "Epoch 1497/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0775 - mae: 0.2193 - val_loss: 0.0715 - val_mae: 0.2059\n",
      "Epoch 1498/2000\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0652 - mae: 0.2004 - val_loss: 0.0738 - val_mae: 0.2065\n",
      "Epoch 1499/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0640 - mae: 0.1968 - val_loss: 0.0678 - val_mae: 0.2124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0655 - mae: 0.2017 - val_loss: 0.0578 - val_mae: 0.1902\n",
      "Epoch 1501/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0646 - mae: 0.1986 - val_loss: 0.0598 - val_mae: 0.1911\n",
      "Epoch 1502/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0582 - mae: 0.1912 - val_loss: 0.0845 - val_mae: 0.2208\n",
      "Epoch 1503/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0669 - mae: 0.2026 - val_loss: 0.0710 - val_mae: 0.2209\n",
      "Epoch 1504/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0748 - mae: 0.2169 - val_loss: 0.0803 - val_mae: 0.2178\n",
      "Epoch 1505/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0617 - mae: 0.1945 - val_loss: 0.0565 - val_mae: 0.1861\n",
      "Epoch 1506/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0614 - mae: 0.1952 - val_loss: 0.0682 - val_mae: 0.2020\n",
      "Epoch 1507/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0560 - mae: 0.1862 - val_loss: 0.0562 - val_mae: 0.1804\n",
      "Epoch 1508/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0488 - mae: 0.1714 - val_loss: 0.0491 - val_mae: 0.1756\n",
      "Epoch 1509/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0471 - mae: 0.1706 - val_loss: 0.0517 - val_mae: 0.1702\n",
      "Epoch 1510/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0464 - mae: 0.1692 - val_loss: 0.0488 - val_mae: 0.1737\n",
      "Epoch 1511/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0502 - mae: 0.1783 - val_loss: 0.0889 - val_mae: 0.2263\n",
      "Epoch 1512/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0604 - mae: 0.1931 - val_loss: 0.0546 - val_mae: 0.1851\n",
      "Epoch 1513/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0581 - mae: 0.1927 - val_loss: 0.0701 - val_mae: 0.2204\n",
      "Epoch 1514/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0641 - mae: 0.2054 - val_loss: 0.0598 - val_mae: 0.1850\n",
      "Epoch 1515/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0566 - mae: 0.1879 - val_loss: 0.0925 - val_mae: 0.2408\n",
      "Epoch 1516/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0743 - mae: 0.2194 - val_loss: 0.0644 - val_mae: 0.2060\n",
      "Epoch 1517/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0672 - mae: 0.2061 - val_loss: 0.0566 - val_mae: 0.1901\n",
      "Epoch 1518/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0752 - mae: 0.2229 - val_loss: 0.1185 - val_mae: 0.2743\n",
      "Epoch 1519/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0721 - mae: 0.2126 - val_loss: 0.1094 - val_mae: 0.2727\n",
      "Epoch 1520/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0743 - mae: 0.2199 - val_loss: 0.0648 - val_mae: 0.1995\n",
      "Epoch 1521/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0601 - mae: 0.1937 - val_loss: 0.0569 - val_mae: 0.1872\n",
      "Epoch 1522/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0549 - mae: 0.1854 - val_loss: 0.0619 - val_mae: 0.1895\n",
      "Epoch 1523/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0648 - mae: 0.2018 - val_loss: 0.0632 - val_mae: 0.2008\n",
      "Epoch 1524/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0609 - mae: 0.1986 - val_loss: 0.0605 - val_mae: 0.1993\n",
      "Epoch 1525/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0622 - mae: 0.1978 - val_loss: 0.0608 - val_mae: 0.1996\n",
      "Epoch 1526/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0528 - mae: 0.1838 - val_loss: 0.0715 - val_mae: 0.2069\n",
      "Epoch 1527/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0538 - mae: 0.1847 - val_loss: 0.0547 - val_mae: 0.1872\n",
      "Epoch 1528/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0527 - mae: 0.1820 - val_loss: 0.0623 - val_mae: 0.2009\n",
      "Epoch 1529/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0598 - mae: 0.1946 - val_loss: 0.0641 - val_mae: 0.2006\n",
      "Epoch 1530/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0508 - mae: 0.1783 - val_loss: 0.0658 - val_mae: 0.2008\n",
      "Epoch 1531/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0559 - mae: 0.1865 - val_loss: 0.0584 - val_mae: 0.1979\n",
      "Epoch 1532/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0511 - mae: 0.1815 - val_loss: 0.0511 - val_mae: 0.1791\n",
      "Epoch 1533/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0494 - mae: 0.1789 - val_loss: 0.0594 - val_mae: 0.1895\n",
      "Epoch 1534/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0516 - mae: 0.1777 - val_loss: 0.0634 - val_mae: 0.2015\n",
      "Epoch 1535/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0524 - mae: 0.1803 - val_loss: 0.0480 - val_mae: 0.1789\n",
      "Epoch 1536/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0598 - mae: 0.1963 - val_loss: 0.0654 - val_mae: 0.2052\n",
      "Epoch 1537/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0533 - mae: 0.1840 - val_loss: 0.0514 - val_mae: 0.1764\n",
      "Epoch 1538/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0501 - mae: 0.1796 - val_loss: 0.0523 - val_mae: 0.1856\n",
      "Epoch 1539/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0429 - mae: 0.1646 - val_loss: 0.0528 - val_mae: 0.1838\n",
      "Epoch 1540/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0430 - mae: 0.1649 - val_loss: 0.0444 - val_mae: 0.1648\n",
      "Epoch 1541/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0450 - mae: 0.1689 - val_loss: 0.0635 - val_mae: 0.2021\n",
      "Epoch 1542/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0606 - mae: 0.1961 - val_loss: 0.0519 - val_mae: 0.1835\n",
      "Epoch 1543/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0511 - mae: 0.1801 - val_loss: 0.0557 - val_mae: 0.1904\n",
      "Epoch 1544/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0530 - mae: 0.1859 - val_loss: 0.0537 - val_mae: 0.1822\n",
      "Epoch 1545/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0536 - mae: 0.1853 - val_loss: 0.0636 - val_mae: 0.1995\n",
      "Epoch 1546/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0490 - mae: 0.1770 - val_loss: 0.0729 - val_mae: 0.2093\n",
      "Epoch 1547/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0559 - mae: 0.1879 - val_loss: 0.0500 - val_mae: 0.1796\n",
      "Epoch 1548/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0405 - mae: 0.1603 - val_loss: 0.0447 - val_mae: 0.1702\n",
      "Epoch 1549/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0485 - mae: 0.1749 - val_loss: 0.0700 - val_mae: 0.2116\n",
      "Epoch 1550/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0528 - mae: 0.1833 - val_loss: 0.1047 - val_mae: 0.2662\n",
      "Epoch 1551/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0583 - mae: 0.1941 - val_loss: 0.0566 - val_mae: 0.1895\n",
      "Epoch 1552/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0506 - mae: 0.1775 - val_loss: 0.0505 - val_mae: 0.1785\n",
      "Epoch 1553/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0463 - mae: 0.1713 - val_loss: 0.0481 - val_mae: 0.1720\n",
      "Epoch 1554/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0480 - mae: 0.1758 - val_loss: 0.0601 - val_mae: 0.1859\n",
      "Epoch 1555/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0501 - mae: 0.1768 - val_loss: 0.0506 - val_mae: 0.1811\n",
      "Epoch 1556/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0443 - mae: 0.1655 - val_loss: 0.0489 - val_mae: 0.1741\n",
      "Epoch 1557/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0459 - mae: 0.1690 - val_loss: 0.0537 - val_mae: 0.1882\n",
      "Epoch 1558/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0479 - mae: 0.1741 - val_loss: 0.0507 - val_mae: 0.1765\n",
      "Epoch 1559/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0490 - mae: 0.1762 - val_loss: 0.0557 - val_mae: 0.1868\n",
      "Epoch 1560/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0488 - mae: 0.1763 - val_loss: 0.0451 - val_mae: 0.1684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1561/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0435 - mae: 0.1658 - val_loss: 0.0450 - val_mae: 0.1701\n",
      "Epoch 1562/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0442 - mae: 0.1679 - val_loss: 0.0681 - val_mae: 0.2112\n",
      "Epoch 1563/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0584 - mae: 0.1931 - val_loss: 0.0550 - val_mae: 0.1894\n",
      "Epoch 1564/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0884 - mae: 0.2368 - val_loss: 0.0648 - val_mae: 0.1995\n",
      "Epoch 1565/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0786 - mae: 0.2279 - val_loss: 0.0646 - val_mae: 0.1951\n",
      "Epoch 1566/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0666 - mae: 0.2046 - val_loss: 0.1064 - val_mae: 0.2503\n",
      "Epoch 1567/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0798 - mae: 0.2263 - val_loss: 0.0778 - val_mae: 0.2161\n",
      "Epoch 1568/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0717 - mae: 0.2134 - val_loss: 0.0766 - val_mae: 0.2200\n",
      "Epoch 1569/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0761 - mae: 0.2196 - val_loss: 0.0805 - val_mae: 0.2228\n",
      "Epoch 1570/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0727 - mae: 0.2154 - val_loss: 0.0707 - val_mae: 0.2052\n",
      "Epoch 1571/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0802 - mae: 0.2249 - val_loss: 0.1006 - val_mae: 0.2623\n",
      "Epoch 1572/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0858 - mae: 0.2345 - val_loss: 0.0625 - val_mae: 0.1950\n",
      "Epoch 1573/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0792 - mae: 0.2220 - val_loss: 0.0891 - val_mae: 0.2330\n",
      "Epoch 1574/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0808 - mae: 0.2260 - val_loss: 0.0545 - val_mae: 0.1797\n",
      "Epoch 1575/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0701 - mae: 0.2089 - val_loss: 0.0796 - val_mae: 0.2262\n",
      "Epoch 1576/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0848 - mae: 0.2325 - val_loss: 0.0987 - val_mae: 0.2451\n",
      "Epoch 1577/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0757 - mae: 0.2176 - val_loss: 0.0910 - val_mae: 0.2393\n",
      "Epoch 1578/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0727 - mae: 0.2127 - val_loss: 0.0689 - val_mae: 0.1999\n",
      "Epoch 1579/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0694 - mae: 0.2104 - val_loss: 0.0643 - val_mae: 0.1997\n",
      "Epoch 1580/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0721 - mae: 0.2135 - val_loss: 0.0624 - val_mae: 0.1951\n",
      "Epoch 1581/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0653 - mae: 0.1986 - val_loss: 0.0752 - val_mae: 0.2129\n",
      "Epoch 1582/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0736 - mae: 0.2127 - val_loss: 0.0712 - val_mae: 0.2108\n",
      "Epoch 1583/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0825 - mae: 0.2253 - val_loss: 0.0742 - val_mae: 0.2184\n",
      "Epoch 1584/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0779 - mae: 0.2215 - val_loss: 0.0919 - val_mae: 0.2448\n",
      "Epoch 1585/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0868 - mae: 0.2365 - val_loss: 0.1362 - val_mae: 0.3005\n",
      "Epoch 1586/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0949 - mae: 0.2483 - val_loss: 0.0652 - val_mae: 0.1936\n",
      "Epoch 1587/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0785 - mae: 0.2231 - val_loss: 0.0696 - val_mae: 0.2226\n",
      "Epoch 1588/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0778 - mae: 0.2225 - val_loss: 0.0660 - val_mae: 0.2091\n",
      "Epoch 1589/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0736 - mae: 0.2155 - val_loss: 0.0796 - val_mae: 0.2122\n",
      "Epoch 1590/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0743 - mae: 0.2141 - val_loss: 0.0898 - val_mae: 0.2261\n",
      "Epoch 1591/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0750 - mae: 0.2180 - val_loss: 0.0738 - val_mae: 0.2124\n",
      "Epoch 1592/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0789 - mae: 0.2229 - val_loss: 0.0683 - val_mae: 0.2128\n",
      "Epoch 1593/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0701 - mae: 0.2090 - val_loss: 0.0727 - val_mae: 0.2125\n",
      "Epoch 1594/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0716 - mae: 0.2122 - val_loss: 0.0660 - val_mae: 0.1995\n",
      "Epoch 1595/2000\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0633 - mae: 0.1976 - val_loss: 0.0612 - val_mae: 0.1962\n",
      "Epoch 1596/2000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0603 - mae: 0.1906 - val_loss: 0.0580 - val_mae: 0.1858\n",
      "Epoch 1597/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0585 - mae: 0.1896 - val_loss: 0.0640 - val_mae: 0.2029\n",
      "Epoch 1598/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0649 - mae: 0.1989 - val_loss: 0.0760 - val_mae: 0.2108\n",
      "Epoch 1599/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0734 - mae: 0.2152 - val_loss: 0.1317 - val_mae: 0.2955\n",
      "Epoch 1600/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0821 - mae: 0.2300 - val_loss: 0.1006 - val_mae: 0.2470\n",
      "Epoch 1601/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0728 - mae: 0.2137 - val_loss: 0.0759 - val_mae: 0.2053\n",
      "Epoch 1602/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0697 - mae: 0.2108 - val_loss: 0.0699 - val_mae: 0.2057\n",
      "Epoch 1603/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0684 - mae: 0.2067 - val_loss: 0.0700 - val_mae: 0.2045\n",
      "Epoch 1604/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0715 - mae: 0.2086 - val_loss: 0.0741 - val_mae: 0.2163\n",
      "Epoch 1605/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0707 - mae: 0.2091 - val_loss: 0.0667 - val_mae: 0.2045\n",
      "Epoch 1606/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0714 - mae: 0.2129 - val_loss: 0.0928 - val_mae: 0.2351\n",
      "Epoch 1607/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0731 - mae: 0.2122 - val_loss: 0.0624 - val_mae: 0.1955\n",
      "Epoch 1608/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0664 - mae: 0.2015 - val_loss: 0.0653 - val_mae: 0.2003\n",
      "Epoch 1609/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0626 - mae: 0.1979 - val_loss: 0.0600 - val_mae: 0.1924\n",
      "Epoch 1610/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0639 - mae: 0.2003 - val_loss: 0.0640 - val_mae: 0.1948\n",
      "Epoch 1611/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0689 - mae: 0.2069 - val_loss: 0.0761 - val_mae: 0.2025\n",
      "Epoch 1612/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0649 - mae: 0.1999 - val_loss: 0.0653 - val_mae: 0.1991\n",
      "Epoch 1613/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0651 - mae: 0.2004 - val_loss: 0.0662 - val_mae: 0.1948\n",
      "Epoch 1614/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0622 - mae: 0.1963 - val_loss: 0.0671 - val_mae: 0.1996\n",
      "Epoch 1615/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0611 - mae: 0.1912 - val_loss: 0.0651 - val_mae: 0.1921\n",
      "Epoch 1616/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0625 - mae: 0.1957 - val_loss: 0.0811 - val_mae: 0.2149\n",
      "Epoch 1617/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0694 - mae: 0.2059 - val_loss: 0.0857 - val_mae: 0.2323\n",
      "Epoch 1618/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0803 - mae: 0.2235 - val_loss: 0.0900 - val_mae: 0.2423\n",
      "Epoch 1619/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0808 - mae: 0.2267 - val_loss: 0.0649 - val_mae: 0.2060\n",
      "Epoch 1620/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0715 - mae: 0.2137 - val_loss: 0.1082 - val_mae: 0.2586\n",
      "Epoch 1621/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0794 - mae: 0.2223 - val_loss: 0.0655 - val_mae: 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1622/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0725 - mae: 0.2122 - val_loss: 0.0684 - val_mae: 0.2039\n",
      "Epoch 1623/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0656 - mae: 0.2008 - val_loss: 0.0586 - val_mae: 0.1836\n",
      "Epoch 1624/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0612 - mae: 0.1943 - val_loss: 0.0628 - val_mae: 0.2011\n",
      "Epoch 1625/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0665 - mae: 0.2025 - val_loss: 0.0662 - val_mae: 0.1926\n",
      "Epoch 1626/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0592 - mae: 0.1874 - val_loss: 0.0619 - val_mae: 0.1916\n",
      "Epoch 1627/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0603 - mae: 0.1932 - val_loss: 0.0794 - val_mae: 0.2166\n",
      "Epoch 1628/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0711 - mae: 0.2122 - val_loss: 0.0991 - val_mae: 0.2447\n",
      "Epoch 1629/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0735 - mae: 0.2151 - val_loss: 0.0776 - val_mae: 0.2091\n",
      "Epoch 1630/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0660 - mae: 0.1996 - val_loss: 0.0696 - val_mae: 0.2019\n",
      "Epoch 1631/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0628 - mae: 0.1931 - val_loss: 0.0597 - val_mae: 0.1940\n",
      "Epoch 1632/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0673 - mae: 0.2044 - val_loss: 0.1303 - val_mae: 0.2896\n",
      "Epoch 1633/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0947 - mae: 0.2448 - val_loss: 0.0698 - val_mae: 0.1998\n",
      "Epoch 1634/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0780 - mae: 0.2220 - val_loss: 0.0886 - val_mae: 0.2380\n",
      "Epoch 1635/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0822 - mae: 0.2270 - val_loss: 0.0771 - val_mae: 0.2205\n",
      "Epoch 1636/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0838 - mae: 0.2300 - val_loss: 0.0747 - val_mae: 0.2196\n",
      "Epoch 1637/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0744 - mae: 0.2164 - val_loss: 0.0740 - val_mae: 0.2107\n",
      "Epoch 1638/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0690 - mae: 0.2081 - val_loss: 0.0706 - val_mae: 0.1997\n",
      "Epoch 1639/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0656 - mae: 0.2015 - val_loss: 0.0659 - val_mae: 0.1938\n",
      "Epoch 1640/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0604 - mae: 0.1898 - val_loss: 0.0645 - val_mae: 0.2032\n",
      "Epoch 1641/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0654 - mae: 0.2001 - val_loss: 0.0565 - val_mae: 0.1829\n",
      "Epoch 1642/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0614 - mae: 0.1941 - val_loss: 0.0652 - val_mae: 0.1914\n",
      "Epoch 1643/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0642 - mae: 0.1971 - val_loss: 0.0673 - val_mae: 0.2012\n",
      "Epoch 1644/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0622 - mae: 0.1974 - val_loss: 0.0703 - val_mae: 0.1965\n",
      "Epoch 1645/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0642 - mae: 0.1966 - val_loss: 0.0640 - val_mae: 0.2005\n",
      "Epoch 1646/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0612 - mae: 0.1943 - val_loss: 0.0604 - val_mae: 0.1857\n",
      "Epoch 1647/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0592 - mae: 0.1888 - val_loss: 0.0598 - val_mae: 0.1877\n",
      "Epoch 1648/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0602 - mae: 0.1932 - val_loss: 0.0594 - val_mae: 0.1886\n",
      "Epoch 1649/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0622 - mae: 0.1933 - val_loss: 0.0719 - val_mae: 0.2184\n",
      "Epoch 1650/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0731 - mae: 0.2142 - val_loss: 0.0643 - val_mae: 0.2031\n",
      "Epoch 1651/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0613 - mae: 0.1946 - val_loss: 0.0685 - val_mae: 0.2050\n",
      "Epoch 1652/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0654 - mae: 0.2012 - val_loss: 0.0633 - val_mae: 0.1837\n",
      "Epoch 1653/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0606 - mae: 0.1904 - val_loss: 0.0709 - val_mae: 0.2082\n",
      "Epoch 1654/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0686 - mae: 0.2058 - val_loss: 0.0772 - val_mae: 0.2156\n",
      "Epoch 1655/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0749 - mae: 0.2164 - val_loss: 0.0660 - val_mae: 0.2089\n",
      "Epoch 1656/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0701 - mae: 0.2092 - val_loss: 0.0653 - val_mae: 0.1962\n",
      "Epoch 1657/2000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0605 - mae: 0.1911 - val_loss: 0.0598 - val_mae: 0.1852\n",
      "Epoch 1658/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0603 - mae: 0.1901 - val_loss: 0.0559 - val_mae: 0.1781\n",
      "Epoch 1659/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0550 - mae: 0.1821 - val_loss: 0.0630 - val_mae: 0.1935\n",
      "Epoch 1660/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0607 - mae: 0.1934 - val_loss: 0.0587 - val_mae: 0.1865\n",
      "Epoch 1661/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0591 - mae: 0.1908 - val_loss: 0.0571 - val_mae: 0.1833\n",
      "Epoch 1662/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0577 - mae: 0.1872 - val_loss: 0.0611 - val_mae: 0.1840\n",
      "Epoch 1663/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0584 - mae: 0.1889 - val_loss: 0.0587 - val_mae: 0.1851\n",
      "Epoch 1664/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0604 - mae: 0.1896 - val_loss: 0.0578 - val_mae: 0.1917\n",
      "Epoch 1665/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0607 - mae: 0.1950 - val_loss: 0.0679 - val_mae: 0.1936\n",
      "Epoch 1666/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0654 - mae: 0.1986 - val_loss: 0.0622 - val_mae: 0.1926\n",
      "Epoch 1667/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0615 - mae: 0.1926 - val_loss: 0.0667 - val_mae: 0.1973\n",
      "Epoch 1668/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0583 - mae: 0.1889 - val_loss: 0.0623 - val_mae: 0.1871\n",
      "Epoch 1669/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0589 - mae: 0.1903 - val_loss: 0.0726 - val_mae: 0.2078\n",
      "Epoch 1670/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0604 - mae: 0.1910 - val_loss: 0.0633 - val_mae: 0.1971\n",
      "Epoch 1671/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0614 - mae: 0.1932 - val_loss: 0.0596 - val_mae: 0.1965\n",
      "Epoch 1672/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0618 - mae: 0.1958 - val_loss: 0.0836 - val_mae: 0.2165\n",
      "Epoch 1673/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0635 - mae: 0.1959 - val_loss: 0.0616 - val_mae: 0.1925\n",
      "Epoch 1674/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0618 - mae: 0.1946 - val_loss: 0.0689 - val_mae: 0.2115\n",
      "Epoch 1675/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0707 - mae: 0.2112 - val_loss: 0.1012 - val_mae: 0.2499\n",
      "Epoch 1676/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0750 - mae: 0.2185 - val_loss: 0.0677 - val_mae: 0.2006\n",
      "Epoch 1677/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0654 - mae: 0.1998 - val_loss: 0.0778 - val_mae: 0.2154\n",
      "Epoch 1678/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0665 - mae: 0.2010 - val_loss: 0.0606 - val_mae: 0.1840\n",
      "Epoch 1679/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0579 - mae: 0.1846 - val_loss: 0.0733 - val_mae: 0.2036\n",
      "Epoch 1680/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0646 - mae: 0.1994 - val_loss: 0.0884 - val_mae: 0.2265\n",
      "Epoch 1681/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0705 - mae: 0.2082 - val_loss: 0.0692 - val_mae: 0.2144\n",
      "Epoch 1682/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0785 - mae: 0.2237 - val_loss: 0.0733 - val_mae: 0.2214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1683/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0787 - mae: 0.2223 - val_loss: 0.0675 - val_mae: 0.2076\n",
      "Epoch 1684/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0769 - mae: 0.2192 - val_loss: 0.0693 - val_mae: 0.2040\n",
      "Epoch 1685/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0850 - mae: 0.2320 - val_loss: 0.0754 - val_mae: 0.2131\n",
      "Epoch 1686/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0749 - mae: 0.2184 - val_loss: 0.0713 - val_mae: 0.2066\n",
      "Epoch 1687/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0700 - mae: 0.2086 - val_loss: 0.0730 - val_mae: 0.2117\n",
      "Epoch 1688/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0661 - mae: 0.2035 - val_loss: 0.0635 - val_mae: 0.2024\n",
      "Epoch 1689/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0702 - mae: 0.2078 - val_loss: 0.0710 - val_mae: 0.2113\n",
      "Epoch 1690/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0746 - mae: 0.2128 - val_loss: 0.0769 - val_mae: 0.2186\n",
      "Epoch 1691/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0842 - mae: 0.2284 - val_loss: 0.0826 - val_mae: 0.2172\n",
      "Epoch 1692/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0818 - mae: 0.2287 - val_loss: 0.0651 - val_mae: 0.2028\n",
      "Epoch 1693/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0656 - mae: 0.2026 - val_loss: 0.0645 - val_mae: 0.1988\n",
      "Epoch 1694/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0647 - mae: 0.2023 - val_loss: 0.0721 - val_mae: 0.2038\n",
      "Epoch 1695/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0659 - mae: 0.2021 - val_loss: 0.0638 - val_mae: 0.1972\n",
      "Epoch 1696/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0643 - mae: 0.2006 - val_loss: 0.0672 - val_mae: 0.2062\n",
      "Epoch 1697/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0716 - mae: 0.2120 - val_loss: 0.0719 - val_mae: 0.2176\n",
      "Epoch 1698/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0745 - mae: 0.2169 - val_loss: 0.0800 - val_mae: 0.2253\n",
      "Epoch 1699/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0704 - mae: 0.2118 - val_loss: 0.0890 - val_mae: 0.2259\n",
      "Epoch 1700/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0747 - mae: 0.2164 - val_loss: 0.0640 - val_mae: 0.1944\n",
      "Epoch 1701/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0655 - mae: 0.2017 - val_loss: 0.0685 - val_mae: 0.2027\n",
      "Epoch 1702/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0598 - mae: 0.1914 - val_loss: 0.0765 - val_mae: 0.2120\n",
      "Epoch 1703/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0668 - mae: 0.2028 - val_loss: 0.0776 - val_mae: 0.2258\n",
      "Epoch 1704/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0750 - mae: 0.2180 - val_loss: 0.0579 - val_mae: 0.1822\n",
      "Epoch 1705/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0612 - mae: 0.1932 - val_loss: 0.0704 - val_mae: 0.2005\n",
      "Epoch 1706/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0646 - mae: 0.1985 - val_loss: 0.0630 - val_mae: 0.2007\n",
      "Epoch 1707/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0601 - mae: 0.1917 - val_loss: 0.0656 - val_mae: 0.1913\n",
      "Epoch 1708/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0579 - mae: 0.1894 - val_loss: 0.0709 - val_mae: 0.1995\n",
      "Epoch 1709/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0651 - mae: 0.1994 - val_loss: 0.0704 - val_mae: 0.2102\n",
      "Epoch 1710/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0658 - mae: 0.1994 - val_loss: 0.0806 - val_mae: 0.2161\n",
      "Epoch 1711/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0628 - mae: 0.1949 - val_loss: 0.0614 - val_mae: 0.1911\n",
      "Epoch 1712/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0568 - mae: 0.1853 - val_loss: 0.0756 - val_mae: 0.2123\n",
      "Epoch 1713/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0620 - mae: 0.1948 - val_loss: 0.0670 - val_mae: 0.2034\n",
      "Epoch 1714/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0597 - mae: 0.1863 - val_loss: 0.0557 - val_mae: 0.1821\n",
      "Epoch 1715/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0579 - mae: 0.1884 - val_loss: 0.0686 - val_mae: 0.2052\n",
      "Epoch 1716/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0594 - mae: 0.1895 - val_loss: 0.0757 - val_mae: 0.2106\n",
      "Epoch 1717/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0648 - mae: 0.1974 - val_loss: 0.0603 - val_mae: 0.1938\n",
      "Epoch 1718/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0535 - mae: 0.1796 - val_loss: 0.0690 - val_mae: 0.1939\n",
      "Epoch 1719/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0533 - mae: 0.1777 - val_loss: 0.0674 - val_mae: 0.1932\n",
      "Epoch 1720/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0575 - mae: 0.1851 - val_loss: 0.0582 - val_mae: 0.1893\n",
      "Epoch 1721/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0601 - mae: 0.1901 - val_loss: 0.0658 - val_mae: 0.1967\n",
      "Epoch 1722/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0589 - mae: 0.1909 - val_loss: 0.0710 - val_mae: 0.2121\n",
      "Epoch 1723/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0638 - mae: 0.1977 - val_loss: 0.0597 - val_mae: 0.1919\n",
      "Epoch 1724/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0643 - mae: 0.1979 - val_loss: 0.0612 - val_mae: 0.1941\n",
      "Epoch 1725/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0690 - mae: 0.2086 - val_loss: 0.0674 - val_mae: 0.1997\n",
      "Epoch 1726/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0615 - mae: 0.1945 - val_loss: 0.0656 - val_mae: 0.1997\n",
      "Epoch 1727/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0613 - mae: 0.1912 - val_loss: 0.0720 - val_mae: 0.2157\n",
      "Epoch 1728/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0670 - mae: 0.2018 - val_loss: 0.0850 - val_mae: 0.2179\n",
      "Epoch 1729/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0643 - mae: 0.1969 - val_loss: 0.0550 - val_mae: 0.1812\n",
      "Epoch 1730/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0588 - mae: 0.1891 - val_loss: 0.0671 - val_mae: 0.1931\n",
      "Epoch 1731/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0640 - mae: 0.1967 - val_loss: 0.0622 - val_mae: 0.1914\n",
      "Epoch 1732/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0622 - mae: 0.1952 - val_loss: 0.0819 - val_mae: 0.2324\n",
      "Epoch 1733/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0679 - mae: 0.2049 - val_loss: 0.0711 - val_mae: 0.2085\n",
      "Epoch 1734/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0664 - mae: 0.2003 - val_loss: 0.0731 - val_mae: 0.2084\n",
      "Epoch 1735/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0772 - mae: 0.2152 - val_loss: 0.0893 - val_mae: 0.2262\n",
      "Epoch 1736/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0683 - mae: 0.2038 - val_loss: 0.0800 - val_mae: 0.2146\n",
      "Epoch 1737/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0678 - mae: 0.2085 - val_loss: 0.0674 - val_mae: 0.2055\n",
      "Epoch 1738/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0650 - mae: 0.1981 - val_loss: 0.0589 - val_mae: 0.1930\n",
      "Epoch 1739/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0664 - mae: 0.2024 - val_loss: 0.0891 - val_mae: 0.2337\n",
      "Epoch 1740/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0844 - mae: 0.2303 - val_loss: 0.1386 - val_mae: 0.3002\n",
      "Epoch 1741/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0827 - mae: 0.2328 - val_loss: 0.0894 - val_mae: 0.2402\n",
      "Epoch 1742/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0689 - mae: 0.2087 - val_loss: 0.0611 - val_mae: 0.1907\n",
      "Epoch 1743/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0552 - mae: 0.1866 - val_loss: 0.0574 - val_mae: 0.1847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1744/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0585 - mae: 0.1881 - val_loss: 0.0644 - val_mae: 0.2048\n",
      "Epoch 1745/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0571 - mae: 0.1852 - val_loss: 0.0553 - val_mae: 0.1817\n",
      "Epoch 1746/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0613 - mae: 0.1934 - val_loss: 0.0630 - val_mae: 0.1914\n",
      "Epoch 1747/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0659 - mae: 0.2007 - val_loss: 0.1288 - val_mae: 0.2894\n",
      "Epoch 1748/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0842 - mae: 0.2293 - val_loss: 0.0675 - val_mae: 0.2083\n",
      "Epoch 1749/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0716 - mae: 0.2115 - val_loss: 0.0789 - val_mae: 0.2233\n",
      "Epoch 1750/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0750 - mae: 0.2184 - val_loss: 0.0920 - val_mae: 0.2488\n",
      "Epoch 1751/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.1011 - mae: 0.2575 - val_loss: 0.1104 - val_mae: 0.2647\n",
      "Epoch 1752/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0962 - mae: 0.2509 - val_loss: 0.0654 - val_mae: 0.2020\n",
      "Epoch 1753/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0715 - mae: 0.2118 - val_loss: 0.0761 - val_mae: 0.2103\n",
      "Epoch 1754/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0654 - mae: 0.2011 - val_loss: 0.0691 - val_mae: 0.2040\n",
      "Epoch 1755/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0615 - mae: 0.1922 - val_loss: 0.0585 - val_mae: 0.1885\n",
      "Epoch 1756/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0670 - mae: 0.2027 - val_loss: 0.0623 - val_mae: 0.1978\n",
      "Epoch 1757/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0616 - mae: 0.1972 - val_loss: 0.0697 - val_mae: 0.2036\n",
      "Epoch 1758/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0674 - mae: 0.2007 - val_loss: 0.0656 - val_mae: 0.1999\n",
      "Epoch 1759/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0575 - mae: 0.1843 - val_loss: 0.0734 - val_mae: 0.2132\n",
      "Epoch 1760/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0664 - mae: 0.2033 - val_loss: 0.0669 - val_mae: 0.1997\n",
      "Epoch 1761/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0552 - mae: 0.1833 - val_loss: 0.0533 - val_mae: 0.1816\n",
      "Epoch 1762/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0542 - mae: 0.1828 - val_loss: 0.0568 - val_mae: 0.1795\n",
      "Epoch 1763/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0501 - mae: 0.1729 - val_loss: 0.0656 - val_mae: 0.1922\n",
      "Epoch 1764/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0529 - mae: 0.1786 - val_loss: 0.0550 - val_mae: 0.1834\n",
      "Epoch 1765/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0553 - mae: 0.1829 - val_loss: 0.0727 - val_mae: 0.2021\n",
      "Epoch 1766/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0534 - mae: 0.1790 - val_loss: 0.0543 - val_mae: 0.1793\n",
      "Epoch 1767/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0505 - mae: 0.1739 - val_loss: 0.0605 - val_mae: 0.1946\n",
      "Epoch 1768/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0566 - mae: 0.1840 - val_loss: 0.0769 - val_mae: 0.2235\n",
      "Epoch 1769/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0677 - mae: 0.2079 - val_loss: 0.0565 - val_mae: 0.1845\n",
      "Epoch 1770/2000\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0570 - mae: 0.1869 - val_loss: 0.0608 - val_mae: 0.1904\n",
      "Epoch 1771/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0565 - mae: 0.1832 - val_loss: 0.0586 - val_mae: 0.1891\n",
      "Epoch 1772/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0647 - mae: 0.1968 - val_loss: 0.0539 - val_mae: 0.1808\n",
      "Epoch 1773/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0574 - mae: 0.1875 - val_loss: 0.0774 - val_mae: 0.2196\n",
      "Epoch 1774/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0698 - mae: 0.2108 - val_loss: 0.1070 - val_mae: 0.2599\n",
      "Epoch 1775/2000\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0731 - mae: 0.2156 - val_loss: 0.0556 - val_mae: 0.1826\n",
      "Epoch 1776/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0586 - mae: 0.1926 - val_loss: 0.0742 - val_mae: 0.2267\n",
      "Epoch 1777/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0628 - mae: 0.2005 - val_loss: 0.0543 - val_mae: 0.1823\n",
      "Epoch 1778/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0555 - mae: 0.1809 - val_loss: 0.0668 - val_mae: 0.2018\n",
      "Epoch 1779/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0540 - mae: 0.1837 - val_loss: 0.0618 - val_mae: 0.1893\n",
      "Epoch 1780/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0570 - mae: 0.1837 - val_loss: 0.0512 - val_mae: 0.1765\n",
      "Epoch 1781/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0532 - mae: 0.1794 - val_loss: 0.0633 - val_mae: 0.1955\n",
      "Epoch 1782/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0516 - mae: 0.1756 - val_loss: 0.0520 - val_mae: 0.1752\n",
      "Epoch 1783/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0568 - mae: 0.1864 - val_loss: 0.0702 - val_mae: 0.2127\n",
      "Epoch 1784/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0696 - mae: 0.2149 - val_loss: 0.0901 - val_mae: 0.2364\n",
      "Epoch 1785/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0692 - mae: 0.2103 - val_loss: 0.0608 - val_mae: 0.1898\n",
      "Epoch 1786/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0601 - mae: 0.1969 - val_loss: 0.0641 - val_mae: 0.2017\n",
      "Epoch 1787/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0669 - mae: 0.2018 - val_loss: 0.0494 - val_mae: 0.1764\n",
      "Epoch 1788/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0614 - mae: 0.1972 - val_loss: 0.0766 - val_mae: 0.2166\n",
      "Epoch 1789/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0610 - mae: 0.1957 - val_loss: 0.0971 - val_mae: 0.2542\n",
      "Epoch 1790/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0710 - mae: 0.2121 - val_loss: 0.0601 - val_mae: 0.1886\n",
      "Epoch 1791/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0610 - mae: 0.1968 - val_loss: 0.0567 - val_mae: 0.1862\n",
      "Epoch 1792/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0516 - mae: 0.1798 - val_loss: 0.0510 - val_mae: 0.1766\n",
      "Epoch 1793/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0468 - mae: 0.1684 - val_loss: 0.0490 - val_mae: 0.1718\n",
      "Epoch 1794/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0474 - mae: 0.1722 - val_loss: 0.0482 - val_mae: 0.1678\n",
      "Epoch 1795/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0438 - mae: 0.1644 - val_loss: 0.0961 - val_mae: 0.2417\n",
      "Epoch 1796/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0585 - mae: 0.1921 - val_loss: 0.0589 - val_mae: 0.1872\n",
      "Epoch 1797/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0529 - mae: 0.1824 - val_loss: 0.0545 - val_mae: 0.1853\n",
      "Epoch 1798/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0527 - mae: 0.1795 - val_loss: 0.0513 - val_mae: 0.1717\n",
      "Epoch 1799/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0481 - mae: 0.1717 - val_loss: 0.0512 - val_mae: 0.1741\n",
      "Epoch 1800/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0490 - mae: 0.1713 - val_loss: 0.0553 - val_mae: 0.1841\n",
      "Epoch 1801/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0497 - mae: 0.1765 - val_loss: 0.0596 - val_mae: 0.1996\n",
      "Epoch 1802/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0609 - mae: 0.1974 - val_loss: 0.0622 - val_mae: 0.1980\n",
      "Epoch 1803/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0657 - mae: 0.2079 - val_loss: 0.1082 - val_mae: 0.2671\n",
      "Epoch 1804/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0763 - mae: 0.2272 - val_loss: 0.0595 - val_mae: 0.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1805/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0649 - mae: 0.2056 - val_loss: 0.0501 - val_mae: 0.1767\n",
      "Epoch 1806/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0526 - mae: 0.1831 - val_loss: 0.0549 - val_mae: 0.1872\n",
      "Epoch 1807/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0468 - mae: 0.1714 - val_loss: 0.0489 - val_mae: 0.1772\n",
      "Epoch 1808/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0440 - mae: 0.1654 - val_loss: 0.0542 - val_mae: 0.1816\n",
      "Epoch 1809/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0427 - mae: 0.1618 - val_loss: 0.0566 - val_mae: 0.1814\n",
      "Epoch 1810/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0445 - mae: 0.1656 - val_loss: 0.0456 - val_mae: 0.1697\n",
      "Epoch 1811/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0440 - mae: 0.1637 - val_loss: 0.0486 - val_mae: 0.1768\n",
      "Epoch 1812/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0470 - mae: 0.1717 - val_loss: 0.0547 - val_mae: 0.1813\n",
      "Epoch 1813/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0519 - mae: 0.1800 - val_loss: 0.0859 - val_mae: 0.2258\n",
      "Epoch 1814/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0663 - mae: 0.2049 - val_loss: 0.0551 - val_mae: 0.1851\n",
      "Epoch 1815/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0631 - mae: 0.2008 - val_loss: 0.0727 - val_mae: 0.2134\n",
      "Epoch 1816/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0653 - mae: 0.2045 - val_loss: 0.0663 - val_mae: 0.2038\n",
      "Epoch 1817/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0581 - mae: 0.1908 - val_loss: 0.0652 - val_mae: 0.1939\n",
      "Epoch 1818/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0509 - mae: 0.1780 - val_loss: 0.0693 - val_mae: 0.2089\n",
      "Epoch 1819/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0526 - mae: 0.1823 - val_loss: 0.0543 - val_mae: 0.1845\n",
      "Epoch 1820/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0480 - mae: 0.1736 - val_loss: 0.0516 - val_mae: 0.1794\n",
      "Epoch 1821/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0475 - mae: 0.1733 - val_loss: 0.0556 - val_mae: 0.1802\n",
      "Epoch 1822/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0493 - mae: 0.1738 - val_loss: 0.0518 - val_mae: 0.1766\n",
      "Epoch 1823/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0433 - mae: 0.1613 - val_loss: 0.0451 - val_mae: 0.1659\n",
      "Epoch 1824/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0441 - mae: 0.1635 - val_loss: 0.0441 - val_mae: 0.1697\n",
      "Epoch 1825/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0414 - mae: 0.1607 - val_loss: 0.0690 - val_mae: 0.2025\n",
      "Epoch 1826/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0492 - mae: 0.1745 - val_loss: 0.0506 - val_mae: 0.1750\n",
      "Epoch 1827/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0462 - mae: 0.1676 - val_loss: 0.0520 - val_mae: 0.1794\n",
      "Epoch 1828/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0447 - mae: 0.1664 - val_loss: 0.0474 - val_mae: 0.1744\n",
      "Epoch 1829/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0481 - mae: 0.1753 - val_loss: 0.0547 - val_mae: 0.1825\n",
      "Epoch 1830/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0525 - mae: 0.1827 - val_loss: 0.0895 - val_mae: 0.2382\n",
      "Epoch 1831/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0509 - mae: 0.1779 - val_loss: 0.0535 - val_mae: 0.1839\n",
      "Epoch 1832/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0495 - mae: 0.1762 - val_loss: 0.0507 - val_mae: 0.1768\n",
      "Epoch 1833/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0465 - mae: 0.1714 - val_loss: 0.0555 - val_mae: 0.1810\n",
      "Epoch 1834/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0463 - mae: 0.1682 - val_loss: 0.0472 - val_mae: 0.1731\n",
      "Epoch 1835/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0454 - mae: 0.1675 - val_loss: 0.0506 - val_mae: 0.1763\n",
      "Epoch 1836/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0527 - mae: 0.1827 - val_loss: 0.0582 - val_mae: 0.1876\n",
      "Epoch 1837/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0543 - mae: 0.1853 - val_loss: 0.0497 - val_mae: 0.1763\n",
      "Epoch 1838/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0477 - mae: 0.1730 - val_loss: 0.0444 - val_mae: 0.1668\n",
      "Epoch 1839/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0448 - mae: 0.1670 - val_loss: 0.0912 - val_mae: 0.2406\n",
      "Epoch 1840/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0597 - mae: 0.1955 - val_loss: 0.0551 - val_mae: 0.1853\n",
      "Epoch 1841/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0627 - mae: 0.2009 - val_loss: 0.0630 - val_mae: 0.1982\n",
      "Epoch 1842/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0686 - mae: 0.2075 - val_loss: 0.0604 - val_mae: 0.1911\n",
      "Epoch 1843/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0805 - mae: 0.2233 - val_loss: 0.1018 - val_mae: 0.2619\n",
      "Epoch 1844/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0668 - mae: 0.2055 - val_loss: 0.0654 - val_mae: 0.2045\n",
      "Epoch 1845/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0569 - mae: 0.1918 - val_loss: 0.1027 - val_mae: 0.2613\n",
      "Epoch 1846/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0680 - mae: 0.2079 - val_loss: 0.0853 - val_mae: 0.2347\n",
      "Epoch 1847/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0595 - mae: 0.1929 - val_loss: 0.0650 - val_mae: 0.2038\n",
      "Epoch 1848/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0514 - mae: 0.1805 - val_loss: 0.0868 - val_mae: 0.2399\n",
      "Epoch 1849/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0601 - mae: 0.1954 - val_loss: 0.0678 - val_mae: 0.2084\n",
      "Epoch 1850/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0561 - mae: 0.1879 - val_loss: 0.0593 - val_mae: 0.1910\n",
      "Epoch 1851/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0507 - mae: 0.1782 - val_loss: 0.0502 - val_mae: 0.1759\n",
      "Epoch 1852/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0562 - mae: 0.1882 - val_loss: 0.0678 - val_mae: 0.2105\n",
      "Epoch 1853/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0649 - mae: 0.2051 - val_loss: 0.0705 - val_mae: 0.2171\n",
      "Epoch 1854/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0642 - mae: 0.2056 - val_loss: 0.0526 - val_mae: 0.1854\n",
      "Epoch 1855/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0601 - mae: 0.1980 - val_loss: 0.0527 - val_mae: 0.1804\n",
      "Epoch 1856/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0551 - mae: 0.1889 - val_loss: 0.0611 - val_mae: 0.1936\n",
      "Epoch 1857/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0571 - mae: 0.1891 - val_loss: 0.0694 - val_mae: 0.2156\n",
      "Epoch 1858/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0481 - mae: 0.1747 - val_loss: 0.0636 - val_mae: 0.2041\n",
      "Epoch 1859/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0466 - mae: 0.1714 - val_loss: 0.0567 - val_mae: 0.1855\n",
      "Epoch 1860/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0478 - mae: 0.1729 - val_loss: 0.0478 - val_mae: 0.1734\n",
      "Epoch 1861/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0501 - mae: 0.1777 - val_loss: 0.0545 - val_mae: 0.1868\n",
      "Epoch 1862/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0499 - mae: 0.1781 - val_loss: 0.0475 - val_mae: 0.1704\n",
      "Epoch 1863/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0527 - mae: 0.1850 - val_loss: 0.0710 - val_mae: 0.2109\n",
      "Epoch 1864/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0485 - mae: 0.1761 - val_loss: 0.0663 - val_mae: 0.2101\n",
      "Epoch 1865/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0526 - mae: 0.1834 - val_loss: 0.0490 - val_mae: 0.1749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1866/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0628 - mae: 0.1973 - val_loss: 0.0582 - val_mae: 0.1922\n",
      "Epoch 1867/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0566 - mae: 0.1928 - val_loss: 0.0511 - val_mae: 0.1777\n",
      "Epoch 1868/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0563 - mae: 0.1900 - val_loss: 0.0827 - val_mae: 0.2342\n",
      "Epoch 1869/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0595 - mae: 0.1953 - val_loss: 0.0920 - val_mae: 0.2592\n",
      "Epoch 1870/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0637 - mae: 0.2047 - val_loss: 0.0466 - val_mae: 0.1717\n",
      "Epoch 1871/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0480 - mae: 0.1763 - val_loss: 0.0609 - val_mae: 0.1977\n",
      "Epoch 1872/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0540 - mae: 0.1885 - val_loss: 0.0679 - val_mae: 0.2147\n",
      "Epoch 1873/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0649 - mae: 0.2041 - val_loss: 0.0969 - val_mae: 0.2524\n",
      "Epoch 1874/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0898 - mae: 0.2424 - val_loss: 0.0551 - val_mae: 0.1875\n",
      "Epoch 1875/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0756 - mae: 0.2203 - val_loss: 0.0982 - val_mae: 0.2486\n",
      "Epoch 1876/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0666 - mae: 0.2058 - val_loss: 0.1007 - val_mae: 0.2583\n",
      "Epoch 1877/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0647 - mae: 0.2046 - val_loss: 0.0599 - val_mae: 0.1977\n",
      "Epoch 1878/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0551 - mae: 0.1872 - val_loss: 0.0501 - val_mae: 0.1788\n",
      "Epoch 1879/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0458 - mae: 0.1709 - val_loss: 0.0689 - val_mae: 0.2038\n",
      "Epoch 1880/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0497 - mae: 0.1759 - val_loss: 0.0602 - val_mae: 0.1965\n",
      "Epoch 1881/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0464 - mae: 0.1711 - val_loss: 0.0461 - val_mae: 0.1727\n",
      "Epoch 1882/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0443 - mae: 0.1677 - val_loss: 0.0482 - val_mae: 0.1728\n",
      "Epoch 1883/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0423 - mae: 0.1613 - val_loss: 0.0678 - val_mae: 0.2020\n",
      "Epoch 1884/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0455 - mae: 0.1684 - val_loss: 0.0510 - val_mae: 0.1798\n",
      "Epoch 1885/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0422 - mae: 0.1613 - val_loss: 0.0607 - val_mae: 0.2025\n",
      "Epoch 1886/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0442 - mae: 0.1690 - val_loss: 0.0435 - val_mae: 0.1660\n",
      "Epoch 1887/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0460 - mae: 0.1703 - val_loss: 0.0657 - val_mae: 0.2045\n",
      "Epoch 1888/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0587 - mae: 0.1979 - val_loss: 0.0496 - val_mae: 0.1767\n",
      "Epoch 1889/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0496 - mae: 0.1780 - val_loss: 0.0526 - val_mae: 0.1858\n",
      "Epoch 1890/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0581 - mae: 0.1925 - val_loss: 0.0704 - val_mae: 0.2181\n",
      "Epoch 1891/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0603 - mae: 0.1985 - val_loss: 0.0613 - val_mae: 0.1990\n",
      "Epoch 1892/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0432 - mae: 0.1650 - val_loss: 0.0534 - val_mae: 0.1811\n",
      "Epoch 1893/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0467 - mae: 0.1691 - val_loss: 0.0435 - val_mae: 0.1634\n",
      "Epoch 1894/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0453 - mae: 0.1685 - val_loss: 0.0633 - val_mae: 0.1995\n",
      "Epoch 1895/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0520 - mae: 0.1830 - val_loss: 0.0450 - val_mae: 0.1663\n",
      "Epoch 1896/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0455 - mae: 0.1687 - val_loss: 0.0529 - val_mae: 0.1803\n",
      "Epoch 1897/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0446 - mae: 0.1661 - val_loss: 0.0436 - val_mae: 0.1633\n",
      "Epoch 1898/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0481 - mae: 0.1745 - val_loss: 0.0861 - val_mae: 0.2327\n",
      "Epoch 1899/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0553 - mae: 0.1871 - val_loss: 0.0574 - val_mae: 0.1906\n",
      "Epoch 1900/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0493 - mae: 0.1765 - val_loss: 0.0638 - val_mae: 0.1997\n",
      "Epoch 1901/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0526 - mae: 0.1830 - val_loss: 0.0463 - val_mae: 0.1721\n",
      "Epoch 1902/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0488 - mae: 0.1755 - val_loss: 0.0463 - val_mae: 0.1705\n",
      "Epoch 1903/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0433 - mae: 0.1649 - val_loss: 0.0514 - val_mae: 0.1749\n",
      "Epoch 1904/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0419 - mae: 0.1631 - val_loss: 0.0523 - val_mae: 0.1808\n",
      "Epoch 1905/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0401 - mae: 0.1585 - val_loss: 0.0482 - val_mae: 0.1756\n",
      "Epoch 1906/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0404 - mae: 0.1604 - val_loss: 0.0563 - val_mae: 0.1817\n",
      "Epoch 1907/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0483 - mae: 0.1752 - val_loss: 0.0511 - val_mae: 0.1832\n",
      "Epoch 1908/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0455 - mae: 0.1713 - val_loss: 0.0496 - val_mae: 0.1753\n",
      "Epoch 1909/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0457 - mae: 0.1687 - val_loss: 0.0459 - val_mae: 0.1674\n",
      "Epoch 1910/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0446 - mae: 0.1680 - val_loss: 0.0531 - val_mae: 0.1812\n",
      "Epoch 1911/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0440 - mae: 0.1661 - val_loss: 0.0676 - val_mae: 0.2105\n",
      "Epoch 1912/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0440 - mae: 0.1670 - val_loss: 0.0466 - val_mae: 0.1694\n",
      "Epoch 1913/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0413 - mae: 0.1607 - val_loss: 0.0437 - val_mae: 0.1653\n",
      "Epoch 1914/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0423 - mae: 0.1636 - val_loss: 0.0482 - val_mae: 0.1732\n",
      "Epoch 1915/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0417 - mae: 0.1617 - val_loss: 0.0464 - val_mae: 0.1677\n",
      "Epoch 1916/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0431 - mae: 0.1631 - val_loss: 0.0430 - val_mae: 0.1636\n",
      "Epoch 1917/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0366 - mae: 0.1511 - val_loss: 0.0396 - val_mae: 0.1607\n",
      "Epoch 1918/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0398 - mae: 0.1580 - val_loss: 0.0633 - val_mae: 0.1992\n",
      "Epoch 1919/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0474 - mae: 0.1739 - val_loss: 0.0427 - val_mae: 0.1637\n",
      "Epoch 1920/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0417 - mae: 0.1613 - val_loss: 0.0476 - val_mae: 0.1692\n",
      "Epoch 1921/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0412 - mae: 0.1596 - val_loss: 0.0542 - val_mae: 0.1847\n",
      "Epoch 1922/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0428 - mae: 0.1646 - val_loss: 0.0514 - val_mae: 0.1803\n",
      "Epoch 1923/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0410 - mae: 0.1606 - val_loss: 0.0456 - val_mae: 0.1696\n",
      "Epoch 1924/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0422 - mae: 0.1632 - val_loss: 0.0607 - val_mae: 0.1947\n",
      "Epoch 1925/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0423 - mae: 0.1636 - val_loss: 0.0568 - val_mae: 0.1913\n",
      "Epoch 1926/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0452 - mae: 0.1695 - val_loss: 0.0443 - val_mae: 0.1642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1927/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0389 - mae: 0.1555 - val_loss: 0.0424 - val_mae: 0.1592\n",
      "Epoch 1928/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0419 - mae: 0.1630 - val_loss: 0.0586 - val_mae: 0.1923\n",
      "Epoch 1929/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0433 - mae: 0.1657 - val_loss: 0.0403 - val_mae: 0.1621\n",
      "Epoch 1930/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0376 - mae: 0.1532 - val_loss: 0.0476 - val_mae: 0.1699\n",
      "Epoch 1931/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0419 - mae: 0.1638 - val_loss: 0.0417 - val_mae: 0.1557\n",
      "Epoch 1932/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0360 - mae: 0.1492 - val_loss: 0.0403 - val_mae: 0.1584\n",
      "Epoch 1933/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0361 - mae: 0.1510 - val_loss: 0.0479 - val_mae: 0.1709\n",
      "Epoch 1934/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0401 - mae: 0.1585 - val_loss: 0.0442 - val_mae: 0.1690\n",
      "Epoch 1935/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0488 - mae: 0.1763 - val_loss: 0.0600 - val_mae: 0.1991\n",
      "Epoch 1936/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0483 - mae: 0.1778 - val_loss: 0.0863 - val_mae: 0.2358\n",
      "Epoch 1937/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0494 - mae: 0.1767 - val_loss: 0.0520 - val_mae: 0.1795\n",
      "Epoch 1938/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0516 - mae: 0.1831 - val_loss: 0.0500 - val_mae: 0.1790\n",
      "Epoch 1939/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0491 - mae: 0.1776 - val_loss: 0.0452 - val_mae: 0.1700\n",
      "Epoch 1940/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0511 - mae: 0.1771 - val_loss: 0.0528 - val_mae: 0.1866\n",
      "Epoch 1941/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0461 - mae: 0.1695 - val_loss: 0.0542 - val_mae: 0.1841\n",
      "Epoch 1942/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0462 - mae: 0.1722 - val_loss: 0.0577 - val_mae: 0.1856\n",
      "Epoch 1943/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0448 - mae: 0.1676 - val_loss: 0.0377 - val_mae: 0.1533\n",
      "Epoch 1944/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0419 - mae: 0.1624 - val_loss: 0.0395 - val_mae: 0.1590\n",
      "Epoch 1945/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0415 - mae: 0.1602 - val_loss: 0.0468 - val_mae: 0.1750\n",
      "Epoch 1946/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0511 - mae: 0.1829 - val_loss: 0.1034 - val_mae: 0.2627\n",
      "Epoch 1947/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0637 - mae: 0.2030 - val_loss: 0.0584 - val_mae: 0.1960\n",
      "Epoch 1948/2000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0500 - mae: 0.1790 - val_loss: 0.0504 - val_mae: 0.1780\n",
      "Epoch 1949/2000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0421 - mae: 0.1632 - val_loss: 0.0490 - val_mae: 0.1720\n",
      "Epoch 1950/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0465 - mae: 0.1730 - val_loss: 0.0533 - val_mae: 0.1846\n",
      "Epoch 1951/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0457 - mae: 0.1696 - val_loss: 0.0483 - val_mae: 0.1771\n",
      "Epoch 1952/2000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0406 - mae: 0.1569 - val_loss: 0.0447 - val_mae: 0.1711\n",
      "Epoch 1953/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0420 - mae: 0.1628 - val_loss: 0.0408 - val_mae: 0.1603\n",
      "Epoch 1954/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0406 - mae: 0.1619 - val_loss: 0.0476 - val_mae: 0.1700\n",
      "Epoch 1955/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0426 - mae: 0.1637 - val_loss: 0.0554 - val_mae: 0.1816\n",
      "Epoch 1956/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0381 - mae: 0.1542 - val_loss: 0.0457 - val_mae: 0.1697\n",
      "Epoch 1957/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0431 - mae: 0.1646 - val_loss: 0.0651 - val_mae: 0.2064\n",
      "Epoch 1958/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0429 - mae: 0.1648 - val_loss: 0.0531 - val_mae: 0.1820\n",
      "Epoch 1959/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0432 - mae: 0.1648 - val_loss: 0.0467 - val_mae: 0.1670\n",
      "Epoch 1960/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0430 - mae: 0.1648 - val_loss: 0.0518 - val_mae: 0.1749\n",
      "Epoch 1961/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0446 - mae: 0.1679 - val_loss: 0.0626 - val_mae: 0.1979\n",
      "Epoch 1962/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0458 - mae: 0.1713 - val_loss: 0.0516 - val_mae: 0.1807\n",
      "Epoch 1963/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0476 - mae: 0.1728 - val_loss: 0.0477 - val_mae: 0.1724\n",
      "Epoch 1964/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0440 - mae: 0.1679 - val_loss: 0.0466 - val_mae: 0.1670\n",
      "Epoch 1965/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0444 - mae: 0.1674 - val_loss: 0.0593 - val_mae: 0.1906\n",
      "Epoch 1966/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0415 - mae: 0.1606 - val_loss: 0.0454 - val_mae: 0.1720\n",
      "Epoch 1967/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0411 - mae: 0.1604 - val_loss: 0.0435 - val_mae: 0.1647\n",
      "Epoch 1968/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0450 - mae: 0.1707 - val_loss: 0.0542 - val_mae: 0.1837\n",
      "Epoch 1969/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0546 - mae: 0.1869 - val_loss: 0.0575 - val_mae: 0.1860\n",
      "Epoch 1970/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0453 - mae: 0.1696 - val_loss: 0.0548 - val_mae: 0.1802\n",
      "Epoch 1971/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0444 - mae: 0.1670 - val_loss: 0.0467 - val_mae: 0.1768\n",
      "Epoch 1972/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0448 - mae: 0.1689 - val_loss: 0.0601 - val_mae: 0.1934\n",
      "Epoch 1973/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0451 - mae: 0.1686 - val_loss: 0.0450 - val_mae: 0.1652\n",
      "Epoch 1974/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0409 - mae: 0.1599 - val_loss: 0.0447 - val_mae: 0.1636\n",
      "Epoch 1975/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0367 - mae: 0.1517 - val_loss: 0.0428 - val_mae: 0.1623\n",
      "Epoch 1976/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0372 - mae: 0.1531 - val_loss: 0.0761 - val_mae: 0.2198\n",
      "Epoch 1977/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0578 - mae: 0.1936 - val_loss: 0.0509 - val_mae: 0.1835\n",
      "Epoch 1978/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0509 - mae: 0.1807 - val_loss: 0.0753 - val_mae: 0.2165\n",
      "Epoch 1979/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0512 - mae: 0.1805 - val_loss: 0.0561 - val_mae: 0.1832\n",
      "Epoch 1980/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0469 - mae: 0.1723 - val_loss: 0.0669 - val_mae: 0.2097\n",
      "Epoch 1981/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0471 - mae: 0.1712 - val_loss: 0.0551 - val_mae: 0.1890\n",
      "Epoch 1982/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0420 - mae: 0.1620 - val_loss: 0.0377 - val_mae: 0.1532\n",
      "Epoch 1983/2000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0389 - mae: 0.1560 - val_loss: 0.0489 - val_mae: 0.1766\n",
      "Epoch 1984/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0480 - mae: 0.1736 - val_loss: 0.0522 - val_mae: 0.1801\n",
      "Epoch 1985/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0403 - mae: 0.1600 - val_loss: 0.0545 - val_mae: 0.1828\n",
      "Epoch 1986/2000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0527 - mae: 0.1847 - val_loss: 0.0476 - val_mae: 0.1750\n",
      "Epoch 1987/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0589 - mae: 0.1898 - val_loss: 0.0707 - val_mae: 0.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1988/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0594 - mae: 0.1934 - val_loss: 0.0762 - val_mae: 0.2303\n",
      "Epoch 1989/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0623 - mae: 0.2011 - val_loss: 0.0621 - val_mae: 0.1975\n",
      "Epoch 1990/2000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0526 - mae: 0.1843 - val_loss: 0.0608 - val_mae: 0.1953\n",
      "Epoch 1991/2000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0507 - mae: 0.1802 - val_loss: 0.0464 - val_mae: 0.1746\n",
      "Epoch 1992/2000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0494 - mae: 0.1776 - val_loss: 0.0547 - val_mae: 0.1867\n",
      "Epoch 1993/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0594 - mae: 0.1940 - val_loss: 0.0718 - val_mae: 0.2156\n",
      "Epoch 1994/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0694 - mae: 0.2133 - val_loss: 0.0506 - val_mae: 0.1793\n",
      "Epoch 1995/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0518 - mae: 0.1815 - val_loss: 0.0586 - val_mae: 0.1940\n",
      "Epoch 1996/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0528 - mae: 0.1839 - val_loss: 0.0641 - val_mae: 0.2013\n",
      "Epoch 1997/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0598 - mae: 0.1969 - val_loss: 0.0544 - val_mae: 0.1850\n",
      "Epoch 1998/2000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0554 - mae: 0.1873 - val_loss: 0.0581 - val_mae: 0.1963\n",
      "Epoch 1999/2000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0501 - mae: 0.1774 - val_loss: 0.0650 - val_mae: 0.2065\n",
      "Epoch 2000/2000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0492 - mae: 0.1769 - val_loss: 0.0694 - val_mae: 0.2166\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.SimpleRNN(1024, input_shape=(time_step,2)))\n",
    "model.add(layers.Dense(25))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(train_input, train_label, epochs=2000, verbose=1, shuffle=True, validation_split=0.20,\n",
    "                   callbacks=[WandbCallback(log_weights=True, log_gradients=True, training_data=(train_input, train_label))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2977e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "test_input = test_input.reshape(1, test_input.shape[0], test_input.shape[1])\n",
    "\n",
    "y_hat = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "569d2b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b083de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.reshape(1, test_label.shape[0], test_label.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e7a073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3e0c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3496064, 1.4730085, 1.484499 , 1.4647421, 1.6875631, 1.8201286,\n",
       "        1.0467167, 1.5440521, 1.7040023, 1.5839533, 2.0255072, 2.3078122,\n",
       "        1.3791027, 1.5879078, 1.6214304, 1.5523719, 1.9751403, 1.9663874,\n",
       "        1.1907656, 1.7358775, 1.7929093, 1.7509434, 2.2028933, 2.3563309,\n",
       "        1.4160148]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e37311d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0f0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat.reshape(y_hat.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ea1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = (y_hat*data_std)+data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "702f2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca1a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e40982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat = y_hat * (scaler.data_max_[1]-scaler.data_min_[1]) + scaler.data_min_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "902bb0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RNN prediction')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(325)\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(df[300:325]['Sales'], label='original')\n",
    "plt.plot(x[300:325], y_hat, label='prediction')\n",
    "plt.legend()\n",
    "plt.xlabel('Sequence', fontsize=20)\n",
    "plt.ylabel('Sales', fontsize=20)\n",
    "plt.title('RNN prediction', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "051887d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1500 - mae: 0.3201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1499682366847992, 0.3201119601726532]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aee6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
